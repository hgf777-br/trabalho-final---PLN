{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VDbi6PDS9MYO"
   },
   "source": [
    "***Participantes (RM - NOME):***<br>\n",
    "339708 - Roberto<br>\n",
    "340192 - Sergio<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7xw6WhaNo4k3"
   },
   "source": [
    "## **Criar um classificador de sentimento aplicando técnicas de PLN**\n",
    "---\n",
    "\n",
    "Utilizando o dataset de revisões de filmes em português [1], criar um classificador de sentimentos que consiga um score na métrica F1 Score superior a 70%.\n",
    "\n",
    "Devem utilizar uma amostra de 20% e randon_state igual a 42 para testar as implementações e mensurar a métrica F1 Score (usar o parâmetro average = 'weighted') o restante dos dados devem ser utilizados para o treinamento (80%).\n",
    "\n",
    "Fique a vontade para testar os métodos de pré-processamento, abordagens, algoritmos e bibliotecas, mas explique e justifique suas decisões.\n",
    "O trabalho poderá ser feito em grupo de até 4 pessoas (mesmo grupo do Startup One).\n",
    "\n",
    "Separe a implementação do seu modelo campeão junto com a parte de validação/teste de forma que o professor consiga executar todo o pipeline do modelo campeão.\n",
    "\n",
    "Composição da nota:\n",
    "- 50% - Demonstrações das aplicações das técnicas de PLN (regras, pré-processamentos, tratamentos, variedade de modelos aplicados, etc.)\n",
    "- 50% - Baseado na performance obtida com o dataset de teste (conforme recomendação da amostra) no seu modelo campeão e na validação que o professor processar (Métrica F1 Score)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fzhQpodBpRpX"
   },
   "source": [
    "[1] - https://dados-ml-pln.s3-sa-east-1.amazonaws.com/reviews-pt-br.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bibliotecas utilizadas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to C:\\Users\\Roberto\n",
      "[nltk_data]     Tengan\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import spacy\n",
    "import nltk\n",
    "import seaborn as sb\n",
    "import plotly.express as px\n",
    "import spacy\n",
    "import nltk\n",
    "\n",
    "from nltk.stem.rslp import RSLPStemmer\n",
    "from nltk.tokenize import word_tokenize\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "\n",
    "rslp = RSLPStemmer()\n",
    "nlp = spacy.load('pt_core_news_sm')\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# função de lematização completa do documento\n",
    "def stemmer(frase):\n",
    "  tokens = [rslp.stem(w) for w in frase.split()]\n",
    "  return \" \".join(tokens)\n",
    "\n",
    "# função de lematização completa do documento\n",
    "def lemmatizer(frase):\n",
    "  doc = nlp(frase)\n",
    "  tokens = [w.lemma_ for w in doc]\n",
    "  return \" \".join(tokens)\n",
    "\n",
    "# função de lematização para os verbos do documento\n",
    "def lemmatizer_verbs(frase):\n",
    "  doc = nlp(frase)\n",
    "  tokens = [w.lemma_ if w.pos_ == 'VERB' else w.text for w in doc]\n",
    "  return \" \".join(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "DMBI8SQtps1n"
   },
   "outputs": [],
   "source": [
    "stops = list(set(nlp.Defaults.stop_words).union(set(nltk.corpus.stopwords.words('portuguese'))))\n",
    "df = pd.read_csv('./data/reviews-pt-br.csv', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "s__lBzDQwrcG",
    "outputId": "0bd3d84d-be60-4da3-c598-62f4a045b6c6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 44514 entries, 0 to 44513\n",
      "Data columns (total 3 columns):\n",
      " #   Column      Non-Null Count  Dtype \n",
      "---  ------      --------------  ----- \n",
      " 0   codigo      44514 non-null  int64 \n",
      " 1   texto       44514 non-null  object\n",
      " 2   sentimento  44514 non-null  object\n",
      "dtypes: int64(1), object(2)\n",
      "memory usage: 1.0+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FyKC9Vhkp0BK"
   },
   "source": [
    "Conferindo se temos dados nulos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "nze8UbKhosm9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "codigo        0\n",
       "texto         0\n",
       "sentimento    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "ue0nV0uVo3OZ"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>codigo</th>\n",
       "      <th>texto</th>\n",
       "      <th>sentimento</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Esse bocejo de pia de cozinha de orçamento mui...</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>O Bravo parece indicar que o personagem princi...</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Durante a Guerra pela Independência do Sul, GE...</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>É fora de questão que a verdadeira Anna Anders...</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Concordo totalmente com outro dos revisores aq...</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>Obra-prima absoluta de um filme! Boa noite Mr....</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>Embora a palavra megalmania seja muito usada p...</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>Esta tem que ser a peça mais incrível de porca...</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>Eu suponho que todas as piadas internas são o ...</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>Se há um tema deste filme, é que as pessoas po...</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   codigo                                              texto sentimento\n",
       "0       1  Esse bocejo de pia de cozinha de orçamento mui...        neg\n",
       "1       2  O Bravo parece indicar que o personagem princi...        neg\n",
       "2       3  Durante a Guerra pela Independência do Sul, GE...        pos\n",
       "3       4  É fora de questão que a verdadeira Anna Anders...        pos\n",
       "4       5  Concordo totalmente com outro dos revisores aq...        neg\n",
       "5       6  Obra-prima absoluta de um filme! Boa noite Mr....        pos\n",
       "6       7  Embora a palavra megalmania seja muito usada p...        pos\n",
       "7       8  Esta tem que ser a peça mais incrível de porca...        neg\n",
       "8       9  Eu suponho que todas as piadas internas são o ...        neg\n",
       "9      10  Se há um tema deste filme, é que as pessoas po...        pos"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>codigo</th>\n",
       "      <th>texto</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sentimento</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>neg</th>\n",
       "      <td>22307</td>\n",
       "      <td>22307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pos</th>\n",
       "      <td>22207</td>\n",
       "      <td>22207</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            codigo  texto\n",
       "sentimento               \n",
       "neg          22307  22307\n",
       "pos          22207  22207"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby('sentimento').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "FziwgqJmw9OD"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='sentimento', ylabel='count'>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZEAAAEGCAYAAACkQqisAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/Z1A+gAAAACXBIWXMAAAsTAAALEwEAmpwYAAARqklEQVR4nO3de7BdZXnH8e9PEOu1RBMpEmgcTWuDVoQMoLYdWjoYmFGU4oWqRGQap4LjpXZKOx1jQafaah3xQotjJHhDvJXooJihtvUWJVRKBC+kipIUIRoULV4GfPrHfo9swznk8ObsvXM438/MnrP2s9611rMzG36zrjtVhSRJPe4z6QYkSfOXISJJ6maISJK6GSKSpG6GiCSp276TbmDcFi9eXMuWLZt0G5I0r1x55ZXfq6olu9YXXIgsW7aMzZs3T7oNSZpXknx7urqHsyRJ3QwRSVI3Q0SS1M0QkSR1M0QkSd0MEUlSN0NEktTNEJEkdTNEJEndFtwd63vqiL+8cNItaC905T+eOukWpIkwRKR7ke+c/bhJt6C90CGv2jKydXs4S5LUzRCRJHUzRCRJ3QwRSVI3Q0SS1M0QkSR1M0QkSd0MEUlSN0NEktTNEJEkdTNEJEndDBFJUjdDRJLUzRCRJHUzRCRJ3QwRSVK3kYVIkoOTfDrJtUmuSfLSVn9oko1Jrmt/F7V6kpybZGuSq5McPrSu1W38dUlWD9WPSLKlLXNukozq80iS7mqUeyK3A39RVSuAo4EzkqwAzgIur6rlwOXtPcDxwPL2WgOcB4PQAdYCRwFHAmungqeN+bOh5VaN8PNIknYxshCpqhur6r/a9I+ArwIHAScC69uw9cDT2/SJwIU1sAnYP8mBwFOAjVW1s6puATYCq9q8h1TVpqoq4MKhdUmSxmAs50SSLAOeAHwROKCqbmyzvgsc0KYPAm4YWmxbq91dfds09em2vybJ5iSbd+zYsWcfRpL0SyMPkSQPAj4MvKyqbh2e1/YgatQ9VNX5VbWyqlYuWbJk1JuTpAVjpCGS5L4MAuS9VfWRVr6pHYqi/b251bcDBw8tvrTV7q6+dJq6JGlMRnl1VoB3Al+tqn8amrUBmLrCajVwyVD91HaV1tHAD9thr8uA45IsaifUjwMua/NuTXJ029apQ+uSJI3BviNc95OB5wNbklzVan8DvA64OMnpwLeBZ7V5lwInAFuB24DTAKpqZ5JzgCvauLOramebfjFwAXB/4BPtJUkak5GFSFV9Fpjpvo1jpxlfwBkzrGsdsG6a+mbgsXvQpiRpD3jHuiSpmyEiSepmiEiSuhkikqRuhogkqZshIknqZohIkroZIpKkboaIJKmbISJJ6maISJK6GSKSpG6GiCSpmyEiSepmiEiSuhkikqRuhogkqZshIknqZohIkroZIpKkboaIJKmbISJJ6maISJK6GSKSpG6GiCSpmyEiSepmiEiSuhkikqRuhogkqZshIknqZohIkroZIpKkboaIJKmbISJJ6maISJK6GSKSpG6GiCSp28hCJMm6JDcn+cpQ7dVJtie5qr1OGJr310m2Jvl6kqcM1Ve12tYkZw3VH5nki63+gST7jeqzSJKmN8o9kQuAVdPU31RVh7XXpQBJVgDPAQ5ty7w9yT5J9gHeBhwPrABOaWMBXt/W9WjgFuD0EX4WSdI0RhYiVfWfwM5ZDj8RuKiqflZV3wK2Ake219aq+mZV/Ry4CDgxSYA/Aj7Ull8PPH0u+5ck7d4kzomcmeTqdrhrUasdBNwwNGZbq81Ufxjwg6q6fZe6JGmMxh0i5wGPAg4DbgTeOI6NJlmTZHOSzTt27BjHJiVpQRhriFTVTVV1R1X9AngHg8NVANuBg4eGLm21merfB/ZPsu8u9Zm2e35VrayqlUuWLJmbDyNJGm+IJDlw6O0zgKkrtzYAz0lyvySPBJYDXwKuAJa3K7H2Y3DyfUNVFfBp4OS2/GrgknF8BknSnfbd/ZA+Sd4PHAMsTrINWAsck+QwoIDrgRcBVNU1SS4GrgVuB86oqjvaes4ELgP2AdZV1TVtE38FXJTkNcCXgXeO6rNIkqY3shCpqlOmKc/4P/qqei3w2mnqlwKXTlP/JnceDpMkTYB3rEuSuhkikqRuhogkqZshIknqZohIkroZIpKkboaIJKmbISJJ6maISJK6GSKSpG6GiCSpmyEiSepmiEiSuhkikqRuswqRJJfPpiZJWlju9vdEkvwa8AAGPyy1CEib9RDgoBH3Jknay+3uR6leBLwMeARwJXeGyK3AW0fXliRpPrjbEKmqNwNvTvKSqnrLmHqSJM0Ts/p53Kp6S5InAcuGl6mqC0fUlyRpHphViCR5N/Ao4CrgjlYuwBCRpAVsViECrARWVFWNshlJ0vwy2/tEvgL8xigbkSTNP7PdE1kMXJvkS8DPpopV9bSRdCVJmhdmGyKvHmUTkqT5abZXZ/3HqBuRJM0/s70660cMrsYC2A+4L/B/VfWQUTUmSdr7zXZP5MFT00kCnAgcPaqmJEnzwz1+im8N/CvwlLlvR5I0n8z2cNZJQ2/vw+C+kZ+OpCNJ0rwx26uznjo0fTtwPYNDWpKkBWy250ROG3UjkqT5Z7Y/SrU0yUeT3NxeH06ydNTNSZL2brM9sf4uYAOD3xV5BPCxVpMkLWCzDZElVfWuqrq9vS4AloywL0nSPDDbEPl+kucl2ae9ngd8f5SNSZL2frMNkRcCzwK+C9wInAy8YEQ9SZLmidle4ns2sLqqbgFI8lDgDQzCRZK0QM12T+R3pwIEoKp2Ak8YTUuSpPlitiFynySLpt60PZG73YtJsq5dDvyV4eWSbExyXfu7qNWT5NwkW5NcneTwoWVWt/HXJVk9VD8iyZa2zLntmV6SpDGabYi8EfhCknOSnAN8HviH3SxzAbBql9pZwOVVtRy4vL0HOB5Y3l5rgPPgl2G1FjgKOBJYOxRm5wF/NrTcrtuSJI3YrEKkqi4ETgJuaq+Tqurdu1nmP4Gdu5RPBNa36fXA04fqF7aHO24C9k9yIIOHPG6sqp3tcNpGYFWb95Cq2tR+9/3CoXVJksZktifWqaprgWv3cHsHVNWNbfq7wAFt+iDghqFx21rt7urbpqlPK8kaBns4HHLIIXvQviRp2D1+FPxcaXsQtduBc7Ot86tqZVWtXLLEeyQlaa6MO0RuaoeiaH9vbvXtwMFD45a22t3Vl05TlySN0bhDZAMwdYXVauCSofqp7Sqto4EftsNelwHHJVnUTqgfB1zW5t2a5Oh2VdapQ+uSJI3JrM+J3FNJ3g8cAyxOso3BVVavAy5OcjrwbQZ3wQNcCpwAbAVuA06Dwf0o7WqwK9q4s9s9KgAvZnAF2P2BT7SXJGmMRhYiVXXKDLOOnWZsAWfMsJ51wLpp6puBx+5Jj5KkPTOxE+uSpPnPEJEkdTNEJEndDBFJUjdDRJLUzRCRJHUzRCRJ3QwRSVI3Q0SS1M0QkSR1M0QkSd0MEUlSN0NEktTNEJEkdTNEJEndDBFJUjdDRJLUzRCRJHUzRCRJ3QwRSVI3Q0SS1M0QkSR1M0QkSd0MEUlSN0NEktTNEJEkdTNEJEndDBFJUjdDRJLUzRCRJHUzRCRJ3QwRSVI3Q0SS1M0QkSR1M0QkSd0MEUlSN0NEktRtIiGS5PokW5JclWRzqz00ycYk17W/i1o9Sc5NsjXJ1UkOH1rP6jb+uiSrJ/FZJGkhm+SeyB9W1WFVtbK9Pwu4vKqWA5e39wDHA8vbaw1wHgxCB1gLHAUcCaydCh5J0njsTYezTgTWt+n1wNOH6hfWwCZg/yQHAk8BNlbVzqq6BdgIrBpzz5K0oE0qRAr4VJIrk6xptQOq6sY2/V3ggDZ9EHDD0LLbWm2m+l0kWZNkc5LNO3bsmKvPIEkL3r4T2u7vVdX2JA8HNib52vDMqqokNVcbq6rzgfMBVq5cOWfrlaSFbiJ7IlW1vf29Gfgog3MaN7XDVLS/N7fh24GDhxZf2moz1SVJYzL2EEnywCQPnpoGjgO+AmwApq6wWg1c0qY3AKe2q7SOBn7YDntdBhyXZFE7oX5cq0mSxmQSh7MOAD6aZGr776uqTya5Arg4yenAt4FntfGXAicAW4HbgNMAqmpnknOAK9q4s6tq5/g+hiRp7CFSVd8EHj9N/fvAsdPUCzhjhnWtA9bNdY+SpNnZmy7xlSTNM4aIJKmbISJJ6maISJK6GSKSpG6GiCSpmyEiSepmiEiSuhkikqRuhogkqZshIknqZohIkroZIpKkboaIJKmbISJJ6maISJK6GSKSpG6GiCSpmyEiSepmiEiSuhkikqRuhogkqZshIknqZohIkroZIpKkboaIJKmbISJJ6maISJK6GSKSpG6GiCSpmyEiSepmiEiSuhkikqRuhogkqZshIknqZohIkroZIpKkboaIJKnbvA+RJKuSfD3J1iRnTbofSVpI5nWIJNkHeBtwPLACOCXJisl2JUkLx7wOEeBIYGtVfbOqfg5cBJw44Z4kacHYd9IN7KGDgBuG3m8Djtp1UJI1wJr29sdJvj6G3haCxcD3Jt3E3iBvWD3pFnRXfj+nrM1crOU3pyvO9xCZlao6Hzh/0n3c2yTZXFUrJ92HNB2/n+Mx3w9nbQcOHnq/tNUkSWMw30PkCmB5kkcm2Q94DrBhwj1J0oIxrw9nVdXtSc4ELgP2AdZV1TUTbmsh8RCh9mZ+P8cgVTXpHiRJ89R8P5wlSZogQ0SS1M0QkSR1M0QkSd0MEc0oybIkX03yjiTXJPlUkvsneVSSTya5MslnkjymjX9Ukk1JtiR5TZIfT/oz6N6rfT+/luS97Xv6oSQPSHJski+37+G6JPdr41+X5NokVyd5w6T7v7cwRLQ7y4G3VdWhwA+AP2Fw6eRLquoI4JXA29vYNwNvrqrHMXgEjTRqvw28vap+B7gVeAVwAfDs9j3cF/jzJA8DngEcWlW/C7xmQv3e6xgi2p1vVdVVbfpKYBnwJOCDSa4C/gU4sM1/IvDBNv2+8bWoBeyGqvpcm34PcCyD7+w3Wm098AfAD4GfAu9MchJw29g7vZea1zcbaix+NjR9B3AA8IOqOmwy7Ui/Ytcb3X4APOwugwY3Jh/JIGROBs4E/mjk3S0A7ononroV+FaSZwJk4PFt3iYGh7tg8AgaadQOSfLENv2nwGZgWZJHt9rzgf9I8iDg16vqUuDlwOPvuir1METU47nA6Un+G7iGO3/D5WXAK5JcDTyawSEEaZS+DpyR5KvAIuBNwGkMDrduAX4B/DPwYODj7bv5WQbnTjQHfOyJ5kySBwA/qapK8hzglKryR8I0EkmWAR+vqsdOupeFzHMimktHAG9NEgbHpl842XYkjZp7IpKkbp4TkSR1M0QkSd0MEUlSN0NEGqEkhyU5Yej905KcNeJtHpPkSaPchjTFEJFG6zDglyFSVRuq6nUj3uYxDB5NI42cV2dJM0jyQOBiYCmwD3AOsBX4J+BBwPeAF1TVjUn+Hfgi8IfA/sDp7f1W4P7AduDv2/TKqjozyQXAT4AnAA9ncEn0qQyeQfbFqnpB6+M44O+A+wH/A5xWVT9Ocj2DZ0M9Fbgv8EwGz4faxOARNTuAlwA3AOuAxa12WlV9Z27/tbRQuScizWwV8L9V9fh2Q9sngbcAJ7cnGK8DXjs0ft+qOpLBnftrq+rnwKuAD1TVYVX1gWm2sYhBaLwc2MDgjutDgce1Q2GLgb8F/riqDmfwWI/hu62/1+rnAa+squsZ3KH9prbNz7Se17en174XOHeP/2WkxpsNpZltAd6Y5PXAx4FbgMcCGwf3U7IPcOPQ+I+0v1NPO56Nj7U7/LcAN1XVFoAk17R1LAVWAJ9r29wP+MIM2zxphm08cWjeu4F/mGVv0m4ZItIMquobSQ5ncE7jNcC/AddU1RNnWGTqicd3MPv/tqaW+QW/+sTkX7R13AFsrKpT5nCb0pzxcJY0gySPAG6rqvcA/wgcBSyZempskvsmOXQ3q/kRg4f/9doEPHnqqbRJHpjkt+7hNj/PnU9Vfi7wmT3oR/oVhog0s8cBX2o/vrWWwfmNk4HXtycYX8Xur4L6NLAiyVVJnn1PG6iqHcALgPe3J9B+AXjMbhb7GPCMts3fZ3By/bS2/POBl97TPqSZeHWWJKmbeyKSpG6GiCSpmyEiSepmiEiSuhkikqRuhogkqZshIknq9v/1AYfZCMGkKQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sb.countplot(x=df.sentimento)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 6min 40s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df['stemmer'] = df.texto.apply(stemmer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 0 ns\n"
     ]
    }
   ],
   "source": [
    "%time\n",
    "df['lemma'] = df.texto.apply(lemmatizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 22min 20s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df['lemma_verb'] = df.texto.apply(lemmatizer_verbs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"./data/criticas.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>codigo</th>\n",
       "      <th>texto</th>\n",
       "      <th>sentimento</th>\n",
       "      <th>stemmer</th>\n",
       "      <th>lemma</th>\n",
       "      <th>lemma_verb</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Esse bocejo de pia de cozinha de orçamento mui...</td>\n",
       "      <td>neg</td>\n",
       "      <td>ess bocej de pia de co de orç muit baix é o ti...</td>\n",
       "      <td>Esse bocejar de pio de cozinhar de orçamentar ...</td>\n",
       "      <td>Esse bocejo de pia de cozinha de orçamento mui...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>O Bravo parece indicar que o personagem princi...</td>\n",
       "      <td>neg</td>\n",
       "      <td>o brav parec indic que o person principal, cla...</td>\n",
       "      <td>O Bravo parecer indicar que o personagem princ...</td>\n",
       "      <td>O Bravo parecer indicar que o personagem princ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Durante a Guerra pela Independência do Sul, GE...</td>\n",
       "      <td>pos</td>\n",
       "      <td>dur a guerr pel independ do sul, gener spanky ...</td>\n",
       "      <td>Durante o Guerra pelar Independência do Sul , ...</td>\n",
       "      <td>Durante a Guerra pela Independência do Sul , G...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>É fora de questão que a verdadeira Anna Anders...</td>\n",
       "      <td>pos</td>\n",
       "      <td>é for de quest que a verd ann anderson não era...</td>\n",
       "      <td>É ser de questão que o verdadeiro Anna Anderso...</td>\n",
       "      <td>É fora de questão que a verdadeira Anna Anders...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Concordo totalmente com outro dos revisores aq...</td>\n",
       "      <td>neg</td>\n",
       "      <td>concord total com outr do revi aqu que fic sat...</td>\n",
       "      <td>Concordo totalmente com outro dos revisor aqui...</td>\n",
       "      <td>Concordo totalmente com outro dos revisores aq...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>Obra-prima absoluta de um filme! Boa noite Mr....</td>\n",
       "      <td>pos</td>\n",
       "      <td>obra-pr absolut de um filme! boa noit mr.tom r...</td>\n",
       "      <td>Obra-prima absoluto de um filmar ! Boa noite M...</td>\n",
       "      <td>Obra-prima absoluta de um filme ! Boa noite Mr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>Embora a palavra megalmania seja muito usada p...</td>\n",
       "      <td>pos</td>\n",
       "      <td>emb a palavr megalman sej muit us par descrev ...</td>\n",
       "      <td>Embora o palavra megalmania ser muito usar par...</td>\n",
       "      <td>Embora a palavra megalmania seja muito usar pa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>Esta tem que ser a peça mais incrível de porca...</td>\n",
       "      <td>neg</td>\n",
       "      <td>est tem que ser a peç mais incr de porc cinema...</td>\n",
       "      <td>Esta ter que ser o pedir mais incrível de porc...</td>\n",
       "      <td>Esta tem que ser a peça mais incrível de porca...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>Eu suponho que todas as piadas internas são o ...</td>\n",
       "      <td>neg</td>\n",
       "      <td>eu suponh que tod as pi intern são o que fez d...</td>\n",
       "      <td>Eu supor que todo o piar interno ser o que faz...</td>\n",
       "      <td>Eu supor que todas as piadas internas são o qu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>Se há um tema deste filme, é que as pessoas po...</td>\n",
       "      <td>pos</td>\n",
       "      <td>se há um tem dest filme, é que as pesso pod li...</td>\n",
       "      <td>Se haver um temer dar filmar , ser que o pesso...</td>\n",
       "      <td>Se haver um tema deste filme , ser que as pess...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   codigo                                              texto sentimento  \\\n",
       "0       1  Esse bocejo de pia de cozinha de orçamento mui...        neg   \n",
       "1       2  O Bravo parece indicar que o personagem princi...        neg   \n",
       "2       3  Durante a Guerra pela Independência do Sul, GE...        pos   \n",
       "3       4  É fora de questão que a verdadeira Anna Anders...        pos   \n",
       "4       5  Concordo totalmente com outro dos revisores aq...        neg   \n",
       "5       6  Obra-prima absoluta de um filme! Boa noite Mr....        pos   \n",
       "6       7  Embora a palavra megalmania seja muito usada p...        pos   \n",
       "7       8  Esta tem que ser a peça mais incrível de porca...        neg   \n",
       "8       9  Eu suponho que todas as piadas internas são o ...        neg   \n",
       "9      10  Se há um tema deste filme, é que as pessoas po...        pos   \n",
       "\n",
       "                                             stemmer  \\\n",
       "0  ess bocej de pia de co de orç muit baix é o ti...   \n",
       "1  o brav parec indic que o person principal, cla...   \n",
       "2  dur a guerr pel independ do sul, gener spanky ...   \n",
       "3  é for de quest que a verd ann anderson não era...   \n",
       "4  concord total com outr do revi aqu que fic sat...   \n",
       "5  obra-pr absolut de um filme! boa noit mr.tom r...   \n",
       "6  emb a palavr megalman sej muit us par descrev ...   \n",
       "7  est tem que ser a peç mais incr de porc cinema...   \n",
       "8  eu suponh que tod as pi intern são o que fez d...   \n",
       "9  se há um tem dest filme, é que as pesso pod li...   \n",
       "\n",
       "                                               lemma  \\\n",
       "0  Esse bocejar de pio de cozinhar de orçamentar ...   \n",
       "1  O Bravo parecer indicar que o personagem princ...   \n",
       "2  Durante o Guerra pelar Independência do Sul , ...   \n",
       "3  É ser de questão que o verdadeiro Anna Anderso...   \n",
       "4  Concordo totalmente com outro dos revisor aqui...   \n",
       "5  Obra-prima absoluto de um filmar ! Boa noite M...   \n",
       "6  Embora o palavra megalmania ser muito usar par...   \n",
       "7  Esta ter que ser o pedir mais incrível de porc...   \n",
       "8  Eu supor que todo o piar interno ser o que faz...   \n",
       "9  Se haver um temer dar filmar , ser que o pesso...   \n",
       "\n",
       "                                          lemma_verb  \n",
       "0  Esse bocejo de pia de cozinha de orçamento mui...  \n",
       "1  O Bravo parecer indicar que o personagem princ...  \n",
       "2  Durante a Guerra pela Independência do Sul , G...  \n",
       "3  É fora de questão que a verdadeira Anna Anders...  \n",
       "4  Concordo totalmente com outro dos revisores aq...  \n",
       "5  Obra-prima absoluta de um filme ! Boa noite Mr...  \n",
       "6  Embora a palavra megalmania seja muito usar pa...  \n",
       "7  Esta tem que ser a peça mais incrível de porca...  \n",
       "8  Eu supor que todas as piadas internas são o qu...  \n",
       "9  Se haver um tema deste filme , ser que as pess...  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_treino, df_teste = train_test_split(\n",
    "      df, \n",
    "      test_size = 0.2, \n",
    "      random_state = 42\n",
    "  )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CountVectorizer Texto Unigrama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "vect = CountVectorizer(ngram_range=(1,1))\n",
    "vect.fit(df_treino.texto)\n",
    "text_vect_treino = vect.transform(df_treino.texto)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree\n",
      "Acuracidade: 0.7139\n",
      "F1 Score: 0.7139\n",
      "=======================================\n",
      "Wall time: 1min 4s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "model = DecisionTreeClassifier(random_state=42)\n",
    "model.fit(text_vect_treino, df_treino.sentimento)\n",
    "\n",
    "# vetorização do dataframe de teste\n",
    "text_vect_teste = vect.transform(df_teste.texto)\n",
    "\n",
    "# escoragem da classificação na amostra de teste (textos vetorizados)\n",
    "y_predicao = model.predict(text_vect_teste)\n",
    "\n",
    "# mensuração do resultado pela acurácia\n",
    "y_teste = df_teste.sentimento\n",
    "\n",
    "accuracy = accuracy_score(df_teste.sentimento, y_predicao)\n",
    "f1score = f1_score(df_teste.sentimento, y_predicao, average='weighted')\n",
    "print(\"Decision Tree\")\n",
    "print(f\"Acuracidade: {round(accuracy,4)}\")\n",
    "print(f\"F1 Score: {round(f1score,4)}\")\n",
    "print(\"=======================================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Roberto Tengan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression\n",
      "Acuracidade: 0.8779\n",
      "F1 Score: 0.8779\n",
      "=======================================\n",
      "Wall time: 5.87 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "model = LogisticRegression(random_state=42)\n",
    "model.fit(text_vect_treino, df_treino.sentimento)\n",
    "\n",
    "# vetorização do dataframe de teste\n",
    "text_vect_teste = vect.transform(df_teste.texto)\n",
    "\n",
    "# escoragem da classificação na amostra de teste (textos vetorizados)\n",
    "y_predicao = model.predict(text_vect_teste)\n",
    "\n",
    "# mensuração do resultado pela acurácia\n",
    "y_teste = df_teste.sentimento\n",
    "accuracy = accuracy_score(df_teste.sentimento, y_predicao)\n",
    "f1score = f1_score(df_teste.sentimento, y_predicao, average='weighted')\n",
    "print(\"Logistic Regression\")\n",
    "print(f\"Acuracidade: {round(accuracy,4)}\")\n",
    "print(f\"F1 Score: {round(f1score,4)}\")\n",
    "print(\"=======================================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest\n",
      "Acuracidade: 0.8425\n",
      "F1 Score: 0.8425\n",
      "=======================================\n",
      "Wall time: 39.6 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "model = RandomForestClassifier(random_state=42, n_jobs=-1)\n",
    "model.fit(text_vect_treino, df_treino.sentimento)\n",
    "\n",
    "# vetorização do dataframe de teste\n",
    "text_vect_teste = vect.transform(df_teste.texto)\n",
    "\n",
    "# escoragem da classificação na amostra de teste (textos vetorizados)\n",
    "y_predicao = model.predict(text_vect_teste)\n",
    "\n",
    "# mensuração do resultado pela acurácia\n",
    "y_teste = df_teste.sentimento\n",
    "accuracy = accuracy_score(df_teste.sentimento, y_predicao)\n",
    "f1score = f1_score(df_teste.sentimento, y_predicao, average='weighted')\n",
    "print(\"Random Forest\")\n",
    "print(f\"Acuracidade: {round(accuracy,4)}\")\n",
    "print(f\"F1 Score: {round(f1score,4)}\")\n",
    "print(\"=======================================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multinomial NB\n",
      "Acuracidade: 0.8581\n",
      "F1 Score: 0.858\n",
      "=======================================\n",
      "Wall time: 1.56 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "model = MultinomialNB()\n",
    "model.fit(text_vect_treino, df_treino.sentimento)\n",
    "\n",
    "# vetorização do dataframe de teste\n",
    "text_vect_teste = vect.transform(df_teste.texto)\n",
    "\n",
    "# escoragem da classificação na amostra de teste (textos vetorizados)\n",
    "y_predicao = model.predict(text_vect_teste)\n",
    "\n",
    "# mensuração do resultado pela acurácia\n",
    "y_teste = df_teste.sentimento\n",
    "\n",
    "accuracy = accuracy_score(df_teste.sentimento, y_predicao)\n",
    "f1score = f1_score(df_teste.sentimento, y_predicao, average='weighted')\n",
    "print(\"Multinomial NB\")\n",
    "print(f\"Acuracidade: {round(accuracy,4)}\")\n",
    "print(f\"F1 Score: {round(f1score,4)}\")\n",
    "print(\"=======================================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bernoulli NB\n",
      "Acuracidade: 0.8606\n",
      "F1 Score: 0.8606\n",
      "=======================================\n",
      "Wall time: 1.56 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "model = BernoulliNB()\n",
    "model.fit(text_vect_treino, df_treino.sentimento)\n",
    "\n",
    "# vetorização do dataframe de teste\n",
    "text_vect_teste = vect.transform(df_teste.texto)\n",
    "\n",
    "# escoragem da classificação na amostra de teste (textos vetorizados)\n",
    "y_predicao = model.predict(text_vect_teste)\n",
    "\n",
    "# mensuração do resultado pela acurácia\n",
    "y_teste = df_teste.sentimento\n",
    "\n",
    "accuracy = accuracy_score(df_teste.sentimento, y_predicao)\n",
    "f1score = f1_score(df_teste.sentimento, y_predicao, average='weighted')\n",
    "print(\"Bernoulli NB\")\n",
    "print(f\"Acuracidade: {round(accuracy,4)}\")\n",
    "print(f\"F1 Score: {round(f1score,4)}\")\n",
    "print(\"=======================================\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CountVectorizer Texto Bigrama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "vect = CountVectorizer(ngram_range=(2,2))\n",
    "vect.fit(df_treino.texto)\n",
    "text_vect_treino = vect.transform(df_treino.texto)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree\n",
      "Acuracidade: 0.6856\n",
      "F1 Score: 0.6856\n",
      "=======================================\n",
      "Wall time: 6min 50s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "model = DecisionTreeClassifier(random_state=42)\n",
    "model.fit(text_vect_treino, df_treino.sentimento)\n",
    "\n",
    "# vetorização do dataframe de teste\n",
    "text_vect_teste = vect.transform(df_teste.texto)\n",
    "\n",
    "# escoragem da classificação na amostra de teste (textos vetorizados)\n",
    "y_predicao = model.predict(text_vect_teste)\n",
    "\n",
    "# mensuração do resultado pela acurácia\n",
    "y_teste = df_teste.sentimento\n",
    "\n",
    "accuracy = accuracy_score(df_teste.sentimento, y_predicao)\n",
    "f1score = f1_score(df_teste.sentimento, y_predicao, average='weighted')\n",
    "print(\"Decision Tree\")\n",
    "print(f\"Acuracidade: {round(accuracy,4)}\")\n",
    "print(f\"F1 Score: {round(f1score,4)}\")\n",
    "print(\"=======================================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Roberto Tengan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression\n",
      "Acuracidade: 0.8814\n",
      "F1 Score: 0.8814\n",
      "=======================================\n",
      "Wall time: 47.6 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "model = LogisticRegression(random_state=42)\n",
    "model.fit(text_vect_treino, df_treino.sentimento)\n",
    "\n",
    "# vetorização do dataframe de teste\n",
    "text_vect_teste = vect.transform(df_teste.texto)\n",
    "\n",
    "# escoragem da classificação na amostra de teste (textos vetorizados)\n",
    "y_predicao = model.predict(text_vect_teste)\n",
    "\n",
    "# mensuração do resultado pela acurácia\n",
    "y_teste = df_teste.sentimento\n",
    "accuracy = accuracy_score(df_teste.sentimento, y_predicao)\n",
    "f1score = f1_score(df_teste.sentimento, y_predicao, average='weighted')\n",
    "print(\"Logistic Regression\")\n",
    "print(f\"Acuracidade: {round(accuracy,4)}\")\n",
    "print(f\"F1 Score: {round(f1score,4)}\")\n",
    "print(\"=======================================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest\n",
      "Acuracidade: 0.8253\n",
      "F1 Score: 0.8253\n",
      "=======================================\n",
      "Wall time: 8min 53s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "model = RandomForestClassifier(random_state=42, n_jobs=-1)\n",
    "model.fit(text_vect_treino, df_treino.sentimento)\n",
    "\n",
    "# vetorização do dataframe de teste\n",
    "text_vect_teste = vect.transform(df_teste.texto)\n",
    "\n",
    "# escoragem da classificação na amostra de teste (textos vetorizados)\n",
    "y_predicao = model.predict(text_vect_teste)\n",
    "\n",
    "# mensuração do resultado pela acurácia\n",
    "y_teste = df_teste.sentimento\n",
    "accuracy = accuracy_score(df_teste.sentimento, y_predicao)\n",
    "f1score = f1_score(df_teste.sentimento, y_predicao, average='weighted')\n",
    "print(\"Random Forest\")\n",
    "print(f\"Acuracidade: {round(accuracy,4)}\")\n",
    "print(f\"F1 Score: {round(f1score,4)}\")\n",
    "print(\"=======================================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multinomial NB\n",
      "Acuracidade: 0.8842\n",
      "F1 Score: 0.8841\n",
      "=======================================\n",
      "Wall time: 2.52 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "model = MultinomialNB()\n",
    "model.fit(text_vect_treino, df_treino.sentimento)\n",
    "\n",
    "# vetorização do dataframe de teste\n",
    "text_vect_teste = vect.transform(df_teste.texto)\n",
    "\n",
    "# escoragem da classificação na amostra de teste (textos vetorizados)\n",
    "y_predicao = model.predict(text_vect_teste)\n",
    "\n",
    "# mensuração do resultado pela acurácia\n",
    "y_teste = df_teste.sentimento\n",
    "\n",
    "accuracy = accuracy_score(df_teste.sentimento, y_predicao)\n",
    "f1score = f1_score(df_teste.sentimento, y_predicao, average='weighted')\n",
    "print(\"Multinomial NB\")\n",
    "print(f\"Acuracidade: {round(accuracy,4)}\")\n",
    "print(f\"F1 Score: {round(f1score,4)}\")\n",
    "print(\"=======================================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bernoulli NB\n",
      "Acuracidade: 0.8837\n",
      "F1 Score: 0.8836\n",
      "=======================================\n",
      "Wall time: 2.61 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "model = BernoulliNB()\n",
    "model.fit(text_vect_treino, df_treino.sentimento)\n",
    "\n",
    "# vetorização do dataframe de teste\n",
    "text_vect_teste = vect.transform(df_teste.texto)\n",
    "\n",
    "# escoragem da classificação na amostra de teste (textos vetorizados)\n",
    "y_predicao = model.predict(text_vect_teste)\n",
    "\n",
    "# mensuração do resultado pela acurácia\n",
    "y_teste = df_teste.sentimento\n",
    "\n",
    "accuracy = accuracy_score(df_teste.sentimento, y_predicao)\n",
    "f1score = f1_score(df_teste.sentimento, y_predicao, average='weighted')\n",
    "print(\"Bernoulli NB\")\n",
    "print(f\"Acuracidade: {round(accuracy,4)}\")\n",
    "print(f\"F1 Score: {round(f1score,4)}\")\n",
    "print(\"=======================================\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CountVectorizer Texto Unigrama - Bigrama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "vect = CountVectorizer(ngram_range=(1,2))\n",
    "vect.fit(df_treino.texto)\n",
    "text_vect_treino = vect.transform(df_treino.texto)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree\n",
      "Acuracidade: 0.724\n",
      "F1 Score: 0.724\n",
      "=======================================\n",
      "Wall time: 6min 31s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "model = DecisionTreeClassifier(random_state=42)\n",
    "model.fit(text_vect_treino, df_treino.sentimento)\n",
    "\n",
    "# vetorização do dataframe de teste\n",
    "text_vect_teste = vect.transform(df_teste.texto)\n",
    "\n",
    "# escoragem da classificação na amostra de teste (textos vetorizados)\n",
    "y_predicao = model.predict(text_vect_teste)\n",
    "\n",
    "# mensuração do resultado pela acurácia\n",
    "y_teste = df_teste.sentimento\n",
    "\n",
    "accuracy = accuracy_score(df_teste.sentimento, y_predicao)\n",
    "f1score = f1_score(df_teste.sentimento, y_predicao, average='weighted')\n",
    "print(\"Decision Tree\")\n",
    "print(f\"Acuracidade: {round(accuracy,4)}\")\n",
    "print(f\"F1 Score: {round(f1score,4)}\")\n",
    "print(\"=======================================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Roberto Tengan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression\n",
      "Acuracidade: 0.8975\n",
      "F1 Score: 0.8974\n",
      "=======================================\n",
      "Wall time: 57.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "model = LogisticRegression(random_state=42)\n",
    "model.fit(text_vect_treino, df_treino.sentimento)\n",
    "\n",
    "# vetorização do dataframe de teste\n",
    "text_vect_teste = vect.transform(df_teste.texto)\n",
    "\n",
    "# escoragem da classificação na amostra de teste (textos vetorizados)\n",
    "y_predicao = model.predict(text_vect_teste)\n",
    "\n",
    "# mensuração do resultado pela acurácia\n",
    "y_teste = df_teste.sentimento\n",
    "accuracy = accuracy_score(df_teste.sentimento, y_predicao)\n",
    "f1score = f1_score(df_teste.sentimento, y_predicao, average='weighted')\n",
    "print(\"Logistic Regression\")\n",
    "print(f\"Acuracidade: {round(accuracy,4)}\")\n",
    "print(f\"F1 Score: {round(f1score,4)}\")\n",
    "print(\"=======================================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest\n",
      "Acuracidade: 0.8485\n",
      "F1 Score: 0.8485\n",
      "=======================================\n",
      "Wall time: 6min 3s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "model = RandomForestClassifier(random_state=42, n_jobs=-1)\n",
    "model.fit(text_vect_treino, df_treino.sentimento)\n",
    "\n",
    "# vetorização do dataframe de teste\n",
    "text_vect_teste = vect.transform(df_teste.texto)\n",
    "\n",
    "# escoragem da classificação na amostra de teste (textos vetorizados)\n",
    "y_predicao = model.predict(text_vect_teste)\n",
    "\n",
    "# mensuração do resultado pela acurácia\n",
    "y_teste = df_teste.sentimento\n",
    "accuracy = accuracy_score(df_teste.sentimento, y_predicao)\n",
    "f1score = f1_score(df_teste.sentimento, y_predicao, average='weighted')\n",
    "print(\"Random Forest\")\n",
    "print(f\"Acuracidade: {round(accuracy,4)}\")\n",
    "print(f\"F1 Score: {round(f1score,4)}\")\n",
    "print(\"=======================================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multinomial NB\n",
      "Acuracidade: 0.8843\n",
      "F1 Score: 0.8842\n",
      "=======================================\n",
      "Wall time: 3.33 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "model = MultinomialNB()\n",
    "model.fit(text_vect_treino, df_treino.sentimento)\n",
    "\n",
    "# vetorização do dataframe de teste\n",
    "text_vect_teste = vect.transform(df_teste.texto)\n",
    "\n",
    "# escoragem da classificação na amostra de teste (textos vetorizados)\n",
    "y_predicao = model.predict(text_vect_teste)\n",
    "\n",
    "# mensuração do resultado pela acurácia\n",
    "y_teste = df_teste.sentimento\n",
    "\n",
    "accuracy = accuracy_score(df_teste.sentimento, y_predicao)\n",
    "f1score = f1_score(df_teste.sentimento, y_predicao, average='weighted')\n",
    "print(\"Multinomial NB\")\n",
    "print(f\"Acuracidade: {round(accuracy,4)}\")\n",
    "print(f\"F1 Score: {round(f1score,4)}\")\n",
    "print(\"=======================================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bernoulli NB\n",
      "Acuracidade: 0.8814\n",
      "F1 Score: 0.8813\n",
      "=======================================\n",
      "Wall time: 3.52 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "model = BernoulliNB()\n",
    "model.fit(text_vect_treino, df_treino.sentimento)\n",
    "\n",
    "# vetorização do dataframe de teste\n",
    "text_vect_teste = vect.transform(df_teste.texto)\n",
    "\n",
    "# escoragem da classificação na amostra de teste (textos vetorizados)\n",
    "y_predicao = model.predict(text_vect_teste)\n",
    "\n",
    "# mensuração do resultado pela acurácia\n",
    "y_teste = df_teste.sentimento\n",
    "\n",
    "accuracy = accuracy_score(df_teste.sentimento, y_predicao)\n",
    "f1score = f1_score(df_teste.sentimento, y_predicao, average='weighted')\n",
    "print(\"Bernoulli NB\")\n",
    "print(f\"Acuracidade: {round(accuracy,4)}\")\n",
    "print(f\"F1 Score: {round(f1score,4)}\")\n",
    "print(\"=======================================\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CountVectorizer Texto / Unigrama / MindF = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "vect = CountVectorizer(ngram_range=(1,1), min_df=10)\n",
    "vect.fit(df_treino.texto)\n",
    "text_vect_treino = vect.transform(df_treino.texto)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree\n",
      "Acuracidade: 0.7081\n",
      "F1 Score: 0.7081\n",
      "=======================================\n",
      "Wall time: 56.6 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "model = DecisionTreeClassifier(random_state=42)\n",
    "model.fit(text_vect_treino, df_treino.sentimento)\n",
    "\n",
    "# vetorização do dataframe de teste\n",
    "text_vect_teste = vect.transform(df_teste.texto)\n",
    "\n",
    "# escoragem da classificação na amostra de teste (textos vetorizados)\n",
    "y_predicao = model.predict(text_vect_teste)\n",
    "\n",
    "# mensuração do resultado pela acurácia\n",
    "y_teste = df_teste.sentimento\n",
    "\n",
    "accuracy = accuracy_score(df_teste.sentimento, y_predicao)\n",
    "f1score = f1_score(df_teste.sentimento, y_predicao, average='weighted')\n",
    "print(\"Decision Tree\")\n",
    "print(f\"Acuracidade: {round(accuracy,4)}\")\n",
    "print(f\"F1 Score: {round(f1score,4)}\")\n",
    "print(\"=======================================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Roberto Tengan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression\n",
      "Acuracidade: 0.8788\n",
      "F1 Score: 0.8788\n",
      "=======================================\n",
      "Wall time: 3.95 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "model = LogisticRegression(random_state=42)\n",
    "model.fit(text_vect_treino, df_treino.sentimento)\n",
    "\n",
    "# vetorização do dataframe de teste\n",
    "text_vect_teste = vect.transform(df_teste.texto)\n",
    "\n",
    "# escoragem da classificação na amostra de teste (textos vetorizados)\n",
    "y_predicao = model.predict(text_vect_teste)\n",
    "\n",
    "# mensuração do resultado pela acurácia\n",
    "y_teste = df_teste.sentimento\n",
    "accuracy = accuracy_score(df_teste.sentimento, y_predicao)\n",
    "f1score = f1_score(df_teste.sentimento, y_predicao, average='weighted')\n",
    "print(\"Logistic Regression\")\n",
    "print(f\"Acuracidade: {round(accuracy,4)}\")\n",
    "print(f\"F1 Score: {round(f1score,4)}\")\n",
    "print(\"=======================================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest\n",
      "Acuracidade: 0.8387\n",
      "F1 Score: 0.8387\n",
      "=======================================\n",
      "Wall time: 32.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "model = RandomForestClassifier(random_state=42, n_jobs=-1)\n",
    "model.fit(text_vect_treino, df_treino.sentimento)\n",
    "\n",
    "# vetorização do dataframe de teste\n",
    "text_vect_teste = vect.transform(df_teste.texto)\n",
    "\n",
    "# escoragem da classificação na amostra de teste (textos vetorizados)\n",
    "y_predicao = model.predict(text_vect_teste)\n",
    "\n",
    "# mensuração do resultado pela acurácia\n",
    "y_teste = df_teste.sentimento\n",
    "accuracy = accuracy_score(df_teste.sentimento, y_predicao)\n",
    "f1score = f1_score(df_teste.sentimento, y_predicao, average='weighted')\n",
    "print(\"Random Forest\")\n",
    "print(f\"Acuracidade: {round(accuracy,4)}\")\n",
    "print(f\"F1 Score: {round(f1score,4)}\")\n",
    "print(\"=======================================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multinomial NB\n",
      "Acuracidade: 0.8517\n",
      "F1 Score: 0.8517\n",
      "=======================================\n",
      "Wall time: 1.55 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "model = MultinomialNB()\n",
    "model.fit(text_vect_treino, df_treino.sentimento)\n",
    "\n",
    "# vetorização do dataframe de teste\n",
    "text_vect_teste = vect.transform(df_teste.texto)\n",
    "\n",
    "# escoragem da classificação na amostra de teste (textos vetorizados)\n",
    "y_predicao = model.predict(text_vect_teste)\n",
    "\n",
    "# mensuração do resultado pela acurácia\n",
    "y_teste = df_teste.sentimento\n",
    "\n",
    "accuracy = accuracy_score(df_teste.sentimento, y_predicao)\n",
    "f1score = f1_score(df_teste.sentimento, y_predicao, average='weighted')\n",
    "print(\"Multinomial NB\")\n",
    "print(f\"Acuracidade: {round(accuracy,4)}\")\n",
    "print(f\"F1 Score: {round(f1score,4)}\")\n",
    "print(\"=======================================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bernoulli NB\n",
      "Acuracidade: 0.8563\n",
      "F1 Score: 0.8563\n",
      "=======================================\n",
      "Wall time: 1.52 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "model = BernoulliNB()\n",
    "model.fit(text_vect_treino, df_treino.sentimento)\n",
    "\n",
    "# vetorização do dataframe de teste\n",
    "text_vect_teste = vect.transform(df_teste.texto)\n",
    "\n",
    "# escoragem da classificação na amostra de teste (textos vetorizados)\n",
    "y_predicao = model.predict(text_vect_teste)\n",
    "\n",
    "# mensuração do resultado pela acurácia\n",
    "y_teste = df_teste.sentimento\n",
    "\n",
    "accuracy = accuracy_score(df_teste.sentimento, y_predicao)\n",
    "f1score = f1_score(df_teste.sentimento, y_predicao, average='weighted')\n",
    "print(\"Bernoulli NB\")\n",
    "print(f\"Acuracidade: {round(accuracy,4)}\")\n",
    "print(f\"F1 Score: {round(f1score,4)}\")\n",
    "print(\"=======================================\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CountVectorizer Texto / Bigrama / MindF = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "vect = CountVectorizer(ngram_range=(2,2), min_df=10)\n",
    "vect.fit(df_treino.texto)\n",
    "text_vect_treino = vect.transform(df_treino.texto)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree\n",
      "Acuracidade: 0.6857\n",
      "F1 Score: 0.6857\n",
      "=======================================\n",
      "Wall time: 1min 10s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "model = DecisionTreeClassifier(random_state=42)\n",
    "model.fit(text_vect_treino, df_treino.sentimento)\n",
    "\n",
    "# vetorização do dataframe de teste\n",
    "text_vect_teste = vect.transform(df_teste.texto)\n",
    "\n",
    "# escoragem da classificação na amostra de teste (textos vetorizados)\n",
    "y_predicao = model.predict(text_vect_teste)\n",
    "\n",
    "# mensuração do resultado pela acurácia\n",
    "y_teste = df_teste.sentimento\n",
    "\n",
    "accuracy = accuracy_score(df_teste.sentimento, y_predicao)\n",
    "f1score = f1_score(df_teste.sentimento, y_predicao, average='weighted')\n",
    "print(\"Decision Tree\")\n",
    "print(f\"Acuracidade: {round(accuracy,4)}\")\n",
    "print(f\"F1 Score: {round(f1score,4)}\")\n",
    "print(\"=======================================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Roberto Tengan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression\n",
      "Acuracidade: 0.8732\n",
      "F1 Score: 0.8732\n",
      "=======================================\n",
      "Wall time: 7.61 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "model = LogisticRegression(random_state=42)\n",
    "model.fit(text_vect_treino, df_treino.sentimento)\n",
    "\n",
    "# vetorização do dataframe de teste\n",
    "text_vect_teste = vect.transform(df_teste.texto)\n",
    "\n",
    "# escoragem da classificação na amostra de teste (textos vetorizados)\n",
    "y_predicao = model.predict(text_vect_teste)\n",
    "\n",
    "# mensuração do resultado pela acurácia\n",
    "y_teste = df_teste.sentimento\n",
    "accuracy = accuracy_score(df_teste.sentimento, y_predicao)\n",
    "f1score = f1_score(df_teste.sentimento, y_predicao, average='weighted')\n",
    "print(\"Logistic Regression\")\n",
    "print(f\"Acuracidade: {round(accuracy,4)}\")\n",
    "print(f\"F1 Score: {round(f1score,4)}\")\n",
    "print(\"=======================================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest\n",
      "Acuracidade: 0.8217\n",
      "F1 Score: 0.8215\n",
      "=======================================\n",
      "Wall time: 38 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "model = RandomForestClassifier(random_state=42, n_jobs=-1)\n",
    "model.fit(text_vect_treino, df_treino.sentimento)\n",
    "\n",
    "# vetorização do dataframe de teste\n",
    "text_vect_teste = vect.transform(df_teste.texto)\n",
    "\n",
    "# escoragem da classificação na amostra de teste (textos vetorizados)\n",
    "y_predicao = model.predict(text_vect_teste)\n",
    "\n",
    "# mensuração do resultado pela acurácia\n",
    "y_teste = df_teste.sentimento\n",
    "accuracy = accuracy_score(df_teste.sentimento, y_predicao)\n",
    "f1score = f1_score(df_teste.sentimento, y_predicao, average='weighted')\n",
    "print(\"Random Forest\")\n",
    "print(f\"Acuracidade: {round(accuracy,4)}\")\n",
    "print(f\"F1 Score: {round(f1score,4)}\")\n",
    "print(\"=======================================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multinomial NB\n",
      "Acuracidade: 0.8786\n",
      "F1 Score: 0.8786\n",
      "=======================================\n",
      "Wall time: 3.05 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "model = MultinomialNB()\n",
    "model.fit(text_vect_treino, df_treino.sentimento)\n",
    "\n",
    "# vetorização do dataframe de teste\n",
    "text_vect_teste = vect.transform(df_teste.texto)\n",
    "\n",
    "# escoragem da classificação na amostra de teste (textos vetorizados)\n",
    "y_predicao = model.predict(text_vect_teste)\n",
    "\n",
    "# mensuração do resultado pela acurácia\n",
    "y_teste = df_teste.sentimento\n",
    "\n",
    "accuracy = accuracy_score(df_teste.sentimento, y_predicao)\n",
    "f1score = f1_score(df_teste.sentimento, y_predicao, average='weighted')\n",
    "print(\"Multinomial NB\")\n",
    "print(f\"Acuracidade: {round(accuracy,4)}\")\n",
    "print(f\"F1 Score: {round(f1score,4)}\")\n",
    "print(\"=======================================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bernoulli NB\n",
      "Acuracidade: 0.8726\n",
      "F1 Score: 0.8725\n",
      "=======================================\n",
      "Wall time: 3.22 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "model = BernoulliNB()\n",
    "model.fit(text_vect_treino, df_treino.sentimento)\n",
    "\n",
    "# vetorização do dataframe de teste\n",
    "text_vect_teste = vect.transform(df_teste.texto)\n",
    "\n",
    "# escoragem da classificação na amostra de teste (textos vetorizados)\n",
    "y_predicao = model.predict(text_vect_teste)\n",
    "\n",
    "# mensuração do resultado pela acurácia\n",
    "y_teste = df_teste.sentimento\n",
    "\n",
    "accuracy = accuracy_score(df_teste.sentimento, y_predicao)\n",
    "f1score = f1_score(df_teste.sentimento, y_predicao, average='weighted')\n",
    "print(\"Bernoulli NB\")\n",
    "print(f\"Acuracidade: {round(accuracy,4)}\")\n",
    "print(f\"F1 Score: {round(f1score,4)}\")\n",
    "print(\"=======================================\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CountVectorizer Texto / Unigrama - Bigrama / MindF = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "vect = CountVectorizer(ngram_range=(1,2), min_df=10)\n",
    "vect.fit(df_treino.texto)\n",
    "text_vect_treino = vect.transform(df_treino.texto)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree\n",
      "Acuracidade: 0.7155\n",
      "F1 Score: 0.7155\n",
      "=======================================\n",
      "Wall time: 1min 52s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "model = DecisionTreeClassifier(random_state=42)\n",
    "model.fit(text_vect_treino, df_treino.sentimento)\n",
    "\n",
    "# vetorização do dataframe de teste\n",
    "text_vect_teste = vect.transform(df_teste.texto)\n",
    "\n",
    "# escoragem da classificação na amostra de teste (textos vetorizados)\n",
    "y_predicao = model.predict(text_vect_teste)\n",
    "\n",
    "# mensuração do resultado pela acurácia\n",
    "y_teste = df_teste.sentimento\n",
    "\n",
    "accuracy = accuracy_score(df_teste.sentimento, y_predicao)\n",
    "f1score = f1_score(df_teste.sentimento, y_predicao, average='weighted')\n",
    "print(\"Decision Tree\")\n",
    "print(f\"Acuracidade: {round(accuracy,4)}\")\n",
    "print(f\"F1 Score: {round(f1score,4)}\")\n",
    "print(\"=======================================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Roberto Tengan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression\n",
      "Acuracidade: 0.8922\n",
      "F1 Score: 0.8922\n",
      "=======================================\n",
      "Wall time: 8.9 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "model = LogisticRegression(random_state=42)\n",
    "model.fit(text_vect_treino, df_treino.sentimento)\n",
    "\n",
    "# vetorização do dataframe de teste\n",
    "text_vect_teste = vect.transform(df_teste.texto)\n",
    "\n",
    "# escoragem da classificação na amostra de teste (textos vetorizados)\n",
    "y_predicao = model.predict(text_vect_teste)\n",
    "\n",
    "# mensuração do resultado pela acurácia\n",
    "y_teste = df_teste.sentimento\n",
    "accuracy = accuracy_score(df_teste.sentimento, y_predicao)\n",
    "f1score = f1_score(df_teste.sentimento, y_predicao, average='weighted')\n",
    "print(\"Logistic Regression\")\n",
    "print(f\"Acuracidade: {round(accuracy,4)}\")\n",
    "print(f\"F1 Score: {round(f1score,4)}\")\n",
    "print(\"=======================================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest\n",
      "Acuracidade: 0.8516\n",
      "F1 Score: 0.8516\n",
      "=======================================\n",
      "Wall time: 44.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "model = RandomForestClassifier(random_state=42, n_jobs=-1)\n",
    "model.fit(text_vect_treino, df_treino.sentimento)\n",
    "\n",
    "# vetorização do dataframe de teste\n",
    "text_vect_teste = vect.transform(df_teste.texto)\n",
    "\n",
    "# escoragem da classificação na amostra de teste (textos vetorizados)\n",
    "y_predicao = model.predict(text_vect_teste)\n",
    "\n",
    "# mensuração do resultado pela acurácia\n",
    "y_teste = df_teste.sentimento\n",
    "accuracy = accuracy_score(df_teste.sentimento, y_predicao)\n",
    "f1score = f1_score(df_teste.sentimento, y_predicao, average='weighted')\n",
    "print(\"Random Forest\")\n",
    "print(f\"Acuracidade: {round(accuracy,4)}\")\n",
    "print(f\"F1 Score: {round(f1score,4)}\")\n",
    "print(\"=======================================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multinomial NB\n",
      "Acuracidade: 0.8761\n",
      "F1 Score: 0.8761\n",
      "=======================================\n",
      "Wall time: 2.86 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "model = MultinomialNB()\n",
    "model.fit(text_vect_treino, df_treino.sentimento)\n",
    "\n",
    "# vetorização do dataframe de teste\n",
    "text_vect_teste = vect.transform(df_teste.texto)\n",
    "\n",
    "# escoragem da classificação na amostra de teste (textos vetorizados)\n",
    "y_predicao = model.predict(text_vect_teste)\n",
    "\n",
    "# mensuração do resultado pela acurácia\n",
    "y_teste = df_teste.sentimento\n",
    "\n",
    "accuracy = accuracy_score(df_teste.sentimento, y_predicao)\n",
    "f1score = f1_score(df_teste.sentimento, y_predicao, average='weighted')\n",
    "print(\"Multinomial NB\")\n",
    "print(f\"Acuracidade: {round(accuracy,4)}\")\n",
    "print(f\"F1 Score: {round(f1score,4)}\")\n",
    "print(\"=======================================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bernoulli NB\n",
      "Acuracidade: 0.877\n",
      "F1 Score: 0.877\n",
      "=======================================\n",
      "Wall time: 3.04 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "model = BernoulliNB()\n",
    "model.fit(text_vect_treino, df_treino.sentimento)\n",
    "\n",
    "# vetorização do dataframe de teste\n",
    "text_vect_teste = vect.transform(df_teste.texto)\n",
    "\n",
    "# escoragem da classificação na amostra de teste (textos vetorizados)\n",
    "y_predicao = model.predict(text_vect_teste)\n",
    "\n",
    "# mensuração do resultado pela acurácia\n",
    "y_teste = df_teste.sentimento\n",
    "\n",
    "accuracy = accuracy_score(df_teste.sentimento, y_predicao)\n",
    "f1score = f1_score(df_teste.sentimento, y_predicao, average='weighted')\n",
    "print(\"Bernoulli NB\")\n",
    "print(f\"Acuracidade: {round(accuracy,4)}\")\n",
    "print(f\"F1 Score: {round(f1score,4)}\")\n",
    "print(\"=======================================\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CountVectorizer Texto / Unigrama / MindF = 10 / token_pattern = Palavras com mais de 3 letras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "vect = CountVectorizer(ngram_range=(1,1), min_df=10, token_pattern='[a-zA-Z0-9]{3,}')\n",
    "vect.fit(df_treino.texto)\n",
    "text_vect_treino = vect.transform(df_treino.texto)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree\n",
      "Acuracidade: 0.7163\n",
      "F1 Score: 0.7163\n",
      "=======================================\n",
      "Wall time: 52.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "model = DecisionTreeClassifier(random_state=42)\n",
    "model.fit(text_vect_treino, df_treino.sentimento)\n",
    "\n",
    "# vetorização do dataframe de teste\n",
    "text_vect_teste = vect.transform(df_teste.texto)\n",
    "\n",
    "# escoragem da classificação na amostra de teste (textos vetorizados)\n",
    "y_predicao = model.predict(text_vect_teste)\n",
    "\n",
    "# mensuração do resultado pela acurácia\n",
    "y_teste = df_teste.sentimento\n",
    "\n",
    "accuracy = accuracy_score(df_teste.sentimento, y_predicao)\n",
    "f1score = f1_score(df_teste.sentimento, y_predicao, average='weighted')\n",
    "print(\"Decision Tree\")\n",
    "print(f\"Acuracidade: {round(accuracy,4)}\")\n",
    "print(f\"F1 Score: {round(f1score,4)}\")\n",
    "print(\"=======================================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Roberto Tengan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression\n",
      "Acuracidade: 0.8706\n",
      "F1 Score: 0.8706\n",
      "=======================================\n",
      "Wall time: 3.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "model = LogisticRegression(random_state=42)\n",
    "model.fit(text_vect_treino, df_treino.sentimento)\n",
    "\n",
    "# vetorização do dataframe de teste\n",
    "text_vect_teste = vect.transform(df_teste.texto)\n",
    "\n",
    "# escoragem da classificação na amostra de teste (textos vetorizados)\n",
    "y_predicao = model.predict(text_vect_teste)\n",
    "\n",
    "# mensuração do resultado pela acurácia\n",
    "y_teste = df_teste.sentimento\n",
    "accuracy = accuracy_score(df_teste.sentimento, y_predicao)\n",
    "f1score = f1_score(df_teste.sentimento, y_predicao, average='weighted')\n",
    "print(\"Logistic Regression\")\n",
    "print(f\"Acuracidade: {round(accuracy,4)}\")\n",
    "print(f\"F1 Score: {round(f1score,4)}\")\n",
    "print(\"=======================================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest\n",
      "Acuracidade: 0.8421\n",
      "F1 Score: 0.8421\n",
      "=======================================\n",
      "Wall time: 32.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "model = RandomForestClassifier(random_state=42, n_jobs=-1)\n",
    "model.fit(text_vect_treino, df_treino.sentimento)\n",
    "\n",
    "# vetorização do dataframe de teste\n",
    "text_vect_teste = vect.transform(df_teste.texto)\n",
    "\n",
    "# escoragem da classificação na amostra de teste (textos vetorizados)\n",
    "y_predicao = model.predict(text_vect_teste)\n",
    "\n",
    "# mensuração do resultado pela acurácia\n",
    "y_teste = df_teste.sentimento\n",
    "accuracy = accuracy_score(df_teste.sentimento, y_predicao)\n",
    "f1score = f1_score(df_teste.sentimento, y_predicao, average='weighted')\n",
    "print(\"Random Forest\")\n",
    "print(f\"Acuracidade: {round(accuracy,4)}\")\n",
    "print(f\"F1 Score: {round(f1score,4)}\")\n",
    "print(\"=======================================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multinomial NB\n",
      "Acuracidade: 0.8505\n",
      "F1 Score: 0.8504\n",
      "=======================================\n",
      "Wall time: 1.28 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "model = MultinomialNB()\n",
    "model.fit(text_vect_treino, df_treino.sentimento)\n",
    "\n",
    "# vetorização do dataframe de teste\n",
    "text_vect_teste = vect.transform(df_teste.texto)\n",
    "\n",
    "# escoragem da classificação na amostra de teste (textos vetorizados)\n",
    "y_predicao = model.predict(text_vect_teste)\n",
    "\n",
    "# mensuração do resultado pela acurácia\n",
    "y_teste = df_teste.sentimento\n",
    "\n",
    "accuracy = accuracy_score(df_teste.sentimento, y_predicao)\n",
    "f1score = f1_score(df_teste.sentimento, y_predicao, average='weighted')\n",
    "print(\"Multinomial NB\")\n",
    "print(f\"Acuracidade: {round(accuracy,4)}\")\n",
    "print(f\"F1 Score: {round(f1score,4)}\")\n",
    "print(\"=======================================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bernoulli NB\n",
      "Acuracidade: 0.8541\n",
      "F1 Score: 0.8541\n",
      "=======================================\n",
      "Wall time: 1.27 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "model = BernoulliNB()\n",
    "model.fit(text_vect_treino, df_treino.sentimento)\n",
    "\n",
    "# vetorização do dataframe de teste\n",
    "text_vect_teste = vect.transform(df_teste.texto)\n",
    "\n",
    "# escoragem da classificação na amostra de teste (textos vetorizados)\n",
    "y_predicao = model.predict(text_vect_teste)\n",
    "\n",
    "# mensuração do resultado pela acurácia\n",
    "y_teste = df_teste.sentimento\n",
    "\n",
    "accuracy = accuracy_score(df_teste.sentimento, y_predicao)\n",
    "f1score = f1_score(df_teste.sentimento, y_predicao, average='weighted')\n",
    "print(\"Bernoulli NB\")\n",
    "print(f\"Acuracidade: {round(accuracy,4)}\")\n",
    "print(f\"F1 Score: {round(f1score,4)}\")\n",
    "print(\"=======================================\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CountVectorizer Texto / Bigrama / MindF = 10 / token_pattern = Palavras com mais de 3 letras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "vect = CountVectorizer(ngram_range=(2,2), min_df=10, token_pattern='[a-zA-Z0-9]{3,}')\n",
    "vect.fit(df_treino.texto)\n",
    "text_vect_treino = vect.transform(df_treino.texto)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree\n",
      "Acuracidade: 0.7128\n",
      "F1 Score: 0.7128\n",
      "=======================================\n",
      "Wall time: 50.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "model = DecisionTreeClassifier(random_state=42)\n",
    "model.fit(text_vect_treino, df_treino.sentimento)\n",
    "\n",
    "# vetorização do dataframe de teste\n",
    "text_vect_teste = vect.transform(df_teste.texto)\n",
    "\n",
    "# escoragem da classificação na amostra de teste (textos vetorizados)\n",
    "y_predicao = model.predict(text_vect_teste)\n",
    "\n",
    "# mensuração do resultado pela acurácia\n",
    "y_teste = df_teste.sentimento\n",
    "\n",
    "accuracy = accuracy_score(df_teste.sentimento, y_predicao)\n",
    "f1score = f1_score(df_teste.sentimento, y_predicao, average='weighted')\n",
    "print(\"Decision Tree\")\n",
    "print(f\"Acuracidade: {round(accuracy,4)}\")\n",
    "print(f\"F1 Score: {round(f1score,4)}\")\n",
    "print(\"=======================================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Roberto Tengan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression\n",
      "Acuracidade: 0.8661\n",
      "F1 Score: 0.8661\n",
      "=======================================\n",
      "Wall time: 4.16 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "model = LogisticRegression(random_state=42)\n",
    "model.fit(text_vect_treino, df_treino.sentimento)\n",
    "\n",
    "# vetorização do dataframe de teste\n",
    "text_vect_teste = vect.transform(df_teste.texto)\n",
    "\n",
    "# escoragem da classificação na amostra de teste (textos vetorizados)\n",
    "y_predicao = model.predict(text_vect_teste)\n",
    "\n",
    "# mensuração do resultado pela acurácia\n",
    "y_teste = df_teste.sentimento\n",
    "accuracy = accuracy_score(df_teste.sentimento, y_predicao)\n",
    "f1score = f1_score(df_teste.sentimento, y_predicao, average='weighted')\n",
    "print(\"Logistic Regression\")\n",
    "print(f\"Acuracidade: {round(accuracy,4)}\")\n",
    "print(f\"F1 Score: {round(f1score,4)}\")\n",
    "print(\"=======================================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest\n",
      "Acuracidade: 0.824\n",
      "F1 Score: 0.8239\n",
      "=======================================\n",
      "Wall time: 29.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "model = RandomForestClassifier(random_state=42, n_jobs=-1)\n",
    "model.fit(text_vect_treino, df_treino.sentimento)\n",
    "\n",
    "# vetorização do dataframe de teste\n",
    "text_vect_teste = vect.transform(df_teste.texto)\n",
    "\n",
    "# escoragem da classificação na amostra de teste (textos vetorizados)\n",
    "y_predicao = model.predict(text_vect_teste)\n",
    "\n",
    "# mensuração do resultado pela acurácia\n",
    "y_teste = df_teste.sentimento\n",
    "accuracy = accuracy_score(df_teste.sentimento, y_predicao)\n",
    "f1score = f1_score(df_teste.sentimento, y_predicao, average='weighted')\n",
    "print(\"Random Forest\")\n",
    "print(f\"Acuracidade: {round(accuracy,4)}\")\n",
    "print(f\"F1 Score: {round(f1score,4)}\")\n",
    "print(\"=======================================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multinomial NB\n",
      "Acuracidade: 0.8755\n",
      "F1 Score: 0.8755\n",
      "=======================================\n",
      "Wall time: 1.79 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "model = MultinomialNB()\n",
    "model.fit(text_vect_treino, df_treino.sentimento)\n",
    "\n",
    "# vetorização do dataframe de teste\n",
    "text_vect_teste = vect.transform(df_teste.texto)\n",
    "\n",
    "# escoragem da classificação na amostra de teste (textos vetorizados)\n",
    "y_predicao = model.predict(text_vect_teste)\n",
    "\n",
    "# mensuração do resultado pela acurácia\n",
    "y_teste = df_teste.sentimento\n",
    "\n",
    "accuracy = accuracy_score(df_teste.sentimento, y_predicao)\n",
    "f1score = f1_score(df_teste.sentimento, y_predicao, average='weighted')\n",
    "print(\"Multinomial NB\")\n",
    "print(f\"Acuracidade: {round(accuracy,4)}\")\n",
    "print(f\"F1 Score: {round(f1score,4)}\")\n",
    "print(\"=======================================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bernoulli NB\n",
      "Acuracidade: 0.8732\n",
      "F1 Score: 0.8731\n",
      "=======================================\n",
      "Wall time: 1.75 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "model = BernoulliNB()\n",
    "model.fit(text_vect_treino, df_treino.sentimento)\n",
    "\n",
    "# vetorização do dataframe de teste\n",
    "text_vect_teste = vect.transform(df_teste.texto)\n",
    "\n",
    "# escoragem da classificação na amostra de teste (textos vetorizados)\n",
    "y_predicao = model.predict(text_vect_teste)\n",
    "\n",
    "# mensuração do resultado pela acurácia\n",
    "y_teste = df_teste.sentimento\n",
    "\n",
    "accuracy = accuracy_score(df_teste.sentimento, y_predicao)\n",
    "f1score = f1_score(df_teste.sentimento, y_predicao, average='weighted')\n",
    "print(\"Bernoulli NB\")\n",
    "print(f\"Acuracidade: {round(accuracy,4)}\")\n",
    "print(f\"F1 Score: {round(f1score,4)}\")\n",
    "print(\"=======================================\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CountVectorizer Texto / Unigrama - Bigrama / MindF = 10 / token_pattern = Palavras com mais de 3 letras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "vect = CountVectorizer(ngram_range=(1,2), min_df=10, token_pattern='[a-zA-Z0-9]{3,}')\n",
    "vect.fit(df_treino.texto)\n",
    "text_vect_treino = vect.transform(df_treino.texto)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree\n",
      "Acuracidade: 0.7276\n",
      "F1 Score: 0.7276\n",
      "=======================================\n",
      "Wall time: 1min 31s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "model = DecisionTreeClassifier(random_state=42)\n",
    "model.fit(text_vect_treino, df_treino.sentimento)\n",
    "\n",
    "# vetorização do dataframe de teste\n",
    "text_vect_teste = vect.transform(df_teste.texto)\n",
    "\n",
    "# escoragem da classificação na amostra de teste (textos vetorizados)\n",
    "y_predicao = model.predict(text_vect_teste)\n",
    "\n",
    "# mensuração do resultado pela acurácia\n",
    "y_teste = df_teste.sentimento\n",
    "\n",
    "accuracy = accuracy_score(df_teste.sentimento, y_predicao)\n",
    "f1score = f1_score(df_teste.sentimento, y_predicao, average='weighted')\n",
    "print(\"Decision Tree\")\n",
    "print(f\"Acuracidade: {round(accuracy,4)}\")\n",
    "print(f\"F1 Score: {round(f1score,4)}\")\n",
    "print(\"=======================================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Roberto Tengan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression\n",
      "Acuracidade: 0.8904\n",
      "F1 Score: 0.8904\n",
      "=======================================\n",
      "Wall time: 7.33 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "model = LogisticRegression(random_state=42)\n",
    "model.fit(text_vect_treino, df_treino.sentimento)\n",
    "\n",
    "# vetorização do dataframe de teste\n",
    "text_vect_teste = vect.transform(df_teste.texto)\n",
    "\n",
    "# escoragem da classificação na amostra de teste (textos vetorizados)\n",
    "y_predicao = model.predict(text_vect_teste)\n",
    "\n",
    "# mensuração do resultado pela acurácia\n",
    "y_teste = df_teste.sentimento\n",
    "accuracy = accuracy_score(df_teste.sentimento, y_predicao)\n",
    "f1score = f1_score(df_teste.sentimento, y_predicao, average='weighted')\n",
    "print(\"Logistic Regression\")\n",
    "print(f\"Acuracidade: {round(accuracy,4)}\")\n",
    "print(f\"F1 Score: {round(f1score,4)}\")\n",
    "print(\"=======================================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest\n",
      "Acuracidade: 0.8469\n",
      "F1 Score: 0.8469\n",
      "=======================================\n",
      "Wall time: 39.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "model = RandomForestClassifier(random_state=42, n_jobs=-1)\n",
    "model.fit(text_vect_treino, df_treino.sentimento)\n",
    "\n",
    "# vetorização do dataframe de teste\n",
    "text_vect_teste = vect.transform(df_teste.texto)\n",
    "\n",
    "# escoragem da classificação na amostra de teste (textos vetorizados)\n",
    "y_predicao = model.predict(text_vect_teste)\n",
    "\n",
    "# mensuração do resultado pela acurácia\n",
    "y_teste = df_teste.sentimento\n",
    "accuracy = accuracy_score(df_teste.sentimento, y_predicao)\n",
    "f1score = f1_score(df_teste.sentimento, y_predicao, average='weighted')\n",
    "print(\"Random Forest\")\n",
    "print(f\"Acuracidade: {round(accuracy,4)}\")\n",
    "print(f\"F1 Score: {round(f1score,4)}\")\n",
    "print(\"=======================================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multinomial NB\n",
      "Acuracidade: 0.8733\n",
      "F1 Score: 0.8733\n",
      "=======================================\n",
      "Wall time: 2.44 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "model = MultinomialNB()\n",
    "model.fit(text_vect_treino, df_treino.sentimento)\n",
    "\n",
    "# vetorização do dataframe de teste\n",
    "text_vect_teste = vect.transform(df_teste.texto)\n",
    "\n",
    "# escoragem da classificação na amostra de teste (textos vetorizados)\n",
    "y_predicao = model.predict(text_vect_teste)\n",
    "\n",
    "# mensuração do resultado pela acurácia\n",
    "y_teste = df_teste.sentimento\n",
    "\n",
    "accuracy = accuracy_score(df_teste.sentimento, y_predicao)\n",
    "f1score = f1_score(df_teste.sentimento, y_predicao, average='weighted')\n",
    "print(\"Multinomial NB\")\n",
    "print(f\"Acuracidade: {round(accuracy,4)}\")\n",
    "print(f\"F1 Score: {round(f1score,4)}\")\n",
    "print(\"=======================================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bernoulli NB\n",
      "Acuracidade: 0.8755\n",
      "F1 Score: 0.8755\n",
      "=======================================\n",
      "Wall time: 2.49 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "model = BernoulliNB()\n",
    "model.fit(text_vect_treino, df_treino.sentimento)\n",
    "\n",
    "# vetorização do dataframe de teste\n",
    "text_vect_teste = vect.transform(df_teste.texto)\n",
    "\n",
    "# escoragem da classificação na amostra de teste (textos vetorizados)\n",
    "y_predicao = model.predict(text_vect_teste)\n",
    "\n",
    "# mensuração do resultado pela acurácia\n",
    "y_teste = df_teste.sentimento\n",
    "\n",
    "accuracy = accuracy_score(df_teste.sentimento, y_predicao)\n",
    "f1score = f1_score(df_teste.sentimento, y_predicao, average='weighted')\n",
    "print(\"Bernoulli NB\")\n",
    "print(f\"Acuracidade: {round(accuracy,4)}\")\n",
    "print(f\"F1 Score: {round(f1score,4)}\")\n",
    "print(\"=======================================\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CountVectorizer Texto / Unigrama / MindF = 10 / token_pattern = Palavras com mais de 3 letras / Stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Roberto Tengan\\anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:388: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['amos', 'atr', 'atrav', 'dever', 'ent', 'est', 'estiv', 'far', 'houv', 'ltimo', 'mero', 'meros', 'nhamos', 'porqu', 'posi', 'poss', 'prio', 'quest', 'ramos', 'rea', 'rela', 'rios', 'ssemos', 'tamb', 'tima', 'timo', 'tiv', 'vamos', 'vel', 'voc', 'xima', 'ximo'] not in stop_words.\n",
      "  warnings.warn('Your stop_words may be inconsistent with '\n"
     ]
    }
   ],
   "source": [
    "vect = CountVectorizer(ngram_range=(1,1), min_df=10, token_pattern='[a-zA-Z0-9]{3,}', stop_words=stops)\n",
    "vect.fit(df_treino.texto)\n",
    "text_vect_treino = vect.transform(df_treino.texto)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree\n",
      "Acuracidade: 0.7157\n",
      "F1 Score: 0.7157\n",
      "=======================================\n",
      "Wall time: 42.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "model = DecisionTreeClassifier(random_state=42)\n",
    "model.fit(text_vect_treino, df_treino.sentimento)\n",
    "\n",
    "# vetorização do dataframe de teste\n",
    "text_vect_teste = vect.transform(df_teste.texto)\n",
    "\n",
    "# escoragem da classificação na amostra de teste (textos vetorizados)\n",
    "y_predicao = model.predict(text_vect_teste)\n",
    "\n",
    "# mensuração do resultado pela acurácia\n",
    "y_teste = df_teste.sentimento\n",
    "\n",
    "accuracy = accuracy_score(df_teste.sentimento, y_predicao)\n",
    "f1score = f1_score(df_teste.sentimento, y_predicao, average='weighted')\n",
    "print(\"Decision Tree\")\n",
    "print(f\"Acuracidade: {round(accuracy,4)}\")\n",
    "print(f\"F1 Score: {round(f1score,4)}\")\n",
    "print(\"=======================================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Roberto Tengan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression\n",
      "Acuracidade: 0.8621\n",
      "F1 Score: 0.8621\n",
      "=======================================\n",
      "Wall time: 2.91 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "model = LogisticRegression(random_state=42)\n",
    "model.fit(text_vect_treino, df_treino.sentimento)\n",
    "\n",
    "# vetorização do dataframe de teste\n",
    "text_vect_teste = vect.transform(df_teste.texto)\n",
    "\n",
    "# escoragem da classificação na amostra de teste (textos vetorizados)\n",
    "y_predicao = model.predict(text_vect_teste)\n",
    "\n",
    "# mensuração do resultado pela acurácia\n",
    "y_teste = df_teste.sentimento\n",
    "accuracy = accuracy_score(df_teste.sentimento, y_predicao)\n",
    "f1score = f1_score(df_teste.sentimento, y_predicao, average='weighted')\n",
    "print(\"Logistic Regression\")\n",
    "print(f\"Acuracidade: {round(accuracy,4)}\")\n",
    "print(f\"F1 Score: {round(f1score,4)}\")\n",
    "print(\"=======================================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest\n",
      "Acuracidade: 0.8413\n",
      "F1 Score: 0.8413\n",
      "=======================================\n",
      "Wall time: 28.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "model = RandomForestClassifier(random_state=42, n_jobs=-1)\n",
    "model.fit(text_vect_treino, df_treino.sentimento)\n",
    "\n",
    "# vetorização do dataframe de teste\n",
    "text_vect_teste = vect.transform(df_teste.texto)\n",
    "\n",
    "# escoragem da classificação na amostra de teste (textos vetorizados)\n",
    "y_predicao = model.predict(text_vect_teste)\n",
    "\n",
    "# mensuração do resultado pela acurácia\n",
    "y_teste = df_teste.sentimento\n",
    "accuracy = accuracy_score(df_teste.sentimento, y_predicao)\n",
    "f1score = f1_score(df_teste.sentimento, y_predicao, average='weighted')\n",
    "print(\"Random Forest\")\n",
    "print(f\"Acuracidade: {round(accuracy,4)}\")\n",
    "print(f\"F1 Score: {round(f1score,4)}\")\n",
    "print(\"=======================================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multinomial NB\n",
      "Acuracidade: 0.8516\n",
      "F1 Score: 0.8516\n",
      "=======================================\n",
      "Wall time: 1.22 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "model = MultinomialNB()\n",
    "model.fit(text_vect_treino, df_treino.sentimento)\n",
    "\n",
    "# vetorização do dataframe de teste\n",
    "text_vect_teste = vect.transform(df_teste.texto)\n",
    "\n",
    "# escoragem da classificação na amostra de teste (textos vetorizados)\n",
    "y_predicao = model.predict(text_vect_teste)\n",
    "\n",
    "# mensuração do resultado pela acurácia\n",
    "y_teste = df_teste.sentimento\n",
    "\n",
    "accuracy = accuracy_score(df_teste.sentimento, y_predicao)\n",
    "f1score = f1_score(df_teste.sentimento, y_predicao, average='weighted')\n",
    "print(\"Multinomial NB\")\n",
    "print(f\"Acuracidade: {round(accuracy,4)}\")\n",
    "print(f\"F1 Score: {round(f1score,4)}\")\n",
    "print(\"=======================================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bernoulli NB\n",
      "Acuracidade: 0.8489\n",
      "F1 Score: 0.8489\n",
      "=======================================\n",
      "Wall time: 1.24 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "model = BernoulliNB()\n",
    "model.fit(text_vect_treino, df_treino.sentimento)\n",
    "\n",
    "# vetorização do dataframe de teste\n",
    "text_vect_teste = vect.transform(df_teste.texto)\n",
    "\n",
    "# escoragem da classificação na amostra de teste (textos vetorizados)\n",
    "y_predicao = model.predict(text_vect_teste)\n",
    "\n",
    "# mensuração do resultado pela acurácia\n",
    "y_teste = df_teste.sentimento\n",
    "\n",
    "accuracy = accuracy_score(df_teste.sentimento, y_predicao)\n",
    "f1score = f1_score(df_teste.sentimento, y_predicao, average='weighted')\n",
    "print(\"Bernoulli NB\")\n",
    "print(f\"Acuracidade: {round(accuracy,4)}\")\n",
    "print(f\"F1 Score: {round(f1score,4)}\")\n",
    "print(\"=======================================\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CountVectorizer Texto / Bigrama / MindF = 10 / token_pattern = Palavras com mais de 3 letras / Stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Roberto Tengan\\anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:388: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['amos', 'atr', 'atrav', 'dever', 'ent', 'est', 'estiv', 'far', 'houv', 'ltimo', 'mero', 'meros', 'nhamos', 'porqu', 'posi', 'poss', 'prio', 'quest', 'ramos', 'rea', 'rela', 'rios', 'ssemos', 'tamb', 'tima', 'timo', 'tiv', 'vamos', 'vel', 'voc', 'xima', 'ximo'] not in stop_words.\n",
      "  warnings.warn('Your stop_words may be inconsistent with '\n"
     ]
    }
   ],
   "source": [
    "vect = CountVectorizer(ngram_range=(2,2), min_df=10, token_pattern='[a-zA-Z0-9]{3,}', stop_words=stops)\n",
    "vect.fit(df_treino.texto)\n",
    "text_vect_treino = vect.transform(df_treino.texto)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree\n",
      "Acuracidade: 0.7126\n",
      "F1 Score: 0.7126\n",
      "=======================================\n",
      "Wall time: 19.9 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "model = DecisionTreeClassifier(random_state=42)\n",
    "model.fit(text_vect_treino, df_treino.sentimento)\n",
    "\n",
    "# vetorização do dataframe de teste\n",
    "text_vect_teste = vect.transform(df_teste.texto)\n",
    "\n",
    "# escoragem da classificação na amostra de teste (textos vetorizados)\n",
    "y_predicao = model.predict(text_vect_teste)\n",
    "\n",
    "# mensuração do resultado pela acurácia\n",
    "y_teste = df_teste.sentimento\n",
    "\n",
    "accuracy = accuracy_score(df_teste.sentimento, y_predicao)\n",
    "f1score = f1_score(df_teste.sentimento, y_predicao, average='weighted')\n",
    "print(\"Decision Tree\")\n",
    "print(f\"Acuracidade: {round(accuracy,4)}\")\n",
    "print(f\"F1 Score: {round(f1score,4)}\")\n",
    "print(\"=======================================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Roberto Tengan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression\n",
      "Acuracidade: 0.8322\n",
      "F1 Score: 0.8322\n",
      "=======================================\n",
      "Wall time: 2.49 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "model = LogisticRegression(random_state=42)\n",
    "model.fit(text_vect_treino, df_treino.sentimento)\n",
    "\n",
    "# vetorização do dataframe de teste\n",
    "text_vect_teste = vect.transform(df_teste.texto)\n",
    "\n",
    "# escoragem da classificação na amostra de teste (textos vetorizados)\n",
    "y_predicao = model.predict(text_vect_teste)\n",
    "\n",
    "# mensuração do resultado pela acurácia\n",
    "y_teste = df_teste.sentimento\n",
    "accuracy = accuracy_score(df_teste.sentimento, y_predicao)\n",
    "f1score = f1_score(df_teste.sentimento, y_predicao, average='weighted')\n",
    "print(\"Logistic Regression\")\n",
    "print(f\"Acuracidade: {round(accuracy,4)}\")\n",
    "print(f\"F1 Score: {round(f1score,4)}\")\n",
    "print(\"=======================================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest\n",
      "Acuracidade: 0.7931\n",
      "F1 Score: 0.793\n",
      "=======================================\n",
      "Wall time: 20.9 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "model = RandomForestClassifier(random_state=42, n_jobs=-1)\n",
    "model.fit(text_vect_treino, df_treino.sentimento)\n",
    "\n",
    "# vetorização do dataframe de teste\n",
    "text_vect_teste = vect.transform(df_teste.texto)\n",
    "\n",
    "# escoragem da classificação na amostra de teste (textos vetorizados)\n",
    "y_predicao = model.predict(text_vect_teste)\n",
    "\n",
    "# mensuração do resultado pela acurácia\n",
    "y_teste = df_teste.sentimento\n",
    "accuracy = accuracy_score(df_teste.sentimento, y_predicao)\n",
    "f1score = f1_score(df_teste.sentimento, y_predicao, average='weighted')\n",
    "print(\"Random Forest\")\n",
    "print(f\"Acuracidade: {round(accuracy,4)}\")\n",
    "print(f\"F1 Score: {round(f1score,4)}\")\n",
    "print(\"=======================================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multinomial NB\n",
      "Acuracidade: 0.7931\n",
      "F1 Score: 0.793\n",
      "=======================================\n",
      "Wall time: 1.44 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "model = MultinomialNB()\n",
    "model.fit(text_vect_treino, df_treino.sentimento)\n",
    "\n",
    "# vetorização do dataframe de teste\n",
    "text_vect_teste = vect.transform(df_teste.texto)\n",
    "\n",
    "# escoragem da classificação na amostra de teste (textos vetorizados)\n",
    "y_predicao = model.predict(text_vect_teste)\n",
    "\n",
    "# mensuração do resultado pela acurácia\n",
    "y_teste = df_teste.sentimento\n",
    "print(\"Multinomial NB\")\n",
    "print(f\"Acuracidade: {round(accuracy,4)}\")\n",
    "print(f\"F1 Score: {round(f1score,4)}\")\n",
    "print(\"=======================================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bernoulli NB\n",
      "Acuracidade: 0.8466\n",
      "F1 Score: 0.8463\n",
      "=======================================\n",
      "Wall time: 1.45 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "model = BernoulliNB()\n",
    "model.fit(text_vect_treino, df_treino.sentimento)\n",
    "\n",
    "# vetorização do dataframe de teste\n",
    "text_vect_teste = vect.transform(df_teste.texto)\n",
    "\n",
    "# escoragem da classificação na amostra de teste (textos vetorizados)\n",
    "y_predicao = model.predict(text_vect_teste)\n",
    "\n",
    "# mensuração do resultado pela acurácia\n",
    "y_teste = df_teste.sentimento\n",
    "\n",
    "accuracy = accuracy_score(df_teste.sentimento, y_predicao)\n",
    "f1score = f1_score(df_teste.sentimento, y_predicao, average='weighted')\n",
    "print(\"Bernoulli NB\")\n",
    "print(f\"Acuracidade: {round(accuracy,4)}\")\n",
    "print(f\"F1 Score: {round(f1score,4)}\")\n",
    "print(\"=======================================\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CountVectorizer Texto / Unigrama - Bigrama / MindF = 10 / token_pattern = Palavras com mais de 3 letras / Stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Roberto Tengan\\anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:388: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['amos', 'atr', 'atrav', 'dever', 'ent', 'est', 'estiv', 'far', 'houv', 'ltimo', 'mero', 'meros', 'nhamos', 'porqu', 'posi', 'poss', 'prio', 'quest', 'ramos', 'rea', 'rela', 'rios', 'ssemos', 'tamb', 'tima', 'timo', 'tiv', 'vamos', 'vel', 'voc', 'xima', 'ximo'] not in stop_words.\n",
      "  warnings.warn('Your stop_words may be inconsistent with '\n"
     ]
    }
   ],
   "source": [
    "vect = CountVectorizer(ngram_range=(1,2), min_df=10, token_pattern='[a-zA-Z0-9]{3,}', stop_words=stops)\n",
    "vect.fit(df_treino.texto)\n",
    "text_vect_treino = vect.transform(df_treino.texto)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree\n",
      "Acuracidade: 0.7214\n",
      "F1 Score: 0.7214\n",
      "=======================================\n",
      "Wall time: 55.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "model = DecisionTreeClassifier(random_state=42)\n",
    "model.fit(text_vect_treino, df_treino.sentimento)\n",
    "\n",
    "# vetorização do dataframe de teste\n",
    "text_vect_teste = vect.transform(df_teste.texto)\n",
    "\n",
    "# escoragem da classificação na amostra de teste (textos vetorizados)\n",
    "y_predicao = model.predict(text_vect_teste)\n",
    "\n",
    "# mensuração do resultado pela acurácia\n",
    "y_teste = df_teste.sentimento\n",
    "\n",
    "accuracy = accuracy_score(df_teste.sentimento, y_predicao)\n",
    "f1score = f1_score(df_teste.sentimento, y_predicao, average='weighted')\n",
    "print(\"Decision Tree\")\n",
    "print(f\"Acuracidade: {round(accuracy,4)}\")\n",
    "print(f\"F1 Score: {round(f1score,4)}\")\n",
    "print(\"=======================================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Roberto Tengan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression\n",
      "Acuracidade: 0.8777\n",
      "F1 Score: 0.8777\n",
      "=======================================\n",
      "Wall time: 4.6 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "model = LogisticRegression(random_state=42)\n",
    "model.fit(text_vect_treino, df_treino.sentimento)\n",
    "\n",
    "# vetorização do dataframe de teste\n",
    "text_vect_teste = vect.transform(df_teste.texto)\n",
    "\n",
    "# escoragem da classificação na amostra de teste (textos vetorizados)\n",
    "y_predicao = model.predict(text_vect_teste)\n",
    "\n",
    "# mensuração do resultado pela acurácia\n",
    "y_teste = df_teste.sentimento\n",
    "accuracy = accuracy_score(df_teste.sentimento, y_predicao)\n",
    "f1score = f1_score(df_teste.sentimento, y_predicao, average='weighted')\n",
    "print(\"Logistic Regression\")\n",
    "print(f\"Acuracidade: {round(accuracy,4)}\")\n",
    "print(f\"F1 Score: {round(f1score,4)}\")\n",
    "print(\"=======================================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest\n",
      "Acuracidade: 0.8497\n",
      "F1 Score: 0.8497\n",
      "=======================================\n",
      "Wall time: 31.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "model = RandomForestClassifier(random_state=42, n_jobs=-1)\n",
    "model.fit(text_vect_treino, df_treino.sentimento)\n",
    "\n",
    "# vetorização do dataframe de teste\n",
    "text_vect_teste = vect.transform(df_teste.texto)\n",
    "\n",
    "# escoragem da classificação na amostra de teste (textos vetorizados)\n",
    "y_predicao = model.predict(text_vect_teste)\n",
    "\n",
    "# mensuração do resultado pela acurácia\n",
    "y_teste = df_teste.sentimento\n",
    "accuracy = accuracy_score(df_teste.sentimento, y_predicao)\n",
    "f1score = f1_score(df_teste.sentimento, y_predicao, average='weighted')\n",
    "print(\"Random Forest\")\n",
    "print(f\"Acuracidade: {round(accuracy,4)}\")\n",
    "print(f\"F1 Score: {round(f1score,4)}\")\n",
    "print(\"=======================================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multinomial NB\n",
      "Acuracidade: 0.8681\n",
      "F1 Score: 0.8681\n",
      "=======================================\n",
      "Wall time: 1.98 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "model = MultinomialNB()\n",
    "model.fit(text_vect_treino, df_treino.sentimento)\n",
    "\n",
    "# vetorização do dataframe de teste\n",
    "text_vect_teste = vect.transform(df_teste.texto)\n",
    "\n",
    "# escoragem da classificação na amostra de teste (textos vetorizados)\n",
    "y_predicao = model.predict(text_vect_teste)\n",
    "\n",
    "# mensuração do resultado pela acurácia\n",
    "y_teste = df_teste.sentimento\n",
    "\n",
    "accuracy = accuracy_score(df_teste.sentimento, y_predicao)\n",
    "f1score = f1_score(df_teste.sentimento, y_predicao, average='weighted')\n",
    "print(\"Multinomial NB\")\n",
    "print(f\"Acuracidade: {round(accuracy,4)}\")\n",
    "print(f\"F1 Score: {round(f1score,4)}\")\n",
    "print(\"=======================================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bernoulli NB\n",
      "Acuracidade: 0.869\n",
      "F1 Score: 0.869\n",
      "=======================================\n",
      "Wall time: 1.96 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "model = BernoulliNB()\n",
    "model.fit(text_vect_treino, df_treino.sentimento)\n",
    "\n",
    "# vetorização do dataframe de teste\n",
    "text_vect_teste = vect.transform(df_teste.texto)\n",
    "\n",
    "# escoragem da classificação na amostra de teste (textos vetorizados)\n",
    "y_predicao = model.predict(text_vect_teste)\n",
    "\n",
    "# mensuração do resultado pela acurácia\n",
    "y_teste = df_teste.sentimento\n",
    "\n",
    "accuracy = accuracy_score(df_teste.sentimento, y_predicao)\n",
    "f1score = f1_score(df_teste.sentimento, y_predicao, average='weighted')\n",
    "print(\"Bernoulli NB\")\n",
    "print(f\"Acuracidade: {round(accuracy,4)}\")\n",
    "print(f\"F1 Score: {round(f1score,4)}\")\n",
    "print(\"=======================================\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VFA-CYfawkEJ"
   },
   "source": [
    "## CountVectorizer Stemmer Unigrama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "vect = CountVectorizer(ngram_range=(1,1))\n",
    "vect.fit(df_treino.stemmer)\n",
    "text_vect_treino = vect.transform(df_treino.stemmer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree\n",
      "Acuracidade: 0.6983\n",
      "F1 Score: 0.6983\n",
      "=======================================\n",
      "Wall time: 1min\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "model = DecisionTreeClassifier(random_state=42)\n",
    "model.fit(text_vect_treino, df_treino.sentimento)\n",
    "\n",
    "# vetorização do dataframe de teste\n",
    "text_vect_teste = vect.transform(df_teste.stemmer)\n",
    "\n",
    "# escoragem da classificação na amostra de teste (textos vetorizados)\n",
    "y_predicao = model.predict(text_vect_teste)\n",
    "\n",
    "# mensuração do resultado pela acurácia\n",
    "y_teste = df_teste.sentimento\n",
    "\n",
    "accuracy = accuracy_score(df_teste.sentimento, y_predicao)\n",
    "f1score = f1_score(df_teste.sentimento, y_predicao, average='weighted')\n",
    "print(\"Decision Tree\")\n",
    "print(f\"Acuracidade: {round(accuracy,4)}\")\n",
    "print(f\"F1 Score: {round(f1score,4)}\")\n",
    "print(\"=======================================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Roberto Tengan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression\n",
      "Acuracidade: 0.8793\n",
      "F1 Score: 0.8793\n",
      "=======================================\n",
      "Wall time: 5.34 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "model = LogisticRegression(random_state=42)\n",
    "model.fit(text_vect_treino, df_treino.sentimento)\n",
    "\n",
    "# vetorização do dataframe de teste\n",
    "text_vect_teste = vect.transform(df_teste.stemmer)\n",
    "\n",
    "# escoragem da classificação na amostra de teste (textos vetorizados)\n",
    "y_predicao = model.predict(text_vect_teste)\n",
    "\n",
    "# mensuração do resultado pela acurácia\n",
    "y_teste = df_teste.sentimento\n",
    "accuracy = accuracy_score(df_teste.sentimento, y_predicao)\n",
    "f1score = f1_score(df_teste.sentimento, y_predicao, average='weighted')\n",
    "print(\"Logistic Regression\")\n",
    "print(f\"Acuracidade: {round(accuracy,4)}\")\n",
    "print(f\"F1 Score: {round(f1score,4)}\")\n",
    "print(\"=======================================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest\n",
      "Acuracidade: 0.8342\n",
      "F1 Score: 0.8342\n",
      "=======================================\n",
      "Wall time: 38.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "model = RandomForestClassifier(random_state=42, n_jobs=-1)\n",
    "model.fit(text_vect_treino, df_treino.sentimento)\n",
    "\n",
    "# vetorização do dataframe de teste\n",
    "text_vect_teste = vect.transform(df_teste.stemmer)\n",
    "\n",
    "# escoragem da classificação na amostra de teste (textos vetorizados)\n",
    "y_predicao = model.predict(text_vect_teste)\n",
    "\n",
    "# mensuração do resultado pela acurácia\n",
    "y_teste = df_teste.sentimento\n",
    "accuracy = accuracy_score(df_teste.sentimento, y_predicao)\n",
    "f1score = f1_score(df_teste.sentimento, y_predicao, average='weighted')\n",
    "print(\"Random Forest\")\n",
    "print(f\"Acuracidade: {round(accuracy,4)}\")\n",
    "print(f\"F1 Score: {round(f1score,4)}\")\n",
    "print(\"=======================================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multinomial NB\n",
      "Acuracidade: 0.8476\n",
      "F1 Score: 0.8474\n",
      "=======================================\n",
      "Wall time: 1.54 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "model = MultinomialNB()\n",
    "model.fit(text_vect_treino, df_treino.sentimento)\n",
    "\n",
    "# vetorização do dataframe de teste\n",
    "text_vect_teste = vect.transform(df_teste.stemmer)\n",
    "\n",
    "# escoragem da classificação na amostra de teste (textos vetorizados)\n",
    "y_predicao = model.predict(text_vect_teste)\n",
    "\n",
    "# mensuração do resultado pela acurácia\n",
    "y_teste = df_teste.sentimento\n",
    "\n",
    "accuracy = accuracy_score(df_teste.sentimento, y_predicao)\n",
    "f1score = f1_score(df_teste.sentimento, y_predicao, average='weighted')\n",
    "print(\"Multinomial NB\")\n",
    "print(f\"Acuracidade: {round(accuracy,4)}\")\n",
    "print(f\"F1 Score: {round(f1score,4)}\")\n",
    "print(\"=======================================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bernoulli NB\n",
      "Acuracidade: 0.8584\n",
      "F1 Score: 0.8583\n",
      "=======================================\n",
      "Wall time: 1.54 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "model = BernoulliNB()\n",
    "model.fit(text_vect_treino, df_treino.sentimento)\n",
    "\n",
    "# vetorização do dataframe de teste\n",
    "text_vect_teste = vect.transform(df_teste.stemmer)\n",
    "\n",
    "# escoragem da classificação na amostra de teste (textos vetorizados)\n",
    "y_predicao = model.predict(text_vect_teste)\n",
    "\n",
    "# mensuração do resultado pela acurácia\n",
    "y_teste = df_teste.sentimento\n",
    "\n",
    "accuracy = accuracy_score(df_teste.sentimento, y_predicao)\n",
    "f1score = f1_score(df_teste.sentimento, y_predicao, average='weighted')\n",
    "print(\"Bernoulli NB\")\n",
    "print(f\"Acuracidade: {round(accuracy,4)}\")\n",
    "print(f\"F1 Score: {round(f1score,4)}\")\n",
    "print(\"=======================================\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CountVectorizer Stemmer Bigrama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "vect = CountVectorizer(ngram_range=(2,2))\n",
    "vect.fit(df_treino.stemmer)\n",
    "text_vect_treino = vect.transform(df_treino.stemmer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree\n",
      "Acuracidade: 0.6865\n",
      "F1 Score: 0.6865\n",
      "=======================================\n",
      "Wall time: 5min 54s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "model = DecisionTreeClassifier(random_state=42)\n",
    "model.fit(text_vect_treino, df_treino.sentimento)\n",
    "\n",
    "# vetorização do dataframe de teste\n",
    "text_vect_teste = vect.transform(df_teste.stemmer)\n",
    "\n",
    "# escoragem da classificação na amostra de teste (textos vetorizados)\n",
    "y_predicao = model.predict(text_vect_teste)\n",
    "\n",
    "# mensuração do resultado pela acurácia\n",
    "y_teste = df_teste.sentimento\n",
    "\n",
    "accuracy = accuracy_score(df_teste.sentimento, y_predicao)\n",
    "f1score = f1_score(df_teste.sentimento, y_predicao, average='weighted')\n",
    "print(\"Decision Tree\")\n",
    "print(f\"Acuracidade: {round(accuracy,4)}\")\n",
    "print(f\"F1 Score: {round(f1score,4)}\")\n",
    "print(\"=======================================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Roberto Tengan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression\n",
      "Acuracidade: 0.8744\n",
      "F1 Score: 0.8744\n",
      "=======================================\n",
      "Wall time: 43.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "model = LogisticRegression(random_state=42)\n",
    "model.fit(text_vect_treino, df_treino.sentimento)\n",
    "\n",
    "# vetorização do dataframe de teste\n",
    "text_vect_teste = vect.transform(df_teste.stemmer)\n",
    "\n",
    "# escoragem da classificação na amostra de teste (textos vetorizados)\n",
    "y_predicao = model.predict(text_vect_teste)\n",
    "\n",
    "# mensuração do resultado pela acurácia\n",
    "y_teste = df_teste.sentimento\n",
    "accuracy = accuracy_score(df_teste.sentimento, y_predicao)\n",
    "f1score = f1_score(df_teste.sentimento, y_predicao, average='weighted')\n",
    "print(\"Logistic Regression\")\n",
    "print(f\"Acuracidade: {round(accuracy,4)}\")\n",
    "print(f\"F1 Score: {round(f1score,4)}\")\n",
    "print(\"=======================================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest\n",
      "Acuracidade: 0.8219\n",
      "F1 Score: 0.8218\n",
      "=======================================\n",
      "Wall time: 8min 22s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "model = RandomForestClassifier(random_state=42, n_jobs=-1)\n",
    "model.fit(text_vect_treino, df_treino.sentimento)\n",
    "\n",
    "# vetorização do dataframe de teste\n",
    "text_vect_teste = vect.transform(df_teste.stemmer)\n",
    "\n",
    "# escoragem da classificação na amostra de teste (textos vetorizados)\n",
    "y_predicao = model.predict(text_vect_teste)\n",
    "\n",
    "# mensuração do resultado pela acurácia\n",
    "y_teste = df_teste.sentimento\n",
    "accuracy = accuracy_score(df_teste.sentimento, y_predicao)\n",
    "f1score = f1_score(df_teste.sentimento, y_predicao, average='weighted')\n",
    "print(\"Random Forest\")\n",
    "print(f\"Acuracidade: {round(accuracy,4)}\")\n",
    "print(f\"F1 Score: {round(f1score,4)}\")\n",
    "print(\"=======================================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multinomial NB\n",
      "Acuracidade: 0.8821\n",
      "F1 Score: 0.8819\n",
      "=======================================\n",
      "Wall time: 3.06 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "model = MultinomialNB()\n",
    "model.fit(text_vect_treino, df_treino.sentimento)\n",
    "\n",
    "# vetorização do dataframe de teste\n",
    "text_vect_teste = vect.transform(df_teste.stemmer)\n",
    "\n",
    "# escoragem da classificação na amostra de teste (textos vetorizados)\n",
    "y_predicao = model.predict(text_vect_teste)\n",
    "\n",
    "# mensuração do resultado pela acurácia\n",
    "y_teste = df_teste.sentimento\n",
    "\n",
    "accuracy = accuracy_score(df_teste.sentimento, y_predicao)\n",
    "f1score = f1_score(df_teste.sentimento, y_predicao, average='weighted')\n",
    "print(\"Multinomial NB\")\n",
    "print(f\"Acuracidade: {round(accuracy,4)}\")\n",
    "print(f\"F1 Score: {round(f1score,4)}\")\n",
    "print(\"=======================================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bernoulli NB\n",
      "Acuracidade: 0.8812\n",
      "F1 Score: 0.881\n",
      "=======================================\n",
      "Wall time: 3.26 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "model = BernoulliNB()\n",
    "model.fit(text_vect_treino, df_treino.sentimento)\n",
    "\n",
    "# vetorização do dataframe de teste\n",
    "text_vect_teste = vect.transform(df_teste.stemmer)\n",
    "\n",
    "# escoragem da classificação na amostra de teste (textos vetorizados)\n",
    "y_predicao = model.predict(text_vect_teste)\n",
    "\n",
    "# mensuração do resultado pela acurácia\n",
    "y_teste = df_teste.sentimento\n",
    "\n",
    "accuracy = accuracy_score(df_teste.sentimento, y_predicao)\n",
    "f1score = f1_score(df_teste.sentimento, y_predicao, average='weighted')\n",
    "print(\"Bernoulli NB\")\n",
    "print(f\"Acuracidade: {round(accuracy,4)}\")\n",
    "print(f\"F1 Score: {round(f1score,4)}\")\n",
    "print(\"=======================================\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CountVectorizer Stemmer / Unigrama - Bigrama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "vect = CountVectorizer(ngram_range=(1,2))\n",
    "vect.fit(df_treino.stemmer)\n",
    "text_vect_treino = vect.transform(df_treino.stemmer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree\n",
      "Acuracidade: 0.702\n",
      "F1 Score: 0.702\n",
      "=======================================\n",
      "Wall time: 5min 53s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "model = DecisionTreeClassifier(random_state=42)\n",
    "model.fit(text_vect_treino, df_treino.sentimento)\n",
    "\n",
    "# vetorização do dataframe de teste\n",
    "text_vect_teste = vect.transform(df_teste.stemmer)\n",
    "\n",
    "# escoragem da classificação na amostra de teste (textos vetorizados)\n",
    "y_predicao = model.predict(text_vect_teste)\n",
    "\n",
    "# mensuração do resultado pela acurácia\n",
    "y_teste = df_teste.sentimento\n",
    "\n",
    "accuracy = accuracy_score(df_teste.sentimento, y_predicao)\n",
    "f1score = f1_score(df_teste.sentimento, y_predicao, average='weighted')\n",
    "print(\"Decision Tree\")\n",
    "print(f\"Acuracidade: {round(accuracy,4)}\")\n",
    "print(f\"F1 Score: {round(f1score,4)}\")\n",
    "print(\"=======================================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Roberto Tengan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression\n",
      "Acuracidade: 0.8946\n",
      "F1 Score: 0.8946\n",
      "=======================================\n",
      "Wall time: 51.9 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "model = LogisticRegression(random_state=42)\n",
    "model.fit(text_vect_treino, df_treino.sentimento)\n",
    "\n",
    "# vetorização do dataframe de teste\n",
    "text_vect_teste = vect.transform(df_teste.stemmer)\n",
    "\n",
    "# escoragem da classificação na amostra de teste (textos vetorizados)\n",
    "y_predicao = model.predict(text_vect_teste)\n",
    "\n",
    "# mensuração do resultado pela acurácia\n",
    "y_teste = df_teste.sentimento\n",
    "accuracy = accuracy_score(df_teste.sentimento, y_predicao)\n",
    "f1score = f1_score(df_teste.sentimento, y_predicao, average='weighted')\n",
    "print(\"Logistic Regression\")\n",
    "print(f\"Acuracidade: {round(accuracy,4)}\")\n",
    "print(f\"F1 Score: {round(f1score,4)}\")\n",
    "print(\"=======================================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest\n",
      "Acuracidade: 0.8445\n",
      "F1 Score: 0.8445\n",
      "=======================================\n",
      "Wall time: 5min 37s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "model = RandomForestClassifier(random_state=42, n_jobs=-1)\n",
    "model.fit(text_vect_treino, df_treino.sentimento)\n",
    "\n",
    "# vetorização do dataframe de teste\n",
    "text_vect_teste = vect.transform(df_teste.stemmer)\n",
    "\n",
    "# escoragem da classificação na amostra de teste (textos vetorizados)\n",
    "y_predicao = model.predict(text_vect_teste)\n",
    "\n",
    "# mensuração do resultado pela acurácia\n",
    "y_teste = df_teste.sentimento\n",
    "accuracy = accuracy_score(df_teste.sentimento, y_predicao)\n",
    "f1score = f1_score(df_teste.sentimento, y_predicao, average='weighted')\n",
    "print(\"Random Forest\")\n",
    "print(f\"Acuracidade: {round(accuracy,4)}\")\n",
    "print(f\"F1 Score: {round(f1score,4)}\")\n",
    "print(\"=======================================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multinomial NB\n",
      "Acuracidade: 0.8799\n",
      "F1 Score: 0.8798\n",
      "=======================================\n",
      "Wall time: 3.34 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "model = MultinomialNB()\n",
    "model.fit(text_vect_treino, df_treino.sentimento)\n",
    "\n",
    "# vetorização do dataframe de teste\n",
    "text_vect_teste = vect.transform(df_teste.stemmer)\n",
    "\n",
    "# escoragem da classificação na amostra de teste (textos vetorizados)\n",
    "y_predicao = model.predict(text_vect_teste)\n",
    "\n",
    "# mensuração do resultado pela acurácia\n",
    "y_teste = df_teste.sentimento\n",
    "\n",
    "accuracy = accuracy_score(df_teste.sentimento, y_predicao)\n",
    "f1score = f1_score(df_teste.sentimento, y_predicao, average='weighted')\n",
    "print(\"Multinomial NB\")\n",
    "print(f\"Acuracidade: {round(accuracy,4)}\")\n",
    "print(f\"F1 Score: {round(f1score,4)}\")\n",
    "print(\"=======================================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bernoulli NB\n",
      "Acuracidade: 0.8805\n",
      "F1 Score: 0.8804\n",
      "=======================================\n",
      "Wall time: 3.46 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "model = BernoulliNB()\n",
    "model.fit(text_vect_treino, df_treino.sentimento)\n",
    "\n",
    "# vetorização do dataframe de teste\n",
    "text_vect_teste = vect.transform(df_teste.stemmer)\n",
    "\n",
    "# escoragem da classificação na amostra de teste (textos vetorizados)\n",
    "y_predicao = model.predict(text_vect_teste)\n",
    "\n",
    "# mensuração do resultado pela acurácia\n",
    "y_teste = df_teste.sentimento\n",
    "\n",
    "accuracy = accuracy_score(df_teste.sentimento, y_predicao)\n",
    "f1score = f1_score(df_teste.sentimento, y_predicao, average='weighted')\n",
    "print(\"Bernoulli NB\")\n",
    "print(f\"Acuracidade: {round(accuracy,4)}\")\n",
    "print(f\"F1 Score: {round(f1score,4)}\")\n",
    "print(\"=======================================\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CountVectorizer Stemmer / Unigrama / MindF = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "vect = CountVectorizer(ngram_range=(1,1), min_df=10)\n",
    "vect.fit(df_treino.stemmer)\n",
    "text_vect_treino = vect.transform(df_treino.stemmer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree\n",
      "Acuracidade: 0.6964\n",
      "F1 Score: 0.6964\n",
      "=======================================\n",
      "Wall time: 51.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "model = DecisionTreeClassifier(random_state=42)\n",
    "model.fit(text_vect_treino, df_treino.sentimento)\n",
    "\n",
    "# vetorização do dataframe de teste\n",
    "text_vect_teste = vect.transform(df_teste.stemmer)\n",
    "\n",
    "# escoragem da classificação na amostra de teste (textos vetorizados)\n",
    "y_predicao = model.predict(text_vect_teste)\n",
    "\n",
    "# mensuração do resultado pela acurácia\n",
    "y_teste = df_teste.sentimento\n",
    "\n",
    "accuracy = accuracy_score(df_teste.sentimento, y_predicao)\n",
    "f1score = f1_score(df_teste.sentimento, y_predicao, average='weighted')\n",
    "print(\"Decision Tree\")\n",
    "print(f\"Acuracidade: {round(accuracy,4)}\")\n",
    "print(f\"F1 Score: {round(f1score,4)}\")\n",
    "print(\"=======================================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Roberto Tengan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression\n",
      "Acuracidade: 0.8805\n",
      "F1 Score: 0.8805\n",
      "=======================================\n",
      "Wall time: 3.73 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "model = LogisticRegression(random_state=42)\n",
    "model.fit(text_vect_treino, df_treino.sentimento)\n",
    "\n",
    "# vetorização do dataframe de teste\n",
    "text_vect_teste = vect.transform(df_teste.stemmer)\n",
    "\n",
    "# escoragem da classificação na amostra de teste (textos vetorizados)\n",
    "y_predicao = model.predict(text_vect_teste)\n",
    "\n",
    "# mensuração do resultado pela acurácia\n",
    "y_teste = df_teste.sentimento\n",
    "accuracy = accuracy_score(df_teste.sentimento, y_predicao)\n",
    "f1score = f1_score(df_teste.sentimento, y_predicao, average='weighted')\n",
    "print(\"Logistic Regression\")\n",
    "print(f\"Acuracidade: {round(accuracy,4)}\")\n",
    "print(f\"F1 Score: {round(f1score,4)}\")\n",
    "print(\"=======================================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest\n",
      "Acuracidade: 0.8302\n",
      "F1 Score: 0.8302\n",
      "=======================================\n",
      "Wall time: 32 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "model = RandomForestClassifier(random_state=42, n_jobs=-1)\n",
    "model.fit(text_vect_treino, df_treino.sentimento)\n",
    "\n",
    "# vetorização do dataframe de teste\n",
    "text_vect_teste = vect.transform(df_teste.stemmer)\n",
    "\n",
    "# escoragem da classificação na amostra de teste (textos vetorizados)\n",
    "y_predicao = model.predict(text_vect_teste)\n",
    "\n",
    "# mensuração do resultado pela acurácia\n",
    "y_teste = df_teste.sentimento\n",
    "accuracy = accuracy_score(df_teste.sentimento, y_predicao)\n",
    "f1score = f1_score(df_teste.sentimento, y_predicao, average='weighted')\n",
    "print(\"Random Forest\")\n",
    "print(f\"Acuracidade: {round(accuracy,4)}\")\n",
    "print(f\"F1 Score: {round(f1score,4)}\")\n",
    "print(\"=======================================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multinomial NB\n",
      "Acuracidade: 0.8443\n",
      "F1 Score: 0.8443\n",
      "=======================================\n",
      "Wall time: 1.53 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "model = MultinomialNB()\n",
    "model.fit(text_vect_treino, df_treino.sentimento)\n",
    "\n",
    "# vetorização do dataframe de teste\n",
    "text_vect_teste = vect.transform(df_teste.stemmer)\n",
    "\n",
    "# escoragem da classificação na amostra de teste (textos vetorizados)\n",
    "y_predicao = model.predict(text_vect_teste)\n",
    "\n",
    "# mensuração do resultado pela acurácia\n",
    "y_teste = df_teste.sentimento\n",
    "\n",
    "accuracy = accuracy_score(df_teste.sentimento, y_predicao)\n",
    "f1score = f1_score(df_teste.sentimento, y_predicao, average='weighted')\n",
    "print(\"Multinomial NB\")\n",
    "print(f\"Acuracidade: {round(accuracy,4)}\")\n",
    "print(f\"F1 Score: {round(f1score,4)}\")\n",
    "print(\"=======================================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bernoulli NB\n",
      "Acuracidade: 0.8551\n",
      "F1 Score: 0.8551\n",
      "=======================================\n",
      "Wall time: 1.49 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "model = BernoulliNB()\n",
    "model.fit(text_vect_treino, df_treino.sentimento)\n",
    "\n",
    "# vetorização do dataframe de teste\n",
    "text_vect_teste = vect.transform(df_teste.stemmer)\n",
    "\n",
    "# escoragem da classificação na amostra de teste (textos vetorizados)\n",
    "y_predicao = model.predict(text_vect_teste)\n",
    "\n",
    "# mensuração do resultado pela acurácia\n",
    "y_teste = df_teste.sentimento\n",
    "\n",
    "accuracy = accuracy_score(df_teste.sentimento, y_predicao)\n",
    "f1score = f1_score(df_teste.sentimento, y_predicao, average='weighted')\n",
    "print(\"Bernoulli NB\")\n",
    "print(f\"Acuracidade: {round(accuracy,4)}\")\n",
    "print(f\"F1 Score: {round(f1score,4)}\")\n",
    "print(\"=======================================\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CountVectorizer Stemmer / Bigrama / MindF = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "vect = CountVectorizer(ngram_range=(2,2), min_df=10)\n",
    "vect.fit(df_treino.stemmer)\n",
    "text_vect_treino = vect.transform(df_treino.stemmer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree\n",
      "Acuracidade: 0.6862\n",
      "F1 Score: 0.6862\n",
      "=======================================\n",
      "Wall time: 1min 11s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "model = DecisionTreeClassifier(random_state=42)\n",
    "model.fit(text_vect_treino, df_treino.sentimento)\n",
    "\n",
    "# vetorização do dataframe de teste\n",
    "text_vect_teste = vect.transform(df_teste.stemmer)\n",
    "\n",
    "# escoragem da classificação na amostra de teste (textos vetorizados)\n",
    "y_predicao = model.predict(text_vect_teste)\n",
    "\n",
    "# mensuração do resultado pela acurácia\n",
    "y_teste = df_teste.sentimento\n",
    "\n",
    "accuracy = accuracy_score(df_teste.sentimento, y_predicao)\n",
    "f1score = f1_score(df_teste.sentimento, y_predicao, average='weighted')\n",
    "print(\"Decision Tree\")\n",
    "print(f\"Acuracidade: {round(accuracy,4)}\")\n",
    "print(f\"F1 Score: {round(f1score,4)}\")\n",
    "print(\"=======================================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Roberto Tengan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression\n",
      "Acuracidade: 0.8623\n",
      "F1 Score: 0.8623\n",
      "=======================================\n",
      "Wall time: 5.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "model = LogisticRegression(random_state=42)\n",
    "model.fit(text_vect_treino, df_treino.sentimento)\n",
    "\n",
    "# vetorização do dataframe de teste\n",
    "text_vect_teste = vect.transform(df_teste.stemmer)\n",
    "\n",
    "# escoragem da classificação na amostra de teste (textos vetorizados)\n",
    "y_predicao = model.predict(text_vect_teste)\n",
    "\n",
    "# mensuração do resultado pela acurácia\n",
    "y_teste = df_teste.sentimento\n",
    "accuracy = accuracy_score(df_teste.sentimento, y_predicao)\n",
    "f1score = f1_score(df_teste.sentimento, y_predicao, average='weighted')\n",
    "print(\"Logistic Regression\")\n",
    "print(f\"Acuracidade: {round(accuracy,4)}\")\n",
    "print(f\"F1 Score: {round(f1score,4)}\")\n",
    "print(\"=======================================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest\n",
      "Acuracidade: 0.8214\n",
      "F1 Score: 0.8213\n",
      "=======================================\n",
      "Wall time: 35.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "model = RandomForestClassifier(random_state=42, n_jobs=-1)\n",
    "model.fit(text_vect_treino, df_treino.sentimento)\n",
    "\n",
    "# vetorização do dataframe de teste\n",
    "text_vect_teste = vect.transform(df_teste.stemmer)\n",
    "\n",
    "# escoragem da classificação na amostra de teste (textos vetorizados)\n",
    "y_predicao = model.predict(text_vect_teste)\n",
    "\n",
    "# mensuração do resultado pela acurácia\n",
    "y_teste = df_teste.sentimento\n",
    "accuracy = accuracy_score(df_teste.sentimento, y_predicao)\n",
    "f1score = f1_score(df_teste.sentimento, y_predicao, average='weighted')\n",
    "print(\"Random Forest\")\n",
    "print(f\"Acuracidade: {round(accuracy,4)}\")\n",
    "print(f\"F1 Score: {round(f1score,4)}\")\n",
    "print(\"=======================================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multinomial NB\n",
      "Acuracidade: 0.8727\n",
      "F1 Score: 0.8727\n",
      "=======================================\n",
      "Wall time: 2.21 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "model = MultinomialNB()\n",
    "model.fit(text_vect_treino, df_treino.sentimento)\n",
    "\n",
    "# vetorização do dataframe de teste\n",
    "text_vect_teste = vect.transform(df_teste.stemmer)\n",
    "\n",
    "# escoragem da classificação na amostra de teste (textos vetorizados)\n",
    "y_predicao = model.predict(text_vect_teste)\n",
    "\n",
    "# mensuração do resultado pela acurácia\n",
    "y_teste = df_teste.sentimento\n",
    "\n",
    "accuracy = accuracy_score(df_teste.sentimento, y_predicao)\n",
    "f1score = f1_score(df_teste.sentimento, y_predicao, average='weighted')\n",
    "print(\"Multinomial NB\")\n",
    "print(f\"Acuracidade: {round(accuracy,4)}\")\n",
    "print(f\"F1 Score: {round(f1score,4)}\")\n",
    "print(\"=======================================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bernoulli NB\n",
      "Acuracidade: 0.8734\n",
      "F1 Score: 0.8733\n",
      "=======================================\n",
      "Wall time: 2.18 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "model = BernoulliNB()\n",
    "model.fit(text_vect_treino, df_treino.sentimento)\n",
    "\n",
    "# vetorização do dataframe de teste\n",
    "text_vect_teste = vect.transform(df_teste.stemmer)\n",
    "\n",
    "# escoragem da classificação na amostra de teste (textos vetorizados)\n",
    "y_predicao = model.predict(text_vect_teste)\n",
    "\n",
    "# mensuração do resultado pela acurácia\n",
    "y_teste = df_teste.sentimento\n",
    "\n",
    "accuracy = accuracy_score(df_teste.sentimento, y_predicao)\n",
    "f1score = f1_score(df_teste.sentimento, y_predicao, average='weighted')\n",
    "print(\"Bernoulli NB\")\n",
    "print(f\"Acuracidade: {round(accuracy,4)}\")\n",
    "print(f\"F1 Score: {round(f1score,4)}\")\n",
    "print(\"=======================================\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CountVectorizer Stemmer / Unigrama - Bigrama / MindF = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "vect = CountVectorizer(ngram_range=(1,2), min_df=10)\n",
    "vect.fit(df_treino.stemmer)\n",
    "text_vect_treino = vect.transform(df_treino.stemmer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree\n",
      "Acuracidade: 0.6994\n",
      "F1 Score: 0.6994\n",
      "=======================================\n",
      "Wall time: 1min 47s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "model = DecisionTreeClassifier(random_state=42)\n",
    "model.fit(text_vect_treino, df_treino.sentimento)\n",
    "\n",
    "# vetorização do dataframe de teste\n",
    "text_vect_teste = vect.transform(df_teste.stemmer)\n",
    "\n",
    "# escoragem da classificação na amostra de teste (textos vetorizados)\n",
    "y_predicao = model.predict(text_vect_teste)\n",
    "\n",
    "# mensuração do resultado pela acurácia\n",
    "y_teste = df_teste.sentimento\n",
    "\n",
    "accuracy = accuracy_score(df_teste.sentimento, y_predicao)\n",
    "f1score = f1_score(df_teste.sentimento, y_predicao, average='weighted')\n",
    "print(\"Decision Tree\")\n",
    "print(f\"Acuracidade: {round(accuracy,4)}\")\n",
    "print(f\"F1 Score: {round(f1score,4)}\")\n",
    "print(\"=======================================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Roberto Tengan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression\n",
      "Acuracidade: 0.8891\n",
      "F1 Score: 0.8891\n",
      "=======================================\n",
      "Wall time: 8.89 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "model = LogisticRegression(random_state=42)\n",
    "model.fit(text_vect_treino, df_treino.sentimento)\n",
    "\n",
    "# vetorização do dataframe de teste\n",
    "text_vect_teste = vect.transform(df_teste.stemmer)\n",
    "\n",
    "# escoragem da classificação na amostra de teste (textos vetorizados)\n",
    "y_predicao = model.predict(text_vect_teste)\n",
    "\n",
    "# mensuração do resultado pela acurácia\n",
    "y_teste = df_teste.sentimento\n",
    "accuracy = accuracy_score(df_teste.sentimento, y_predicao)\n",
    "f1score = f1_score(df_teste.sentimento, y_predicao, average='weighted')\n",
    "print(\"Logistic Regression\")\n",
    "print(f\"Acuracidade: {round(accuracy,4)}\")\n",
    "print(f\"F1 Score: {round(f1score,4)}\")\n",
    "print(\"=======================================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest\n",
      "Acuracidade: 0.841\n",
      "F1 Score: 0.841\n",
      "=======================================\n",
      "Wall time: 44.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "model = RandomForestClassifier(random_state=42, n_jobs=-1)\n",
    "model.fit(text_vect_treino, df_treino.sentimento)\n",
    "\n",
    "# vetorização do dataframe de teste\n",
    "text_vect_teste = vect.transform(df_teste.stemmer)\n",
    "\n",
    "# escoragem da classificação na amostra de teste (textos vetorizados)\n",
    "y_predicao = model.predict(text_vect_teste)\n",
    "\n",
    "# mensuração do resultado pela acurácia\n",
    "y_teste = df_teste.sentimento\n",
    "accuracy = accuracy_score(df_teste.sentimento, y_predicao)\n",
    "f1score = f1_score(df_teste.sentimento, y_predicao, average='weighted')\n",
    "print(\"Random Forest\")\n",
    "print(f\"Acuracidade: {round(accuracy,4)}\")\n",
    "print(f\"F1 Score: {round(f1score,4)}\")\n",
    "print(\"=======================================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multinomial NB\n",
      "Acuracidade: 0.8713\n",
      "F1 Score: 0.8713\n",
      "=======================================\n",
      "Wall time: 2.92 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "model = MultinomialNB()\n",
    "model.fit(text_vect_treino, df_treino.sentimento)\n",
    "\n",
    "# vetorização do dataframe de teste\n",
    "text_vect_teste = vect.transform(df_teste.stemmer)\n",
    "\n",
    "# escoragem da classificação na amostra de teste (textos vetorizados)\n",
    "y_predicao = model.predict(text_vect_teste)\n",
    "\n",
    "# mensuração do resultado pela acurácia\n",
    "y_teste = df_teste.sentimento\n",
    "\n",
    "accuracy = accuracy_score(df_teste.sentimento, y_predicao)\n",
    "f1score = f1_score(df_teste.sentimento, y_predicao, average='weighted')\n",
    "print(\"Multinomial NB\")\n",
    "print(f\"Acuracidade: {round(accuracy,4)}\")\n",
    "print(f\"F1 Score: {round(f1score,4)}\")\n",
    "print(\"=======================================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bernoulli NB\n",
      "Acuracidade: 0.8731\n",
      "F1 Score: 0.8731\n",
      "=======================================\n",
      "Wall time: 2.98 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "model = BernoulliNB()\n",
    "model.fit(text_vect_treino, df_treino.sentimento)\n",
    "\n",
    "# vetorização do dataframe de teste\n",
    "text_vect_teste = vect.transform(df_teste.stemmer)\n",
    "\n",
    "# escoragem da classificação na amostra de teste (textos vetorizados)\n",
    "y_predicao = model.predict(text_vect_teste)\n",
    "\n",
    "# mensuração do resultado pela acurácia\n",
    "y_teste = df_teste.sentimento\n",
    "\n",
    "accuracy = accuracy_score(df_teste.sentimento, y_predicao)\n",
    "f1score = f1_score(df_teste.sentimento, y_predicao, average='weighted')\n",
    "print(\"Bernoulli NB\")\n",
    "print(f\"Acuracidade: {round(accuracy,4)}\")\n",
    "print(f\"F1 Score: {round(f1score,4)}\")\n",
    "print(\"=======================================\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CountVectorizer Stemmer / Unigrama / MindF = 10 / token_pattern = Palavras com mais de 3 letras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "vect = CountVectorizer(ngram_range=(1,1), min_df=10, token_pattern='[a-zA-Z0-9]{3,}')\n",
    "vect.fit(df_treino.stemmer)\n",
    "text_vect_treino = vect.transform(df_treino.stemmer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree\n",
      "Acuracidade: 0.6912\n",
      "F1 Score: 0.6912\n",
      "=======================================\n",
      "Wall time: 48.6 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "model = DecisionTreeClassifier(random_state=42)\n",
    "model.fit(text_vect_treino, df_treino.sentimento)\n",
    "\n",
    "# vetorização do dataframe de teste\n",
    "text_vect_teste = vect.transform(df_teste.stemmer)\n",
    "\n",
    "# escoragem da classificação na amostra de teste (textos vetorizados)\n",
    "y_predicao = model.predict(text_vect_teste)\n",
    "\n",
    "# mensuração do resultado pela acurácia\n",
    "y_teste = df_teste.sentimento\n",
    "\n",
    "accuracy = accuracy_score(df_teste.sentimento, y_predicao)\n",
    "f1score = f1_score(df_teste.sentimento, y_predicao, average='weighted')\n",
    "print(\"Decision Tree\")\n",
    "print(f\"Acuracidade: {round(accuracy,4)}\")\n",
    "print(f\"F1 Score: {round(f1score,4)}\")\n",
    "print(\"=======================================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Roberto Tengan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression\n",
      "Acuracidade: 0.8767\n",
      "F1 Score: 0.8767\n",
      "=======================================\n",
      "Wall time: 3.13 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "model = LogisticRegression(random_state=42)\n",
    "model.fit(text_vect_treino, df_treino.sentimento)\n",
    "\n",
    "# vetorização do dataframe de teste\n",
    "text_vect_teste = vect.transform(df_teste.stemmer)\n",
    "\n",
    "# escoragem da classificação na amostra de teste (textos vetorizados)\n",
    "y_predicao = model.predict(text_vect_teste)\n",
    "\n",
    "# mensuração do resultado pela acurácia\n",
    "y_teste = df_teste.sentimento\n",
    "accuracy = accuracy_score(df_teste.sentimento, y_predicao)\n",
    "f1score = f1_score(df_teste.sentimento, y_predicao, average='weighted')\n",
    "print(\"Logistic Regression\")\n",
    "print(f\"Acuracidade: {round(accuracy,4)}\")\n",
    "print(f\"F1 Score: {round(f1score,4)}\")\n",
    "print(\"=======================================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest\n",
      "Acuracidade: 0.8325\n",
      "F1 Score: 0.8325\n",
      "=======================================\n",
      "Wall time: 31.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "model = RandomForestClassifier(random_state=42, n_jobs=-1)\n",
    "model.fit(text_vect_treino, df_treino.sentimento)\n",
    "\n",
    "# vetorização do dataframe de teste\n",
    "text_vect_teste = vect.transform(df_teste.stemmer)\n",
    "\n",
    "# escoragem da classificação na amostra de teste (textos vetorizados)\n",
    "y_predicao = model.predict(text_vect_teste)\n",
    "\n",
    "# mensuração do resultado pela acurácia\n",
    "y_teste = df_teste.sentimento\n",
    "accuracy = accuracy_score(df_teste.sentimento, y_predicao)\n",
    "f1score = f1_score(df_teste.sentimento, y_predicao, average='weighted')\n",
    "print(\"Random Forest\")\n",
    "print(f\"Acuracidade: {round(accuracy,4)}\")\n",
    "print(f\"F1 Score: {round(f1score,4)}\")\n",
    "print(\"=======================================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multinomial NB\n",
      "Acuracidade: 0.8434\n",
      "F1 Score: 0.8433\n",
      "=======================================\n",
      "Wall time: 1.18 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "model = MultinomialNB()\n",
    "model.fit(text_vect_treino, df_treino.sentimento)\n",
    "\n",
    "# vetorização do dataframe de teste\n",
    "text_vect_teste = vect.transform(df_teste.stemmer)\n",
    "\n",
    "# escoragem da classificação na amostra de teste (textos vetorizados)\n",
    "y_predicao = model.predict(text_vect_teste)\n",
    "\n",
    "# mensuração do resultado pela acurácia\n",
    "y_teste = df_teste.sentimento\n",
    "\n",
    "accuracy = accuracy_score(df_teste.sentimento, y_predicao)\n",
    "f1score = f1_score(df_teste.sentimento, y_predicao, average='weighted')\n",
    "print(\"Multinomial NB\")\n",
    "print(f\"Acuracidade: {round(accuracy,4)}\")\n",
    "print(f\"F1 Score: {round(f1score,4)}\")\n",
    "print(\"=======================================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bernoulli NB\n",
      "Acuracidade: 0.8536\n",
      "F1 Score: 0.8536\n",
      "=======================================\n",
      "Wall time: 1.18 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "model = BernoulliNB()\n",
    "model.fit(text_vect_treino, df_treino.sentimento)\n",
    "\n",
    "# vetorização do dataframe de teste\n",
    "text_vect_teste = vect.transform(df_teste.stemmer)\n",
    "\n",
    "# escoragem da classificação na amostra de teste (textos vetorizados)\n",
    "y_predicao = model.predict(text_vect_teste)\n",
    "\n",
    "# mensuração do resultado pela acurácia\n",
    "y_teste = df_teste.sentimento\n",
    "\n",
    "accuracy = accuracy_score(df_teste.sentimento, y_predicao)\n",
    "f1score = f1_score(df_teste.sentimento, y_predicao, average='weighted')\n",
    "print(\"Bernoulli NB\")\n",
    "print(f\"Acuracidade: {round(accuracy,4)}\")\n",
    "print(f\"F1 Score: {round(f1score,4)}\")\n",
    "print(\"=======================================\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CountVectorizer Stemmer / Bigrama / MindF = 10 / token_pattern = Palavras com mais de 3 letras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "vect = CountVectorizer(ngram_range=(2,2), min_df=10, token_pattern='[a-zA-Z0-9]{3,}')\n",
    "vect.fit(df_treino.stemmer)\n",
    "text_vect_treino = vect.transform(df_treino.stemmer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree\n",
      "Acuracidade: 0.6904\n",
      "F1 Score: 0.6904\n",
      "=======================================\n",
      "Wall time: 52 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "model = DecisionTreeClassifier(random_state=42)\n",
    "model.fit(text_vect_treino, df_treino.sentimento)\n",
    "\n",
    "# vetorização do dataframe de teste\n",
    "text_vect_teste = vect.transform(df_teste.stemmer)\n",
    "\n",
    "# escoragem da classificação na amostra de teste (textos vetorizados)\n",
    "y_predicao = model.predict(text_vect_teste)\n",
    "\n",
    "# mensuração do resultado pela acurácia\n",
    "y_teste = df_teste.sentimento\n",
    "\n",
    "accuracy = accuracy_score(df_teste.sentimento, y_predicao)\n",
    "f1score = f1_score(df_teste.sentimento, y_predicao, average='weighted')\n",
    "print(\"Decision Tree\")\n",
    "print(f\"Acuracidade: {round(accuracy,4)}\")\n",
    "print(f\"F1 Score: {round(f1score,4)}\")\n",
    "print(\"=======================================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Roberto Tengan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression\n",
      "Acuracidade: 0.8566\n",
      "F1 Score: 0.8566\n",
      "=======================================\n",
      "Wall time: 4.13 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "model = LogisticRegression(random_state=42)\n",
    "model.fit(text_vect_treino, df_treino.sentimento)\n",
    "\n",
    "# vetorização do dataframe de teste\n",
    "text_vect_teste = vect.transform(df_teste.stemmer)\n",
    "\n",
    "# escoragem da classificação na amostra de teste (textos vetorizados)\n",
    "y_predicao = model.predict(text_vect_teste)\n",
    "\n",
    "# mensuração do resultado pela acurácia\n",
    "y_teste = df_teste.sentimento\n",
    "accuracy = accuracy_score(df_teste.sentimento, y_predicao)\n",
    "f1score = f1_score(df_teste.sentimento, y_predicao, average='weighted')\n",
    "print(\"Logistic Regression\")\n",
    "print(f\"Acuracidade: {round(accuracy,4)}\")\n",
    "print(f\"F1 Score: {round(f1score,4)}\")\n",
    "print(\"=======================================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest\n",
      "Acuracidade: 0.8059\n",
      "F1 Score: 0.8057\n",
      "=======================================\n",
      "Wall time: 30.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "model = RandomForestClassifier(random_state=42, n_jobs=-1)\n",
    "model.fit(text_vect_treino, df_treino.sentimento)\n",
    "\n",
    "# vetorização do dataframe de teste\n",
    "text_vect_teste = vect.transform(df_teste.stemmer)\n",
    "\n",
    "# escoragem da classificação na amostra de teste (textos vetorizados)\n",
    "y_predicao = model.predict(text_vect_teste)\n",
    "\n",
    "# mensuração do resultado pela acurácia\n",
    "y_teste = df_teste.sentimento\n",
    "accuracy = accuracy_score(df_teste.sentimento, y_predicao)\n",
    "f1score = f1_score(df_teste.sentimento, y_predicao, average='weighted')\n",
    "print(\"Random Forest\")\n",
    "print(f\"Acuracidade: {round(accuracy,4)}\")\n",
    "print(f\"F1 Score: {round(f1score,4)}\")\n",
    "print(\"=======================================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multinomial NB\n",
      "Acuracidade: 0.8695\n",
      "F1 Score: 0.8695\n",
      "=======================================\n",
      "Wall time: 1.71 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "model = MultinomialNB()\n",
    "model.fit(text_vect_treino, df_treino.sentimento)\n",
    "\n",
    "# vetorização do dataframe de teste\n",
    "text_vect_teste = vect.transform(df_teste.stemmer)\n",
    "\n",
    "# escoragem da classificação na amostra de teste (textos vetorizados)\n",
    "y_predicao = model.predict(text_vect_teste)\n",
    "\n",
    "# mensuração do resultado pela acurácia\n",
    "y_teste = df_teste.sentimento\n",
    "\n",
    "accuracy = accuracy_score(df_teste.sentimento, y_predicao)\n",
    "f1score = f1_score(df_teste.sentimento, y_predicao, average='weighted')\n",
    "print(\"Multinomial NB\")\n",
    "print(f\"Acuracidade: {round(accuracy,4)}\")\n",
    "print(f\"F1 Score: {round(f1score,4)}\")\n",
    "print(\"=======================================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bernoulli NB\n",
      "Acuracidade: 0.8677\n",
      "F1 Score: 0.8676\n",
      "=======================================\n",
      "Wall time: 1.66 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "model = BernoulliNB()\n",
    "model.fit(text_vect_treino, df_treino.sentimento)\n",
    "\n",
    "# vetorização do dataframe de teste\n",
    "text_vect_teste = vect.transform(df_teste.stemmer)\n",
    "\n",
    "# escoragem da classificação na amostra de teste (textos vetorizados)\n",
    "y_predicao = model.predict(text_vect_teste)\n",
    "\n",
    "# mensuração do resultado pela acurácia\n",
    "y_teste = df_teste.sentimento\n",
    "\n",
    "accuracy = accuracy_score(df_teste.sentimento, y_predicao)\n",
    "f1score = f1_score(df_teste.sentimento, y_predicao, average='weighted')\n",
    "print(\"Bernoulli NB\")\n",
    "print(f\"Acuracidade: {round(accuracy,4)}\")\n",
    "print(f\"F1 Score: {round(f1score,4)}\")\n",
    "print(\"=======================================\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CountVectorizer Stemmer / Unigrama - Bigrama / MindF = 10 / token_pattern = Palavras com mais de 3 letras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "vect = CountVectorizer(ngram_range=(1,2), min_df=10, token_pattern='[a-zA-Z0-9]{3,}')\n",
    "vect.fit(df_treino.stemmer)\n",
    "text_vect_treino = vect.transform(df_treino.stemmer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree\n",
      "Acuracidade: 0.6965\n",
      "F1 Score: 0.6965\n",
      "=======================================\n",
      "Wall time: 1min 26s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "model = DecisionTreeClassifier(random_state=42)\n",
    "model.fit(text_vect_treino, df_treino.sentimento)\n",
    "\n",
    "# vetorização do dataframe de teste\n",
    "text_vect_teste = vect.transform(df_teste.stemmer)\n",
    "\n",
    "# escoragem da classificação na amostra de teste (textos vetorizados)\n",
    "y_predicao = model.predict(text_vect_teste)\n",
    "\n",
    "# mensuração do resultado pela acurácia\n",
    "y_teste = df_teste.sentimento\n",
    "\n",
    "accuracy = accuracy_score(df_teste.sentimento, y_predicao)\n",
    "f1score = f1_score(df_teste.sentimento, y_predicao, average='weighted')\n",
    "print(\"Decision Tree\")\n",
    "print(f\"Acuracidade: {round(accuracy,4)}\")\n",
    "print(f\"F1 Score: {round(f1score,4)}\")\n",
    "print(\"=======================================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Roberto Tengan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression\n",
      "Acuracidade: 0.8866\n",
      "F1 Score: 0.8866\n",
      "=======================================\n",
      "Wall time: 7.87 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "model = LogisticRegression(random_state=42)\n",
    "model.fit(text_vect_treino, df_treino.sentimento)\n",
    "\n",
    "# vetorização do dataframe de teste\n",
    "text_vect_teste = vect.transform(df_teste.stemmer)\n",
    "\n",
    "# escoragem da classificação na amostra de teste (textos vetorizados)\n",
    "y_predicao = model.predict(text_vect_teste)\n",
    "\n",
    "# mensuração do resultado pela acurácia\n",
    "y_teste = df_teste.sentimento\n",
    "accuracy = accuracy_score(df_teste.sentimento, y_predicao)\n",
    "f1score = f1_score(df_teste.sentimento, y_predicao, average='weighted')\n",
    "print(\"Logistic Regression\")\n",
    "print(f\"Acuracidade: {round(accuracy,4)}\")\n",
    "print(f\"F1 Score: {round(f1score,4)}\")\n",
    "print(\"=======================================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest\n",
      "Acuracidade: 0.8411\n",
      "F1 Score: 0.8411\n",
      "=======================================\n",
      "Wall time: 43.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "model = RandomForestClassifier(random_state=42, n_jobs=-1)\n",
    "model.fit(text_vect_treino, df_treino.sentimento)\n",
    "\n",
    "# vetorização do dataframe de teste\n",
    "text_vect_teste = vect.transform(df_teste.stemmer)\n",
    "\n",
    "# escoragem da classificação na amostra de teste (textos vetorizados)\n",
    "y_predicao = model.predict(text_vect_teste)\n",
    "\n",
    "# mensuração do resultado pela acurácia\n",
    "y_teste = df_teste.sentimento\n",
    "accuracy = accuracy_score(df_teste.sentimento, y_predicao)\n",
    "f1score = f1_score(df_teste.sentimento, y_predicao, average='weighted')\n",
    "print(\"Random Forest\")\n",
    "print(f\"Acuracidade: {round(accuracy,4)}\")\n",
    "print(f\"F1 Score: {round(f1score,4)}\")\n",
    "print(\"=======================================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multinomial NB\n",
      "Acuracidade: 0.8746\n",
      "F1 Score: 0.8746\n",
      "=======================================\n",
      "Wall time: 3.16 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "model = MultinomialNB()\n",
    "model.fit(text_vect_treino, df_treino.sentimento)\n",
    "\n",
    "# vetorização do dataframe de teste\n",
    "text_vect_teste = vect.transform(df_teste.stemmer)\n",
    "\n",
    "# escoragem da classificação na amostra de teste (textos vetorizados)\n",
    "y_predicao = model.predict(text_vect_teste)\n",
    "\n",
    "# mensuração do resultado pela acurácia\n",
    "y_teste = df_teste.sentimento\n",
    "\n",
    "accuracy = accuracy_score(df_teste.sentimento, y_predicao)\n",
    "f1score = f1_score(df_teste.sentimento, y_predicao, average='weighted')\n",
    "print(\"Multinomial NB\")\n",
    "print(f\"Acuracidade: {round(accuracy,4)}\")\n",
    "print(f\"F1 Score: {round(f1score,4)}\")\n",
    "print(\"=======================================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bernoulli NB\n",
      "Acuracidade: 0.8748\n",
      "F1 Score: 0.8747\n",
      "=======================================\n",
      "Wall time: 3.28 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "model = BernoulliNB()\n",
    "model.fit(text_vect_treino, df_treino.sentimento)\n",
    "\n",
    "# vetorização do dataframe de teste\n",
    "text_vect_teste = vect.transform(df_teste.stemmer)\n",
    "\n",
    "# escoragem da classificação na amostra de teste (textos vetorizados)\n",
    "y_predicao = model.predict(text_vect_teste)\n",
    "\n",
    "# mensuração do resultado pela acurácia\n",
    "y_teste = df_teste.sentimento\n",
    "\n",
    "accuracy = accuracy_score(df_teste.sentimento, y_predicao)\n",
    "f1score = f1_score(df_teste.sentimento, y_predicao, average='weighted')\n",
    "print(\"Bernoulli NB\")\n",
    "print(f\"Acuracidade: {round(accuracy,4)}\")\n",
    "print(f\"F1 Score: {round(f1score,4)}\")\n",
    "print(\"=======================================\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CountVectorizer Lemma Unigrama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "vect = CountVectorizer(ngram_range=(1,1))\n",
    "vect.fit(df_treino.lemma)\n",
    "text_vect_treino = vect.transform(df_treino.lemma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree\n",
      "Acuracidade: 0.712\n",
      "F1 Score: 0.712\n",
      "=======================================\n",
      "Wall time: 1min 5s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "model = DecisionTreeClassifier(random_state=42)\n",
    "model.fit(text_vect_treino, df_treino.sentimento)\n",
    "\n",
    "# vetorização do dataframe de teste\n",
    "text_vect_teste = vect.transform(df_teste.lemma)\n",
    "\n",
    "# escoragem da classificação na amostra de teste (textos vetorizados)\n",
    "y_predicao = model.predict(text_vect_teste)\n",
    "\n",
    "# mensuração do resultado pela acurácia\n",
    "y_teste = df_teste.sentimento\n",
    "\n",
    "accuracy = accuracy_score(df_teste.sentimento, y_predicao)\n",
    "f1score = f1_score(df_teste.sentimento, y_predicao, average='weighted')\n",
    "print(\"Decision Tree\")\n",
    "print(f\"Acuracidade: {round(accuracy,4)}\")\n",
    "print(f\"F1 Score: {round(f1score,4)}\")\n",
    "print(\"=======================================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Roberto Tengan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression\n",
      "Acuracidade: 0.8823\n",
      "F1 Score: 0.8823\n",
      "=======================================\n",
      "Wall time: 4.93 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "model = LogisticRegression(random_state=42)\n",
    "model.fit(text_vect_treino, df_treino.sentimento)\n",
    "\n",
    "# vetorização do dataframe de teste\n",
    "text_vect_teste = vect.transform(df_teste.lemma)\n",
    "\n",
    "# escoragem da classificação na amostra de teste (textos vetorizados)\n",
    "y_predicao = model.predict(text_vect_teste)\n",
    "\n",
    "# mensuração do resultado pela acurácia\n",
    "y_teste = df_teste.sentimento\n",
    "accuracy = accuracy_score(df_teste.sentimento, y_predicao)\n",
    "f1score = f1_score(df_teste.sentimento, y_predicao, average='weighted')\n",
    "print(\"Logistic Regression\")\n",
    "print(f\"Acuracidade: {round(accuracy,4)}\")\n",
    "print(f\"F1 Score: {round(f1score,4)}\")\n",
    "print(\"=======================================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest\n",
      "Acuracidade: 0.8487\n",
      "F1 Score: 0.8487\n",
      "=======================================\n",
      "Wall time: 35.9 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "model = RandomForestClassifier(random_state=42, n_jobs=-1)\n",
    "model.fit(text_vect_treino, df_treino.sentimento)\n",
    "\n",
    "# vetorização do dataframe de teste\n",
    "text_vect_teste = vect.transform(df_teste.lemma)\n",
    "\n",
    "# escoragem da classificação na amostra de teste (textos vetorizados)\n",
    "y_predicao = model.predict(text_vect_teste)\n",
    "\n",
    "# mensuração do resultado pela acurácia\n",
    "y_teste = df_teste.sentimento\n",
    "accuracy = accuracy_score(df_teste.sentimento, y_predicao)\n",
    "f1score = f1_score(df_teste.sentimento, y_predicao, average='weighted')\n",
    "print(\"Random Forest\")\n",
    "print(f\"Acuracidade: {round(accuracy,4)}\")\n",
    "print(f\"F1 Score: {round(f1score,4)}\")\n",
    "print(\"=======================================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multinomial NB\n",
      "Acuracidade: 0.8517\n",
      "F1 Score: 0.8516\n",
      "=======================================\n",
      "Wall time: 1.57 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "model = MultinomialNB()\n",
    "model.fit(text_vect_treino, df_treino.sentimento)\n",
    "\n",
    "# vetorização do dataframe de teste\n",
    "text_vect_teste = vect.transform(df_teste.lemma)\n",
    "\n",
    "# escoragem da classificação na amostra de teste (textos vetorizados)\n",
    "y_predicao = model.predict(text_vect_teste)\n",
    "\n",
    "# mensuração do resultado pela acurácia\n",
    "y_teste = df_teste.sentimento\n",
    "\n",
    "accuracy = accuracy_score(df_teste.sentimento, y_predicao)\n",
    "f1score = f1_score(df_teste.sentimento, y_predicao, average='weighted')\n",
    "print(\"Multinomial NB\")\n",
    "print(f\"Acuracidade: {round(accuracy,4)}\")\n",
    "print(f\"F1 Score: {round(f1score,4)}\")\n",
    "print(\"=======================================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bernoulli NB\n",
      "Acuracidade: 0.8552\n",
      "F1 Score: 0.8551\n",
      "=======================================\n",
      "Wall time: 1.59 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "model = BernoulliNB()\n",
    "model.fit(text_vect_treino, df_treino.sentimento)\n",
    "\n",
    "# vetorização do dataframe de teste\n",
    "text_vect_teste = vect.transform(df_teste.lemma)\n",
    "\n",
    "# escoragem da classificação na amostra de teste (textos vetorizados)\n",
    "y_predicao = model.predict(text_vect_teste)\n",
    "\n",
    "# mensuração do resultado pela acurácia\n",
    "y_teste = df_teste.sentimento\n",
    "\n",
    "accuracy = accuracy_score(df_teste.sentimento, y_predicao)\n",
    "f1score = f1_score(df_teste.sentimento, y_predicao, average='weighted')\n",
    "print(\"Bernoulli NB\")\n",
    "print(f\"Acuracidade: {round(accuracy,4)}\")\n",
    "print(f\"F1 Score: {round(f1score,4)}\")\n",
    "print(\"=======================================\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CountVectorizer Lemma Bigrama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "vect = CountVectorizer(ngram_range=(2,2))\n",
    "vect.fit(df_treino.lemma)\n",
    "text_vect_treino = vect.transform(df_treino.lemma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree\n",
      "Acuracidade: 0.6938\n",
      "F1 Score: 0.6938\n",
      "=======================================\n",
      "Wall time: 5min 2s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "model = DecisionTreeClassifier(random_state=42)\n",
    "model.fit(text_vect_treino, df_treino.sentimento)\n",
    "\n",
    "# vetorização do dataframe de teste\n",
    "text_vect_teste = vect.transform(df_teste.lemma)\n",
    "\n",
    "# escoragem da classificação na amostra de teste (textos vetorizados)\n",
    "y_predicao = model.predict(text_vect_teste)\n",
    "\n",
    "# mensuração do resultado pela acurácia\n",
    "y_teste = df_teste.sentimento\n",
    "\n",
    "accuracy = accuracy_score(df_teste.sentimento, y_predicao)\n",
    "f1score = f1_score(df_teste.sentimento, y_predicao, average='weighted')\n",
    "print(\"Decision Tree\")\n",
    "print(f\"Acuracidade: {round(accuracy,4)}\")\n",
    "print(f\"F1 Score: {round(f1score,4)}\")\n",
    "print(\"=======================================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Roberto Tengan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression\n",
      "Acuracidade: 0.8826\n",
      "F1 Score: 0.8826\n",
      "=======================================\n",
      "Wall time: 40.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "model = LogisticRegression(random_state=42)\n",
    "model.fit(text_vect_treino, df_treino.sentimento)\n",
    "\n",
    "# vetorização do dataframe de teste\n",
    "text_vect_teste = vect.transform(df_teste.lemma)\n",
    "\n",
    "# escoragem da classificação na amostra de teste (textos vetorizados)\n",
    "y_predicao = model.predict(text_vect_teste)\n",
    "\n",
    "# mensuração do resultado pela acurácia\n",
    "y_teste = df_teste.sentimento\n",
    "accuracy = accuracy_score(df_teste.sentimento, y_predicao)\n",
    "f1score = f1_score(df_teste.sentimento, y_predicao, average='weighted')\n",
    "print(\"Logistic Regression\")\n",
    "print(f\"Acuracidade: {round(accuracy,4)}\")\n",
    "print(f\"F1 Score: {round(f1score,4)}\")\n",
    "print(\"=======================================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest\n",
      "Acuracidade: 0.8266\n",
      "F1 Score: 0.8265\n",
      "=======================================\n",
      "Wall time: 7min 16s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "model = RandomForestClassifier(random_state=42, n_jobs=-1)\n",
    "model.fit(text_vect_treino, df_treino.sentimento)\n",
    "\n",
    "# vetorização do dataframe de teste\n",
    "text_vect_teste = vect.transform(df_teste.lemma)\n",
    "\n",
    "# escoragem da classificação na amostra de teste (textos vetorizados)\n",
    "y_predicao = model.predict(text_vect_teste)\n",
    "\n",
    "# mensuração do resultado pela acurácia\n",
    "y_teste = df_teste.sentimento\n",
    "accuracy = accuracy_score(df_teste.sentimento, y_predicao)\n",
    "f1score = f1_score(df_teste.sentimento, y_predicao, average='weighted')\n",
    "print(\"Random Forest\")\n",
    "print(f\"Acuracidade: {round(accuracy,4)}\")\n",
    "print(f\"F1 Score: {round(f1score,4)}\")\n",
    "print(\"=======================================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multinomial NB\n",
      "Acuracidade: 0.8836\n",
      "F1 Score: 0.8835\n",
      "=======================================\n",
      "Wall time: 2.42 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "model = MultinomialNB()\n",
    "model.fit(text_vect_treino, df_treino.sentimento)\n",
    "\n",
    "# vetorização do dataframe de teste\n",
    "text_vect_teste = vect.transform(df_teste.lemma)\n",
    "\n",
    "# escoragem da classificação na amostra de teste (textos vetorizados)\n",
    "y_predicao = model.predict(text_vect_teste)\n",
    "\n",
    "# mensuração do resultado pela acurácia\n",
    "y_teste = df_teste.sentimento\n",
    "\n",
    "accuracy = accuracy_score(df_teste.sentimento, y_predicao)\n",
    "f1score = f1_score(df_teste.sentimento, y_predicao, average='weighted')\n",
    "print(\"Multinomial NB\")\n",
    "print(f\"Acuracidade: {round(accuracy,4)}\")\n",
    "print(f\"F1 Score: {round(f1score,4)}\")\n",
    "print(\"=======================================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bernoulli NB\n",
      "Acuracidade: 0.8822\n",
      "F1 Score: 0.882\n",
      "=======================================\n",
      "Wall time: 2.49 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "model = BernoulliNB()\n",
    "model.fit(text_vect_treino, df_treino.sentimento)\n",
    "\n",
    "# vetorização do dataframe de teste\n",
    "text_vect_teste = vect.transform(df_teste.lemma)\n",
    "\n",
    "# escoragem da classificação na amostra de teste (textos vetorizados)\n",
    "y_predicao = model.predict(text_vect_teste)\n",
    "\n",
    "# mensuração do resultado pela acurácia\n",
    "y_teste = df_teste.sentimento\n",
    "\n",
    "accuracy = accuracy_score(df_teste.sentimento, y_predicao)\n",
    "f1score = f1_score(df_teste.sentimento, y_predicao, average='weighted')\n",
    "print(\"Bernoulli NB\")\n",
    "print(f\"Acuracidade: {round(accuracy,4)}\")\n",
    "print(f\"F1 Score: {round(f1score,4)}\")\n",
    "print(\"=======================================\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CountVectorizer Lemma / Unigrama - Bigrama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "vect = CountVectorizer(ngram_range=(1,2))\n",
    "vect.fit(df_treino.lemma)\n",
    "text_vect_treino = vect.transform(df_treino.lemma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree\n",
      "Acuracidade: 0.7195\n",
      "F1 Score: 0.7195\n",
      "=======================================\n",
      "Wall time: 5min 14s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "model = DecisionTreeClassifier(random_state=42)\n",
    "model.fit(text_vect_treino, df_treino.sentimento)\n",
    "\n",
    "# vetorização do dataframe de teste\n",
    "text_vect_teste = vect.transform(df_teste.lemma)\n",
    "\n",
    "# escoragem da classificação na amostra de teste (textos vetorizados)\n",
    "y_predicao = model.predict(text_vect_teste)\n",
    "\n",
    "# mensuração do resultado pela acurácia\n",
    "y_teste = df_teste.sentimento\n",
    "\n",
    "accuracy = accuracy_score(df_teste.sentimento, y_predicao)\n",
    "f1score = f1_score(df_teste.sentimento, y_predicao, average='weighted')\n",
    "print(\"Decision Tree\")\n",
    "print(f\"Acuracidade: {round(accuracy,4)}\")\n",
    "print(f\"F1 Score: {round(f1score,4)}\")\n",
    "print(\"=======================================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Roberto Tengan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression\n",
      "Acuracidade: 0.9007\n",
      "F1 Score: 0.9007\n",
      "=======================================\n",
      "Wall time: 48.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "model = LogisticRegression(random_state=42)\n",
    "model.fit(text_vect_treino, df_treino.sentimento)\n",
    "\n",
    "# vetorização do dataframe de teste\n",
    "text_vect_teste = vect.transform(df_teste.lemma)\n",
    "\n",
    "# escoragem da classificação na amostra de teste (textos vetorizados)\n",
    "y_predicao = model.predict(text_vect_teste)\n",
    "\n",
    "# mensuração do resultado pela acurácia\n",
    "y_teste = df_teste.sentimento\n",
    "accuracy = accuracy_score(df_teste.sentimento, y_predicao)\n",
    "f1score = f1_score(df_teste.sentimento, y_predicao, average='weighted')\n",
    "print(\"Logistic Regression\")\n",
    "print(f\"Acuracidade: {round(accuracy,4)}\")\n",
    "print(f\"F1 Score: {round(f1score,4)}\")\n",
    "print(\"=======================================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest\n",
      "Acuracidade: 0.8516\n",
      "F1 Score: 0.8516\n",
      "=======================================\n",
      "Wall time: 5min 8s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "model = RandomForestClassifier(random_state=42, n_jobs=-1)\n",
    "model.fit(text_vect_treino, df_treino.sentimento)\n",
    "\n",
    "# vetorização do dataframe de teste\n",
    "text_vect_teste = vect.transform(df_teste.lemma)\n",
    "\n",
    "# escoragem da classificação na amostra de teste (textos vetorizados)\n",
    "y_predicao = model.predict(text_vect_teste)\n",
    "\n",
    "# mensuração do resultado pela acurácia\n",
    "y_teste = df_teste.sentimento\n",
    "accuracy = accuracy_score(df_teste.sentimento, y_predicao)\n",
    "f1score = f1_score(df_teste.sentimento, y_predicao, average='weighted')\n",
    "print(\"Random Forest\")\n",
    "print(f\"Acuracidade: {round(accuracy,4)}\")\n",
    "print(f\"F1 Score: {round(f1score,4)}\")\n",
    "print(\"=======================================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multinomial NB\n",
      "Acuracidade: 0.8811\n",
      "F1 Score: 0.8809\n",
      "=======================================\n",
      "Wall time: 3.26 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "model = MultinomialNB()\n",
    "model.fit(text_vect_treino, df_treino.sentimento)\n",
    "\n",
    "# vetorização do dataframe de teste\n",
    "text_vect_teste = vect.transform(df_teste.lemma)\n",
    "\n",
    "# escoragem da classificação na amostra de teste (textos vetorizados)\n",
    "y_predicao = model.predict(text_vect_teste)\n",
    "\n",
    "# mensuração do resultado pela acurácia\n",
    "y_teste = df_teste.sentimento\n",
    "\n",
    "accuracy = accuracy_score(df_teste.sentimento, y_predicao)\n",
    "f1score = f1_score(df_teste.sentimento, y_predicao, average='weighted')\n",
    "print(\"Multinomial NB\")\n",
    "print(f\"Acuracidade: {round(accuracy,4)}\")\n",
    "print(f\"F1 Score: {round(f1score,4)}\")\n",
    "print(\"=======================================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bernoulli NB\n",
      "Acuracidade: 0.8819\n",
      "F1 Score: 0.8818\n",
      "=======================================\n",
      "Wall time: 3.35 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "model = BernoulliNB()\n",
    "model.fit(text_vect_treino, df_treino.sentimento)\n",
    "\n",
    "# vetorização do dataframe de teste\n",
    "text_vect_teste = vect.transform(df_teste.lemma)\n",
    "\n",
    "# escoragem da classificação na amostra de teste (textos vetorizados)\n",
    "y_predicao = model.predict(text_vect_teste)\n",
    "\n",
    "# mensuração do resultado pela acurácia\n",
    "y_teste = df_teste.sentimento\n",
    "\n",
    "accuracy = accuracy_score(df_teste.sentimento, y_predicao)\n",
    "f1score = f1_score(df_teste.sentimento, y_predicao, average='weighted')\n",
    "print(\"Bernoulli NB\")\n",
    "print(f\"Acuracidade: {round(accuracy,4)}\")\n",
    "print(f\"F1 Score: {round(f1score,4)}\")\n",
    "print(\"=======================================\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CountVectorizer Lemma / Unigrama / MindF = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "vect = CountVectorizer(ngram_range=(1,1), min_df=10)\n",
    "vect.fit(df_treino.lemma)\n",
    "text_vect_treino = vect.transform(df_treino.lemma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree\n",
      "Acuracidade: 0.7113\n",
      "F1 Score: 0.7113\n",
      "=======================================\n",
      "Wall time: 49.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "model = DecisionTreeClassifier(random_state=42)\n",
    "model.fit(text_vect_treino, df_treino.sentimento)\n",
    "\n",
    "# vetorização do dataframe de teste\n",
    "text_vect_teste = vect.transform(df_teste.lemma)\n",
    "\n",
    "# escoragem da classificação na amostra de teste (textos vetorizados)\n",
    "y_predicao = model.predict(text_vect_teste)\n",
    "\n",
    "# mensuração do resultado pela acurácia\n",
    "y_teste = df_teste.sentimento\n",
    "\n",
    "accuracy = accuracy_score(df_teste.sentimento, y_predicao)\n",
    "f1score = f1_score(df_teste.sentimento, y_predicao, average='weighted')\n",
    "print(\"Decision Tree\")\n",
    "print(f\"Acuracidade: {round(accuracy,4)}\")\n",
    "print(f\"F1 Score: {round(f1score,4)}\")\n",
    "print(\"=======================================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Roberto Tengan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression\n",
      "Acuracidade: 0.8754\n",
      "F1 Score: 0.8754\n",
      "=======================================\n",
      "Wall time: 3.52 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "model = LogisticRegression(random_state=42)\n",
    "model.fit(text_vect_treino, df_treino.sentimento)\n",
    "\n",
    "# vetorização do dataframe de teste\n",
    "text_vect_teste = vect.transform(df_teste.lemma)\n",
    "\n",
    "# escoragem da classificação na amostra de teste (textos vetorizados)\n",
    "y_predicao = model.predict(text_vect_teste)\n",
    "\n",
    "# mensuração do resultado pela acurácia\n",
    "y_teste = df_teste.sentimento\n",
    "accuracy = accuracy_score(df_teste.sentimento, y_predicao)\n",
    "f1score = f1_score(df_teste.sentimento, y_predicao, average='weighted')\n",
    "print(\"Logistic Regression\")\n",
    "print(f\"Acuracidade: {round(accuracy,4)}\")\n",
    "print(f\"F1 Score: {round(f1score,4)}\")\n",
    "print(\"=======================================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest\n",
      "Acuracidade: 0.8401\n",
      "F1 Score: 0.84\n",
      "=======================================\n",
      "Wall time: 30.9 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "model = RandomForestClassifier(random_state=42, n_jobs=-1)\n",
    "model.fit(text_vect_treino, df_treino.sentimento)\n",
    "\n",
    "# vetorização do dataframe de teste\n",
    "text_vect_teste = vect.transform(df_teste.lemma)\n",
    "\n",
    "# escoragem da classificação na amostra de teste (textos vetorizados)\n",
    "y_predicao = model.predict(text_vect_teste)\n",
    "\n",
    "# mensuração do resultado pela acurácia\n",
    "y_teste = df_teste.sentimento\n",
    "accuracy = accuracy_score(df_teste.sentimento, y_predicao)\n",
    "f1score = f1_score(df_teste.sentimento, y_predicao, average='weighted')\n",
    "print(\"Random Forest\")\n",
    "print(f\"Acuracidade: {round(accuracy,4)}\")\n",
    "print(f\"F1 Score: {round(f1score,4)}\")\n",
    "print(\"=======================================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multinomial NB\n",
      "Acuracidade: 0.8463\n",
      "F1 Score: 0.8463\n",
      "=======================================\n",
      "Wall time: 1.53 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "model = MultinomialNB()\n",
    "model.fit(text_vect_treino, df_treino.sentimento)\n",
    "\n",
    "# vetorização do dataframe de teste\n",
    "text_vect_teste = vect.transform(df_teste.lemma)\n",
    "\n",
    "# escoragem da classificação na amostra de teste (textos vetorizados)\n",
    "y_predicao = model.predict(text_vect_teste)\n",
    "\n",
    "# mensuração do resultado pela acurácia\n",
    "y_teste = df_teste.sentimento\n",
    "\n",
    "accuracy = accuracy_score(df_teste.sentimento, y_predicao)\n",
    "f1score = f1_score(df_teste.sentimento, y_predicao, average='weighted')\n",
    "print(\"Multinomial NB\")\n",
    "print(f\"Acuracidade: {round(accuracy,4)}\")\n",
    "print(f\"F1 Score: {round(f1score,4)}\")\n",
    "print(\"=======================================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bernoulli NB\n",
      "Acuracidade: 0.8524\n",
      "F1 Score: 0.8524\n",
      "=======================================\n",
      "Wall time: 1.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "model = BernoulliNB()\n",
    "model.fit(text_vect_treino, df_treino.sentimento)\n",
    "\n",
    "# vetorização do dataframe de teste\n",
    "text_vect_teste = vect.transform(df_teste.lemma)\n",
    "\n",
    "# escoragem da classificação na amostra de teste (textos vetorizados)\n",
    "y_predicao = model.predict(text_vect_teste)\n",
    "\n",
    "# mensuração do resultado pela acurácia\n",
    "y_teste = df_teste.sentimento\n",
    "\n",
    "accuracy = accuracy_score(df_teste.sentimento, y_predicao)\n",
    "f1score = f1_score(df_teste.sentimento, y_predicao, average='weighted')\n",
    "print(\"Bernoulli NB\")\n",
    "print(f\"Acuracidade: {round(accuracy,4)}\")\n",
    "print(f\"F1 Score: {round(f1score,4)}\")\n",
    "print(\"=======================================\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CountVectorizer Lemma / Bigrama / MindF = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "vect = CountVectorizer(ngram_range=(2,2), min_df=10)\n",
    "vect.fit(df_treino.lemma)\n",
    "text_vect_treino = vect.transform(df_treino.lemma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree\n",
      "Acuracidade: 0.6857\n",
      "F1 Score: 0.6857\n",
      "=======================================\n",
      "Wall time: 1min 14s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "model = DecisionTreeClassifier(random_state=42)\n",
    "model.fit(text_vect_treino, df_treino.sentimento)\n",
    "\n",
    "# vetorização do dataframe de teste\n",
    "text_vect_teste = vect.transform(df_teste.lemma)\n",
    "\n",
    "# escoragem da classificação na amostra de teste (textos vetorizados)\n",
    "y_predicao = model.predict(text_vect_teste)\n",
    "\n",
    "# mensuração do resultado pela acurácia\n",
    "y_teste = df_teste.sentimento\n",
    "\n",
    "accuracy = accuracy_score(df_teste.sentimento, y_predicao)\n",
    "f1score = f1_score(df_teste.sentimento, y_predicao, average='weighted')\n",
    "print(\"Decision Tree\")\n",
    "print(f\"Acuracidade: {round(accuracy,4)}\")\n",
    "print(f\"F1 Score: {round(f1score,4)}\")\n",
    "print(\"=======================================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Roberto Tengan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression\n",
      "Acuracidade: 0.8782\n",
      "F1 Score: 0.8782\n",
      "=======================================\n",
      "Wall time: 6.96 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "model = LogisticRegression(random_state=42)\n",
    "model.fit(text_vect_treino, df_treino.sentimento)\n",
    "\n",
    "# vetorização do dataframe de teste\n",
    "text_vect_teste = vect.transform(df_teste.lemma)\n",
    "\n",
    "# escoragem da classificação na amostra de teste (textos vetorizados)\n",
    "y_predicao = model.predict(text_vect_teste)\n",
    "\n",
    "# mensuração do resultado pela acurácia\n",
    "y_teste = df_teste.sentimento\n",
    "accuracy = accuracy_score(df_teste.sentimento, y_predicao)\n",
    "f1score = f1_score(df_teste.sentimento, y_predicao, average='weighted')\n",
    "print(\"Logistic Regression\")\n",
    "print(f\"Acuracidade: {round(accuracy,4)}\")\n",
    "print(f\"F1 Score: {round(f1score,4)}\")\n",
    "print(\"=======================================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest\n",
      "Acuracidade: 0.8308\n",
      "F1 Score: 0.8308\n",
      "=======================================\n",
      "Wall time: 39 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "model = RandomForestClassifier(random_state=42, n_jobs=-1)\n",
    "model.fit(text_vect_treino, df_treino.sentimento)\n",
    "\n",
    "# vetorização do dataframe de teste\n",
    "text_vect_teste = vect.transform(df_teste.lemma)\n",
    "\n",
    "# escoragem da classificação na amostra de teste (textos vetorizados)\n",
    "y_predicao = model.predict(text_vect_teste)\n",
    "\n",
    "# mensuração do resultado pela acurácia\n",
    "y_teste = df_teste.sentimento\n",
    "accuracy = accuracy_score(df_teste.sentimento, y_predicao)\n",
    "f1score = f1_score(df_teste.sentimento, y_predicao, average='weighted')\n",
    "print(\"Random Forest\")\n",
    "print(f\"Acuracidade: {round(accuracy,4)}\")\n",
    "print(f\"F1 Score: {round(f1score,4)}\")\n",
    "print(\"=======================================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multinomial NB\n",
      "Acuracidade: 0.8767\n",
      "F1 Score: 0.8767\n",
      "=======================================\n",
      "Wall time: 3.16 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "model = MultinomialNB()\n",
    "model.fit(text_vect_treino, df_treino.sentimento)\n",
    "\n",
    "# vetorização do dataframe de teste\n",
    "text_vect_teste = vect.transform(df_teste.lemma)\n",
    "\n",
    "# escoragem da classificação na amostra de teste (textos vetorizados)\n",
    "y_predicao = model.predict(text_vect_teste)\n",
    "\n",
    "# mensuração do resultado pela acurácia\n",
    "y_teste = df_teste.sentimento\n",
    "\n",
    "accuracy = accuracy_score(df_teste.sentimento, y_predicao)\n",
    "f1score = f1_score(df_teste.sentimento, y_predicao, average='weighted')\n",
    "print(\"Multinomial NB\")\n",
    "print(f\"Acuracidade: {round(accuracy,4)}\")\n",
    "print(f\"F1 Score: {round(f1score,4)}\")\n",
    "print(\"=======================================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bernoulli NB\n",
      "Acuracidade: 0.8722\n",
      "F1 Score: 0.8721\n",
      "=======================================\n",
      "Wall time: 3.14 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "model = BernoulliNB()\n",
    "model.fit(text_vect_treino, df_treino.sentimento)\n",
    "\n",
    "# vetorização do dataframe de teste\n",
    "text_vect_teste = vect.transform(df_teste.lemma)\n",
    "\n",
    "# escoragem da classificação na amostra de teste (textos vetorizados)\n",
    "y_predicao = model.predict(text_vect_teste)\n",
    "\n",
    "# mensuração do resultado pela acurácia\n",
    "y_teste = df_teste.sentimento\n",
    "\n",
    "accuracy = accuracy_score(df_teste.sentimento, y_predicao)\n",
    "f1score = f1_score(df_teste.sentimento, y_predicao, average='weighted')\n",
    "print(\"Bernoulli NB\")\n",
    "print(f\"Acuracidade: {round(accuracy,4)}\")\n",
    "print(f\"F1 Score: {round(f1score,4)}\")\n",
    "print(\"=======================================\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CountVectorizer Lemma / Unigrama - Bigrama / MindF = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "vect = CountVectorizer(ngram_range=(1,2), min_df=10)\n",
    "vect.fit(df_treino.lemma)\n",
    "text_vect_treino = vect.transform(df_treino.lemma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree\n",
      "Acuracidade: 0.7213\n",
      "F1 Score: 0.7213\n",
      "=======================================\n",
      "Wall time: 2min 9s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "model = DecisionTreeClassifier(random_state=42)\n",
    "model.fit(text_vect_treino, df_treino.sentimento)\n",
    "\n",
    "# vetorização do dataframe de teste\n",
    "text_vect_teste = vect.transform(df_teste.lemma)\n",
    "\n",
    "# escoragem da classificação na amostra de teste (textos vetorizados)\n",
    "y_predicao = model.predict(text_vect_teste)\n",
    "\n",
    "# mensuração do resultado pela acurácia\n",
    "y_teste = df_teste.sentimento\n",
    "\n",
    "accuracy = accuracy_score(df_teste.sentimento, y_predicao)\n",
    "f1score = f1_score(df_teste.sentimento, y_predicao, average='weighted')\n",
    "print(\"Decision Tree\")\n",
    "print(f\"Acuracidade: {round(accuracy,4)}\")\n",
    "print(f\"F1 Score: {round(f1score,4)}\")\n",
    "print(\"=======================================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Roberto Tengan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression\n",
      "Acuracidade: 0.8921\n",
      "F1 Score: 0.8921\n",
      "=======================================\n",
      "Wall time: 8.66 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "model = LogisticRegression(random_state=42)\n",
    "model.fit(text_vect_treino, df_treino.sentimento)\n",
    "\n",
    "# vetorização do dataframe de teste\n",
    "text_vect_teste = vect.transform(df_teste.lemma)\n",
    "\n",
    "# escoragem da classificação na amostra de teste (textos vetorizados)\n",
    "y_predicao = model.predict(text_vect_teste)\n",
    "\n",
    "# mensuração do resultado pela acurácia\n",
    "y_teste = df_teste.sentimento\n",
    "accuracy = accuracy_score(df_teste.sentimento, y_predicao)\n",
    "f1score = f1_score(df_teste.sentimento, y_predicao, average='weighted')\n",
    "print(\"Logistic Regression\")\n",
    "print(f\"Acuracidade: {round(accuracy,4)}\")\n",
    "print(f\"F1 Score: {round(f1score,4)}\")\n",
    "print(\"=======================================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest\n",
      "Acuracidade: 0.8518\n",
      "F1 Score: 0.8518\n",
      "=======================================\n",
      "Wall time: 42.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "model = RandomForestClassifier(random_state=42, n_jobs=-1)\n",
    "model.fit(text_vect_treino, df_treino.sentimento)\n",
    "\n",
    "# vetorização do dataframe de teste\n",
    "text_vect_teste = vect.transform(df_teste.lemma)\n",
    "\n",
    "# escoragem da classificação na amostra de teste (textos vetorizados)\n",
    "y_predicao = model.predict(text_vect_teste)\n",
    "\n",
    "# mensuração do resultado pela acurácia\n",
    "y_teste = df_teste.sentimento\n",
    "accuracy = accuracy_score(df_teste.sentimento, y_predicao)\n",
    "f1score = f1_score(df_teste.sentimento, y_predicao, average='weighted')\n",
    "print(\"Random Forest\")\n",
    "print(f\"Acuracidade: {round(accuracy,4)}\")\n",
    "print(f\"F1 Score: {round(f1score,4)}\")\n",
    "print(\"=======================================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multinomial NB\n",
      "Acuracidade: 0.8699\n",
      "F1 Score: 0.8699\n",
      "=======================================\n",
      "Wall time: 2.91 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "model = MultinomialNB()\n",
    "model.fit(text_vect_treino, df_treino.sentimento)\n",
    "\n",
    "# vetorização do dataframe de teste\n",
    "text_vect_teste = vect.transform(df_teste.lemma)\n",
    "\n",
    "# escoragem da classificação na amostra de teste (textos vetorizados)\n",
    "y_predicao = model.predict(text_vect_teste)\n",
    "\n",
    "# mensuração do resultado pela acurácia\n",
    "y_teste = df_teste.sentimento\n",
    "\n",
    "accuracy = accuracy_score(df_teste.sentimento, y_predicao)\n",
    "f1score = f1_score(df_teste.sentimento, y_predicao, average='weighted')\n",
    "print(\"Multinomial NB\")\n",
    "print(f\"Acuracidade: {round(accuracy,4)}\")\n",
    "print(f\"F1 Score: {round(f1score,4)}\")\n",
    "print(\"=======================================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bernoulli NB\n",
      "Acuracidade: 0.8759\n",
      "F1 Score: 0.8759\n",
      "=======================================\n",
      "Wall time: 2.97 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "model = BernoulliNB()\n",
    "model.fit(text_vect_treino, df_treino.sentimento)\n",
    "\n",
    "# vetorização do dataframe de teste\n",
    "text_vect_teste = vect.transform(df_teste.lemma)\n",
    "\n",
    "# escoragem da classificação na amostra de teste (textos vetorizados)\n",
    "y_predicao = model.predict(text_vect_teste)\n",
    "\n",
    "# mensuração do resultado pela acurácia\n",
    "y_teste = df_teste.sentimento\n",
    "\n",
    "accuracy = accuracy_score(df_teste.sentimento, y_predicao)\n",
    "f1score = f1_score(df_teste.sentimento, y_predicao, average='weighted')\n",
    "print(\"Bernoulli NB\")\n",
    "print(f\"Acuracidade: {round(accuracy,4)}\")\n",
    "print(f\"F1 Score: {round(f1score,4)}\")\n",
    "print(\"=======================================\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CountVectorizer Lemma / Unigrama / MindF = 10 / token_pattern = Palavras com mais de 3 letras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "vect = CountVectorizer(ngram_range=(1,1), min_df=10, token_pattern='[a-zA-Z0-9]{3,}')\n",
    "vect.fit(df_treino.lemma)\n",
    "text_vect_treino = vect.transform(df_treino.lemma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree\n",
      "Acuracidade: 0.7116\n",
      "F1 Score: 0.7116\n",
      "=======================================\n",
      "Wall time: 47.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "model = DecisionTreeClassifier(random_state=42)\n",
    "model.fit(text_vect_treino, df_treino.sentimento)\n",
    "\n",
    "# vetorização do dataframe de teste\n",
    "text_vect_teste = vect.transform(df_teste.lemma)\n",
    "\n",
    "# escoragem da classificação na amostra de teste (textos vetorizados)\n",
    "y_predicao = model.predict(text_vect_teste)\n",
    "\n",
    "# mensuração do resultado pela acurácia\n",
    "y_teste = df_teste.sentimento\n",
    "\n",
    "accuracy = accuracy_score(df_teste.sentimento, y_predicao)\n",
    "f1score = f1_score(df_teste.sentimento, y_predicao, average='weighted')\n",
    "print(\"Decision Tree\")\n",
    "print(f\"Acuracidade: {round(accuracy,4)}\")\n",
    "print(f\"F1 Score: {round(f1score,4)}\")\n",
    "print(\"=======================================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Roberto Tengan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression\n",
      "Acuracidade: 0.8768\n",
      "F1 Score: 0.8768\n",
      "=======================================\n",
      "Wall time: 3.22 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "model = LogisticRegression(random_state=42)\n",
    "model.fit(text_vect_treino, df_treino.sentimento)\n",
    "\n",
    "# vetorização do dataframe de teste\n",
    "text_vect_teste = vect.transform(df_teste.lemma)\n",
    "\n",
    "# escoragem da classificação na amostra de teste (textos vetorizados)\n",
    "y_predicao = model.predict(text_vect_teste)\n",
    "\n",
    "# mensuração do resultado pela acurácia\n",
    "y_teste = df_teste.sentimento\n",
    "accuracy = accuracy_score(df_teste.sentimento, y_predicao)\n",
    "f1score = f1_score(df_teste.sentimento, y_predicao, average='weighted')\n",
    "print(\"Logistic Regression\")\n",
    "print(f\"Acuracidade: {round(accuracy,4)}\")\n",
    "print(f\"F1 Score: {round(f1score,4)}\")\n",
    "print(\"=======================================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest\n",
      "Acuracidade: 0.8414\n",
      "F1 Score: 0.8414\n",
      "=======================================\n",
      "Wall time: 31.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "model = RandomForestClassifier(random_state=42, n_jobs=-1)\n",
    "model.fit(text_vect_treino, df_treino.sentimento)\n",
    "\n",
    "# vetorização do dataframe de teste\n",
    "text_vect_teste = vect.transform(df_teste.lemma)\n",
    "\n",
    "# escoragem da classificação na amostra de teste (textos vetorizados)\n",
    "y_predicao = model.predict(text_vect_teste)\n",
    "\n",
    "# mensuração do resultado pela acurácia\n",
    "y_teste = df_teste.sentimento\n",
    "accuracy = accuracy_score(df_teste.sentimento, y_predicao)\n",
    "f1score = f1_score(df_teste.sentimento, y_predicao, average='weighted')\n",
    "print(\"Random Forest\")\n",
    "print(f\"Acuracidade: {round(accuracy,4)}\")\n",
    "print(f\"F1 Score: {round(f1score,4)}\")\n",
    "print(\"=======================================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multinomial NB\n",
      "Acuracidade: 0.8479\n",
      "F1 Score: 0.8478\n",
      "=======================================\n",
      "Wall time: 1.31 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "model = MultinomialNB()\n",
    "model.fit(text_vect_treino, df_treino.sentimento)\n",
    "\n",
    "# vetorização do dataframe de teste\n",
    "text_vect_teste = vect.transform(df_teste.lemma)\n",
    "\n",
    "# escoragem da classificação na amostra de teste (textos vetorizados)\n",
    "y_predicao = model.predict(text_vect_teste)\n",
    "\n",
    "# mensuração do resultado pela acurácia\n",
    "y_teste = df_teste.sentimento\n",
    "\n",
    "accuracy = accuracy_score(df_teste.sentimento, y_predicao)\n",
    "f1score = f1_score(df_teste.sentimento, y_predicao, average='weighted')\n",
    "print(\"Multinomial NB\")\n",
    "print(f\"Acuracidade: {round(accuracy,4)}\")\n",
    "print(f\"F1 Score: {round(f1score,4)}\")\n",
    "print(\"=======================================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bernoulli NB\n",
      "Acuracidade: 0.852\n",
      "F1 Score: 0.8519\n",
      "=======================================\n",
      "Wall time: 1.23 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "model = BernoulliNB()\n",
    "model.fit(text_vect_treino, df_treino.sentimento)\n",
    "\n",
    "# vetorização do dataframe de teste\n",
    "text_vect_teste = vect.transform(df_teste.lemma)\n",
    "\n",
    "# escoragem da classificação na amostra de teste (textos vetorizados)\n",
    "y_predicao = model.predict(text_vect_teste)\n",
    "\n",
    "# mensuração do resultado pela acurácia\n",
    "y_teste = df_teste.sentimento\n",
    "\n",
    "accuracy = accuracy_score(df_teste.sentimento, y_predicao)\n",
    "f1score = f1_score(df_teste.sentimento, y_predicao, average='weighted')\n",
    "print(\"Bernoulli NB\")\n",
    "print(f\"Acuracidade: {round(accuracy,4)}\")\n",
    "print(f\"F1 Score: {round(f1score,4)}\")\n",
    "print(\"=======================================\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CountVectorizer Lemma / Bigrama / MindF = 10 / token_pattern = Palavras com mais de 3 letras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "vect = CountVectorizer(ngram_range=(2,2), min_df=10, token_pattern='[a-zA-Z0-9]{3,}')\n",
    "vect.fit(df_treino.lemma)\n",
    "text_vect_treino = vect.transform(df_treino.lemma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree\n",
      "Acuracidade: 0.7208\n",
      "F1 Score: 0.7207\n",
      "=======================================\n",
      "Wall time: 57.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "model = DecisionTreeClassifier(random_state=42)\n",
    "model.fit(text_vect_treino, df_treino.sentimento)\n",
    "\n",
    "# vetorização do dataframe de teste\n",
    "text_vect_teste = vect.transform(df_teste.lemma)\n",
    "\n",
    "# escoragem da classificação na amostra de teste (textos vetorizados)\n",
    "y_predicao = model.predict(text_vect_teste)\n",
    "\n",
    "# mensuração do resultado pela acurácia\n",
    "y_teste = df_teste.sentimento\n",
    "\n",
    "accuracy = accuracy_score(df_teste.sentimento, y_predicao)\n",
    "f1score = f1_score(df_teste.sentimento, y_predicao, average='weighted')\n",
    "print(\"Decision Tree\")\n",
    "print(f\"Acuracidade: {round(accuracy,4)}\")\n",
    "print(f\"F1 Score: {round(f1score,4)}\")\n",
    "print(\"=======================================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Roberto Tengan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression\n",
      "Acuracidade: 0.8702\n",
      "F1 Score: 0.8701\n",
      "=======================================\n",
      "Wall time: 4.61 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "model = LogisticRegression(random_state=42)\n",
    "model.fit(text_vect_treino, df_treino.sentimento)\n",
    "\n",
    "# vetorização do dataframe de teste\n",
    "text_vect_teste = vect.transform(df_teste.lemma)\n",
    "\n",
    "# escoragem da classificação na amostra de teste (textos vetorizados)\n",
    "y_predicao = model.predict(text_vect_teste)\n",
    "\n",
    "# mensuração do resultado pela acurácia\n",
    "y_teste = df_teste.sentimento\n",
    "accuracy = accuracy_score(df_teste.sentimento, y_predicao)\n",
    "f1score = f1_score(df_teste.sentimento, y_predicao, average='weighted')\n",
    "print(\"Logistic Regression\")\n",
    "print(f\"Acuracidade: {round(accuracy,4)}\")\n",
    "print(f\"F1 Score: {round(f1score,4)}\")\n",
    "print(\"=======================================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest\n",
      "Acuracidade: 0.8287\n",
      "F1 Score: 0.8287\n",
      "=======================================\n",
      "Wall time: 30.9 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "model = RandomForestClassifier(random_state=42, n_jobs=-1)\n",
    "model.fit(text_vect_treino, df_treino.sentimento)\n",
    "\n",
    "# vetorização do dataframe de teste\n",
    "text_vect_teste = vect.transform(df_teste.lemma)\n",
    "\n",
    "# escoragem da classificação na amostra de teste (textos vetorizados)\n",
    "y_predicao = model.predict(text_vect_teste)\n",
    "\n",
    "# mensuração do resultado pela acurácia\n",
    "y_teste = df_teste.sentimento\n",
    "accuracy = accuracy_score(df_teste.sentimento, y_predicao)\n",
    "f1score = f1_score(df_teste.sentimento, y_predicao, average='weighted')\n",
    "print(\"Random Forest\")\n",
    "print(f\"Acuracidade: {round(accuracy,4)}\")\n",
    "print(f\"F1 Score: {round(f1score,4)}\")\n",
    "print(\"=======================================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multinomial NB\n",
      "Acuracidade: 0.8772\n",
      "F1 Score: 0.8772\n",
      "=======================================\n",
      "Wall time: 1.85 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "model = MultinomialNB()\n",
    "model.fit(text_vect_treino, df_treino.sentimento)\n",
    "\n",
    "# vetorização do dataframe de teste\n",
    "text_vect_teste = vect.transform(df_teste.lemma)\n",
    "\n",
    "# escoragem da classificação na amostra de teste (textos vetorizados)\n",
    "y_predicao = model.predict(text_vect_teste)\n",
    "\n",
    "# mensuração do resultado pela acurácia\n",
    "y_teste = df_teste.sentimento\n",
    "\n",
    "accuracy = accuracy_score(df_teste.sentimento, y_predicao)\n",
    "f1score = f1_score(df_teste.sentimento, y_predicao, average='weighted')\n",
    "print(\"Multinomial NB\")\n",
    "print(f\"Acuracidade: {round(accuracy,4)}\")\n",
    "print(f\"F1 Score: {round(f1score,4)}\")\n",
    "print(\"=======================================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bernoulli NB\n",
      "Acuracidade: 0.8736\n",
      "F1 Score: 0.8736\n",
      "=======================================\n",
      "Wall time: 1.81 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "model = BernoulliNB()\n",
    "model.fit(text_vect_treino, df_treino.sentimento)\n",
    "\n",
    "# vetorização do dataframe de teste\n",
    "text_vect_teste = vect.transform(df_teste.lemma)\n",
    "\n",
    "# escoragem da classificação na amostra de teste (textos vetorizados)\n",
    "y_predicao = model.predict(text_vect_teste)\n",
    "\n",
    "# mensuração do resultado pela acurácia\n",
    "y_teste = df_teste.sentimento\n",
    "\n",
    "accuracy = accuracy_score(df_teste.sentimento, y_predicao)\n",
    "f1score = f1_score(df_teste.sentimento, y_predicao, average='weighted')\n",
    "print(\"Bernoulli NB\")\n",
    "print(f\"Acuracidade: {round(accuracy,4)}\")\n",
    "print(f\"F1 Score: {round(f1score,4)}\")\n",
    "print(\"=======================================\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CountVectorizer Lemma / Unigrama - Bigrama / MindF = 10 / token_pattern = Palavras com mais de 3 letras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "vect = CountVectorizer(ngram_range=(1,2), min_df=10, token_pattern='[a-zA-Z0-9]{3,}')\n",
    "vect.fit(df_treino.lemma)\n",
    "text_vect_treino = vect.transform(df_treino.lemma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree\n",
      "Acuracidade: 0.7199\n",
      "F1 Score: 0.7199\n",
      "=======================================\n",
      "Wall time: 1min 31s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "model = DecisionTreeClassifier(random_state=42)\n",
    "model.fit(text_vect_treino, df_treino.sentimento)\n",
    "\n",
    "# vetorização do dataframe de teste\n",
    "text_vect_teste = vect.transform(df_teste.lemma)\n",
    "\n",
    "# escoragem da classificação na amostra de teste (textos vetorizados)\n",
    "y_predicao = model.predict(text_vect_teste)\n",
    "\n",
    "# mensuração do resultado pela acurácia\n",
    "y_teste = df_teste.sentimento\n",
    "\n",
    "accuracy = accuracy_score(df_teste.sentimento, y_predicao)\n",
    "f1score = f1_score(df_teste.sentimento, y_predicao, average='weighted')\n",
    "print(\"Decision Tree\")\n",
    "print(f\"Acuracidade: {round(accuracy,4)}\")\n",
    "print(f\"F1 Score: {round(f1score,4)}\")\n",
    "print(\"=======================================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Roberto Tengan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression\n",
      "Acuracidade: 0.8888\n",
      "F1 Score: 0.8888\n",
      "=======================================\n",
      "Wall time: 7.12 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "model = LogisticRegression(random_state=42)\n",
    "model.fit(text_vect_treino, df_treino.sentimento)\n",
    "\n",
    "# vetorização do dataframe de teste\n",
    "text_vect_teste = vect.transform(df_teste.lemma)\n",
    "\n",
    "# escoragem da classificação na amostra de teste (textos vetorizados)\n",
    "y_predicao = model.predict(text_vect_teste)\n",
    "\n",
    "# mensuração do resultado pela acurácia\n",
    "y_teste = df_teste.sentimento\n",
    "accuracy = accuracy_score(df_teste.sentimento, y_predicao)\n",
    "f1score = f1_score(df_teste.sentimento, y_predicao, average='weighted')\n",
    "print(\"Logistic Regression\")\n",
    "print(f\"Acuracidade: {round(accuracy,4)}\")\n",
    "print(f\"F1 Score: {round(f1score,4)}\")\n",
    "print(\"=======================================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest\n",
      "Acuracidade: 0.8511\n",
      "F1 Score: 0.8511\n",
      "=======================================\n",
      "Wall time: 39.6 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "model = RandomForestClassifier(random_state=42, n_jobs=-1)\n",
    "model.fit(text_vect_treino, df_treino.sentimento)\n",
    "\n",
    "# vetorização do dataframe de teste\n",
    "text_vect_teste = vect.transform(df_teste.lemma)\n",
    "\n",
    "# escoragem da classificação na amostra de teste (textos vetorizados)\n",
    "y_predicao = model.predict(text_vect_teste)\n",
    "\n",
    "# mensuração do resultado pela acurácia\n",
    "y_teste = df_teste.sentimento\n",
    "accuracy = accuracy_score(df_teste.sentimento, y_predicao)\n",
    "f1score = f1_score(df_teste.sentimento, y_predicao, average='weighted')\n",
    "print(\"Random Forest\")\n",
    "print(f\"Acuracidade: {round(accuracy,4)}\")\n",
    "print(f\"F1 Score: {round(f1score,4)}\")\n",
    "print(\"=======================================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multinomial NB\n",
      "Acuracidade: 0.872\n",
      "F1 Score: 0.872\n",
      "=======================================\n",
      "Wall time: 2.47 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "model = MultinomialNB()\n",
    "model.fit(text_vect_treino, df_treino.sentimento)\n",
    "\n",
    "# vetorização do dataframe de teste\n",
    "text_vect_teste = vect.transform(df_teste.lemma)\n",
    "\n",
    "# escoragem da classificação na amostra de teste (textos vetorizados)\n",
    "y_predicao = model.predict(text_vect_teste)\n",
    "\n",
    "# mensuração do resultado pela acurácia\n",
    "y_teste = df_teste.sentimento\n",
    "\n",
    "accuracy = accuracy_score(df_teste.sentimento, y_predicao)\n",
    "f1score = f1_score(df_teste.sentimento, y_predicao, average='weighted')\n",
    "print(\"Multinomial NB\")\n",
    "print(f\"Acuracidade: {round(accuracy,4)}\")\n",
    "print(f\"F1 Score: {round(f1score,4)}\")\n",
    "print(\"=======================================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bernoulli NB\n",
      "Acuracidade: 0.875\n",
      "F1 Score: 0.875\n",
      "=======================================\n",
      "Wall time: 2.46 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "model = BernoulliNB()\n",
    "model.fit(text_vect_treino, df_treino.sentimento)\n",
    "\n",
    "# vetorização do dataframe de teste\n",
    "text_vect_teste = vect.transform(df_teste.lemma)\n",
    "\n",
    "# escoragem da classificação na amostra de teste (textos vetorizados)\n",
    "y_predicao = model.predict(text_vect_teste)\n",
    "\n",
    "# mensuração do resultado pela acurácia\n",
    "y_teste = df_teste.sentimento\n",
    "\n",
    "accuracy = accuracy_score(df_teste.sentimento, y_predicao)\n",
    "f1score = f1_score(df_teste.sentimento, y_predicao, average='weighted')\n",
    "print(\"Bernoulli NB\")\n",
    "print(f\"Acuracidade: {round(accuracy,4)}\")\n",
    "print(f\"F1 Score: {round(f1score,4)}\")\n",
    "print(\"=======================================\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CountVectorizer Lemma_Verb Unigrama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "vect = CountVectorizer(ngram_range=(1,1))\n",
    "vect.fit(df_treino.lemma_verb)\n",
    "text_vect_treino = vect.transform(df_treino.lemma_verb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree\n",
      "Acuracidade: 0.7071\n",
      "F1 Score: 0.7071\n",
      "=======================================\n",
      "Wall time: 1min 1s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "model = DecisionTreeClassifier(random_state=42)\n",
    "model.fit(text_vect_treino, df_treino.sentimento)\n",
    "\n",
    "# vetorização do dataframe de teste\n",
    "text_vect_teste = vect.transform(df_teste.lemma_verb)\n",
    "\n",
    "# escoragem da classificação na amostra de teste (textos vetorizados)\n",
    "y_predicao = model.predict(text_vect_teste)\n",
    "\n",
    "# mensuração do resultado pela acurácia\n",
    "y_teste = df_teste.sentimento\n",
    "\n",
    "accuracy = accuracy_score(df_teste.sentimento, y_predicao)\n",
    "f1score = f1_score(df_teste.sentimento, y_predicao, average='weighted')\n",
    "print(\"Decision Tree\")\n",
    "print(f\"Acuracidade: {round(accuracy,4)}\")\n",
    "print(f\"F1 Score: {round(f1score,4)}\")\n",
    "print(\"=======================================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Roberto Tengan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression\n",
      "Acuracidade: 0.8797\n",
      "F1 Score: 0.8797\n",
      "=======================================\n",
      "Wall time: 5.28 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "model = LogisticRegression(random_state=42)\n",
    "model.fit(text_vect_treino, df_treino.sentimento)\n",
    "\n",
    "# vetorização do dataframe de teste\n",
    "text_vect_teste = vect.transform(df_teste.lemma_verb)\n",
    "\n",
    "# escoragem da classificação na amostra de teste (textos vetorizados)\n",
    "y_predicao = model.predict(text_vect_teste)\n",
    "\n",
    "# mensuração do resultado pela acurácia\n",
    "y_teste = df_teste.sentimento\n",
    "accuracy = accuracy_score(df_teste.sentimento, y_predicao)\n",
    "f1score = f1_score(df_teste.sentimento, y_predicao, average='weighted')\n",
    "print(\"Logistic Regression\")\n",
    "print(f\"Acuracidade: {round(accuracy,4)}\")\n",
    "print(f\"F1 Score: {round(f1score,4)}\")\n",
    "print(\"=======================================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest\n",
      "Acuracidade: 0.8449\n",
      "F1 Score: 0.8449\n",
      "=======================================\n",
      "Wall time: 38.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "model = RandomForestClassifier(random_state=42, n_jobs=-1)\n",
    "model.fit(text_vect_treino, df_treino.sentimento)\n",
    "\n",
    "# vetorização do dataframe de teste\n",
    "text_vect_teste = vect.transform(df_teste.lemma_verb)\n",
    "\n",
    "# escoragem da classificação na amostra de teste (textos vetorizados)\n",
    "y_predicao = model.predict(text_vect_teste)\n",
    "\n",
    "# mensuração do resultado pela acurácia\n",
    "y_teste = df_teste.sentimento\n",
    "accuracy = accuracy_score(df_teste.sentimento, y_predicao)\n",
    "f1score = f1_score(df_teste.sentimento, y_predicao, average='weighted')\n",
    "print(\"Random Forest\")\n",
    "print(f\"Acuracidade: {round(accuracy,4)}\")\n",
    "print(f\"F1 Score: {round(f1score,4)}\")\n",
    "print(\"=======================================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multinomial NB\n",
      "Acuracidade: 0.8542\n",
      "F1 Score: 0.8541\n",
      "=======================================\n",
      "Wall time: 1.57 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "model = MultinomialNB()\n",
    "model.fit(text_vect_treino, df_treino.sentimento)\n",
    "\n",
    "# vetorização do dataframe de teste\n",
    "text_vect_teste = vect.transform(df_teste.lemma_verb)\n",
    "\n",
    "# escoragem da classificação na amostra de teste (textos vetorizados)\n",
    "y_predicao = model.predict(text_vect_teste)\n",
    "\n",
    "# mensuração do resultado pela acurácia\n",
    "y_teste = df_teste.sentimento\n",
    "\n",
    "accuracy = accuracy_score(df_teste.sentimento, y_predicao)\n",
    "f1score = f1_score(df_teste.sentimento, y_predicao, average='weighted')\n",
    "print(\"Multinomial NB\")\n",
    "print(f\"Acuracidade: {round(accuracy,4)}\")\n",
    "print(f\"F1 Score: {round(f1score,4)}\")\n",
    "print(\"=======================================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bernoulli NB\n",
      "Acuracidade: 0.8586\n",
      "F1 Score: 0.8585\n",
      "=======================================\n",
      "Wall time: 1.57 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "model = BernoulliNB()\n",
    "model.fit(text_vect_treino, df_treino.sentimento)\n",
    "\n",
    "# vetorização do dataframe de teste\n",
    "text_vect_teste = vect.transform(df_teste.lemma_verb)\n",
    "\n",
    "# escoragem da classificação na amostra de teste (textos vetorizados)\n",
    "y_predicao = model.predict(text_vect_teste)\n",
    "\n",
    "# mensuração do resultado pela acurácia\n",
    "y_teste = df_teste.sentimento\n",
    "\n",
    "accuracy = accuracy_score(df_teste.sentimento, y_predicao)\n",
    "f1score = f1_score(df_teste.sentimento, y_predicao, average='weighted')\n",
    "print(\"Bernoulli NB\")\n",
    "print(f\"Acuracidade: {round(accuracy,4)}\")\n",
    "print(f\"F1 Score: {round(f1score,4)}\")\n",
    "print(\"=======================================\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CountVectorizer Lemma_Verb Bigrama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "vect = CountVectorizer(ngram_range=(2,2))\n",
    "vect.fit(df_treino.lemma_verb)\n",
    "text_vect_treino = vect.transform(df_treino.lemma_verb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree\n",
      "Acuracidade: 0.691\n",
      "F1 Score: 0.691\n",
      "=======================================\n",
      "Wall time: 6min 3s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "model = DecisionTreeClassifier(random_state=42)\n",
    "model.fit(text_vect_treino, df_treino.sentimento)\n",
    "\n",
    "# vetorização do dataframe de teste\n",
    "text_vect_teste = vect.transform(df_teste.lemma_verb)\n",
    "\n",
    "# escoragem da classificação na amostra de teste (textos vetorizados)\n",
    "y_predicao = model.predict(text_vect_teste)\n",
    "\n",
    "# mensuração do resultado pela acurácia\n",
    "y_teste = df_teste.sentimento\n",
    "\n",
    "accuracy = accuracy_score(df_teste.sentimento, y_predicao)\n",
    "f1score = f1_score(df_teste.sentimento, y_predicao, average='weighted')\n",
    "print(\"Decision Tree\")\n",
    "print(f\"Acuracidade: {round(accuracy,4)}\")\n",
    "print(f\"F1 Score: {round(f1score,4)}\")\n",
    "print(\"=======================================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Roberto Tengan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression\n",
      "Acuracidade: 0.8813\n",
      "F1 Score: 0.8813\n",
      "=======================================\n",
      "Wall time: 44.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "model = LogisticRegression(random_state=42)\n",
    "model.fit(text_vect_treino, df_treino.sentimento)\n",
    "\n",
    "# vetorização do dataframe de teste\n",
    "text_vect_teste = vect.transform(df_teste.lemma_verb)\n",
    "\n",
    "# escoragem da classificação na amostra de teste (textos vetorizados)\n",
    "y_predicao = model.predict(text_vect_teste)\n",
    "\n",
    "# mensuração do resultado pela acurácia\n",
    "y_teste = df_teste.sentimento\n",
    "accuracy = accuracy_score(df_teste.sentimento, y_predicao)\n",
    "f1score = f1_score(df_teste.sentimento, y_predicao, average='weighted')\n",
    "print(\"Logistic Regression\")\n",
    "print(f\"Acuracidade: {round(accuracy,4)}\")\n",
    "print(f\"F1 Score: {round(f1score,4)}\")\n",
    "print(\"=======================================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest\n",
      "Acuracidade: 0.8294\n",
      "F1 Score: 0.8294\n",
      "=======================================\n",
      "Wall time: 8min 7s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "model = RandomForestClassifier(random_state=42, n_jobs=-1)\n",
    "model.fit(text_vect_treino, df_treino.sentimento)\n",
    "\n",
    "# vetorização do dataframe de teste\n",
    "text_vect_teste = vect.transform(df_teste.lemma_verb)\n",
    "\n",
    "# escoragem da classificação na amostra de teste (textos vetorizados)\n",
    "y_predicao = model.predict(text_vect_teste)\n",
    "\n",
    "# mensuração do resultado pela acurácia\n",
    "y_teste = df_teste.sentimento\n",
    "accuracy = accuracy_score(df_teste.sentimento, y_predicao)\n",
    "f1score = f1_score(df_teste.sentimento, y_predicao, average='weighted')\n",
    "print(\"Random Forest\")\n",
    "print(f\"Acuracidade: {round(accuracy,4)}\")\n",
    "print(f\"F1 Score: {round(f1score,4)}\")\n",
    "print(\"=======================================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multinomial NB\n",
      "Acuracidade: 0.8831\n",
      "F1 Score: 0.8829\n",
      "=======================================\n",
      "Wall time: 2.48 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "model = MultinomialNB()\n",
    "model.fit(text_vect_treino, df_treino.sentimento)\n",
    "\n",
    "# vetorização do dataframe de teste\n",
    "text_vect_teste = vect.transform(df_teste.lemma_verb)\n",
    "\n",
    "# escoragem da classificação na amostra de teste (textos vetorizados)\n",
    "y_predicao = model.predict(text_vect_teste)\n",
    "\n",
    "# mensuração do resultado pela acurácia\n",
    "y_teste = df_teste.sentimento\n",
    "\n",
    "accuracy = accuracy_score(df_teste.sentimento, y_predicao)\n",
    "f1score = f1_score(df_teste.sentimento, y_predicao, average='weighted')\n",
    "print(\"Multinomial NB\")\n",
    "print(f\"Acuracidade: {round(accuracy,4)}\")\n",
    "print(f\"F1 Score: {round(f1score,4)}\")\n",
    "print(\"=======================================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bernoulli NB\n",
      "Acuracidade: 0.8826\n",
      "F1 Score: 0.8825\n",
      "=======================================\n",
      "Wall time: 2.58 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "model = BernoulliNB()\n",
    "model.fit(text_vect_treino, df_treino.sentimento)\n",
    "\n",
    "# vetorização do dataframe de teste\n",
    "text_vect_teste = vect.transform(df_teste.lemma_verb)\n",
    "\n",
    "# escoragem da classificação na amostra de teste (textos vetorizados)\n",
    "y_predicao = model.predict(text_vect_teste)\n",
    "\n",
    "# mensuração do resultado pela acurácia\n",
    "y_teste = df_teste.sentimento\n",
    "\n",
    "accuracy = accuracy_score(df_teste.sentimento, y_predicao)\n",
    "f1score = f1_score(df_teste.sentimento, y_predicao, average='weighted')\n",
    "print(\"Bernoulli NB\")\n",
    "print(f\"Acuracidade: {round(accuracy,4)}\")\n",
    "print(f\"F1 Score: {round(f1score,4)}\")\n",
    "print(\"=======================================\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CountVectorizer Lemma_Verb / Unigrama - Bigrama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "vect = CountVectorizer(ngram_range=(1,2))\n",
    "vect.fit(df_treino.lemma_verb)\n",
    "text_vect_treino = vect.transform(df_treino.lemma_verb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree\n",
      "Acuracidade: 0.7167\n",
      "F1 Score: 0.7167\n",
      "=======================================\n",
      "Wall time: 6min 21s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "model = DecisionTreeClassifier(random_state=42)\n",
    "model.fit(text_vect_treino, df_treino.sentimento)\n",
    "\n",
    "# vetorização do dataframe de teste\n",
    "text_vect_teste = vect.transform(df_teste.lemma_verb)\n",
    "\n",
    "# escoragem da classificação na amostra de teste (textos vetorizados)\n",
    "y_predicao = model.predict(text_vect_teste)\n",
    "\n",
    "# mensuração do resultado pela acurácia\n",
    "y_teste = df_teste.sentimento\n",
    "\n",
    "accuracy = accuracy_score(df_teste.sentimento, y_predicao)\n",
    "f1score = f1_score(df_teste.sentimento, y_predicao, average='weighted')\n",
    "print(\"Decision Tree\")\n",
    "print(f\"Acuracidade: {round(accuracy,4)}\")\n",
    "print(f\"F1 Score: {round(f1score,4)}\")\n",
    "print(\"=======================================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Roberto Tengan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression\n",
      "Acuracidade: 0.8996\n",
      "F1 Score: 0.8996\n",
      "=======================================\n",
      "Wall time: 52.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "model = LogisticRegression(random_state=42)\n",
    "model.fit(text_vect_treino, df_treino.sentimento)\n",
    "\n",
    "# vetorização do dataframe de teste\n",
    "text_vect_teste = vect.transform(df_teste.lemma_verb)\n",
    "\n",
    "# escoragem da classificação na amostra de teste (textos vetorizados)\n",
    "y_predicao = model.predict(text_vect_teste)\n",
    "\n",
    "# mensuração do resultado pela acurácia\n",
    "y_teste = df_teste.sentimento\n",
    "accuracy = accuracy_score(df_teste.sentimento, y_predicao)\n",
    "f1score = f1_score(df_teste.sentimento, y_predicao, average='weighted')\n",
    "print(\"Logistic Regression\")\n",
    "print(f\"Acuracidade: {round(accuracy,4)}\")\n",
    "print(f\"F1 Score: {round(f1score,4)}\")\n",
    "print(\"=======================================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest\n",
      "Acuracidade: 0.8531\n",
      "F1 Score: 0.8531\n",
      "=======================================\n",
      "Wall time: 5min 36s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "model = RandomForestClassifier(random_state=42, n_jobs=-1)\n",
    "model.fit(text_vect_treino, df_treino.sentimento)\n",
    "\n",
    "# vetorização do dataframe de teste\n",
    "text_vect_teste = vect.transform(df_teste.lemma_verb)\n",
    "\n",
    "# escoragem da classificação na amostra de teste (textos vetorizados)\n",
    "y_predicao = model.predict(text_vect_teste)\n",
    "\n",
    "# mensuração do resultado pela acurácia\n",
    "y_teste = df_teste.sentimento\n",
    "accuracy = accuracy_score(df_teste.sentimento, y_predicao)\n",
    "f1score = f1_score(df_teste.sentimento, y_predicao, average='weighted')\n",
    "print(\"Random Forest\")\n",
    "print(f\"Acuracidade: {round(accuracy,4)}\")\n",
    "print(f\"F1 Score: {round(f1score,4)}\")\n",
    "print(\"=======================================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multinomial NB\n",
      "Acuracidade: 0.8812\n",
      "F1 Score: 0.881\n",
      "=======================================\n",
      "Wall time: 3.43 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "model = MultinomialNB()\n",
    "model.fit(text_vect_treino, df_treino.sentimento)\n",
    "\n",
    "# vetorização do dataframe de teste\n",
    "text_vect_teste = vect.transform(df_teste.lemma_verb)\n",
    "\n",
    "# escoragem da classificação na amostra de teste (textos vetorizados)\n",
    "y_predicao = model.predict(text_vect_teste)\n",
    "\n",
    "# mensuração do resultado pela acurácia\n",
    "y_teste = df_teste.sentimento\n",
    "\n",
    "accuracy = accuracy_score(df_teste.sentimento, y_predicao)\n",
    "f1score = f1_score(df_teste.sentimento, y_predicao, average='weighted')\n",
    "print(\"Multinomial NB\")\n",
    "print(f\"Acuracidade: {round(accuracy,4)}\")\n",
    "print(f\"F1 Score: {round(f1score,4)}\")\n",
    "print(\"=======================================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bernoulli NB\n",
      "Acuracidade: 0.8823\n",
      "F1 Score: 0.8822\n",
      "=======================================\n",
      "Wall time: 3.51 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "model = BernoulliNB()\n",
    "model.fit(text_vect_treino, df_treino.sentimento)\n",
    "\n",
    "# vetorização do dataframe de teste\n",
    "text_vect_teste = vect.transform(df_teste.lemma_verb)\n",
    "\n",
    "# escoragem da classificação na amostra de teste (textos vetorizados)\n",
    "y_predicao = model.predict(text_vect_teste)\n",
    "\n",
    "# mensuração do resultado pela acurácia\n",
    "y_teste = df_teste.sentimento\n",
    "\n",
    "accuracy = accuracy_score(df_teste.sentimento, y_predicao)\n",
    "f1score = f1_score(df_teste.sentimento, y_predicao, average='weighted')\n",
    "print(\"Bernoulli NB\")\n",
    "print(f\"Acuracidade: {round(accuracy,4)}\")\n",
    "print(f\"F1 Score: {round(f1score,4)}\")\n",
    "print(\"=======================================\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CountVectorizer Lemma_Verb / Unigrama / MindF = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "vect = CountVectorizer(ngram_range=(1,1), min_df=10)\n",
    "vect.fit(df_treino.lemma_verb)\n",
    "text_vect_treino = vect.transform(df_treino.lemma_verb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree\n",
      "Acuracidade: 0.7085\n",
      "F1 Score: 0.7085\n",
      "=======================================\n",
      "Wall time: 53.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "model = DecisionTreeClassifier(random_state=42)\n",
    "model.fit(text_vect_treino, df_treino.sentimento)\n",
    "\n",
    "# vetorização do dataframe de teste\n",
    "text_vect_teste = vect.transform(df_teste.lemma_verb)\n",
    "\n",
    "# escoragem da classificação na amostra de teste (textos vetorizados)\n",
    "y_predicao = model.predict(text_vect_teste)\n",
    "\n",
    "# mensuração do resultado pela acurácia\n",
    "y_teste = df_teste.sentimento\n",
    "\n",
    "accuracy = accuracy_score(df_teste.sentimento, y_predicao)\n",
    "f1score = f1_score(df_teste.sentimento, y_predicao, average='weighted')\n",
    "print(\"Decision Tree\")\n",
    "print(f\"Acuracidade: {round(accuracy,4)}\")\n",
    "print(f\"F1 Score: {round(f1score,4)}\")\n",
    "print(\"=======================================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Roberto Tengan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression\n",
      "Acuracidade: 0.8761\n",
      "F1 Score: 0.8761\n",
      "=======================================\n",
      "Wall time: 3.81 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "model = LogisticRegression(random_state=42)\n",
    "model.fit(text_vect_treino, df_treino.sentimento)\n",
    "\n",
    "# vetorização do dataframe de teste\n",
    "text_vect_teste = vect.transform(df_teste.lemma_verb)\n",
    "\n",
    "# escoragem da classificação na amostra de teste (textos vetorizados)\n",
    "y_predicao = model.predict(text_vect_teste)\n",
    "\n",
    "# mensuração do resultado pela acurácia\n",
    "y_teste = df_teste.sentimento\n",
    "accuracy = accuracy_score(df_teste.sentimento, y_predicao)\n",
    "f1score = f1_score(df_teste.sentimento, y_predicao, average='weighted')\n",
    "print(\"Logistic Regression\")\n",
    "print(f\"Acuracidade: {round(accuracy,4)}\")\n",
    "print(f\"F1 Score: {round(f1score,4)}\")\n",
    "print(\"=======================================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest\n",
      "Acuracidade: 0.842\n",
      "F1 Score: 0.842\n",
      "=======================================\n",
      "Wall time: 32.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "model = RandomForestClassifier(random_state=42, n_jobs=-1)\n",
    "model.fit(text_vect_treino, df_treino.sentimento)\n",
    "\n",
    "# vetorização do dataframe de teste\n",
    "text_vect_teste = vect.transform(df_teste.lemma_verb)\n",
    "\n",
    "# escoragem da classificação na amostra de teste (textos vetorizados)\n",
    "y_predicao = model.predict(text_vect_teste)\n",
    "\n",
    "# mensuração do resultado pela acurácia\n",
    "y_teste = df_teste.sentimento\n",
    "accuracy = accuracy_score(df_teste.sentimento, y_predicao)\n",
    "f1score = f1_score(df_teste.sentimento, y_predicao, average='weighted')\n",
    "print(\"Random Forest\")\n",
    "print(f\"Acuracidade: {round(accuracy,4)}\")\n",
    "print(f\"F1 Score: {round(f1score,4)}\")\n",
    "print(\"=======================================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multinomial NB\n",
      "Acuracidade: 0.8477\n",
      "F1 Score: 0.8476\n",
      "=======================================\n",
      "Wall time: 1.65 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "model = MultinomialNB()\n",
    "model.fit(text_vect_treino, df_treino.sentimento)\n",
    "\n",
    "# vetorização do dataframe de teste\n",
    "text_vect_teste = vect.transform(df_teste.lemma_verb)\n",
    "\n",
    "# escoragem da classificação na amostra de teste (textos vetorizados)\n",
    "y_predicao = model.predict(text_vect_teste)\n",
    "\n",
    "# mensuração do resultado pela acurácia\n",
    "y_teste = df_teste.sentimento\n",
    "\n",
    "accuracy = accuracy_score(df_teste.sentimento, y_predicao)\n",
    "f1score = f1_score(df_teste.sentimento, y_predicao, average='weighted')\n",
    "print(\"Multinomial NB\")\n",
    "print(f\"Acuracidade: {round(accuracy,4)}\")\n",
    "print(f\"F1 Score: {round(f1score,4)}\")\n",
    "print(\"=======================================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bernoulli NB\n",
      "Acuracidade: 0.8549\n",
      "F1 Score: 0.8549\n",
      "=======================================\n",
      "Wall time: 1.58 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "model = BernoulliNB()\n",
    "model.fit(text_vect_treino, df_treino.sentimento)\n",
    "\n",
    "# vetorização do dataframe de teste\n",
    "text_vect_teste = vect.transform(df_teste.lemma_verb)\n",
    "\n",
    "# escoragem da classificação na amostra de teste (textos vetorizados)\n",
    "y_predicao = model.predict(text_vect_teste)\n",
    "\n",
    "# mensuração do resultado pela acurácia\n",
    "y_teste = df_teste.sentimento\n",
    "\n",
    "accuracy = accuracy_score(df_teste.sentimento, y_predicao)\n",
    "f1score = f1_score(df_teste.sentimento, y_predicao, average='weighted')\n",
    "print(\"Bernoulli NB\")\n",
    "print(f\"Acuracidade: {round(accuracy,4)}\")\n",
    "print(f\"F1 Score: {round(f1score,4)}\")\n",
    "print(\"=======================================\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CountVectorizer Lemma_Verb / Bigrama / MindF = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "vect = CountVectorizer(ngram_range=(2,2), min_df=10)\n",
    "vect.fit(df_treino.lemma_verb)\n",
    "text_vect_treino = vect.transform(df_treino.lemma_verb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree\n",
      "Acuracidade: 0.6893\n",
      "F1 Score: 0.6893\n",
      "=======================================\n",
      "Wall time: 1min 7s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "model = DecisionTreeClassifier(random_state=42)\n",
    "model.fit(text_vect_treino, df_treino.sentimento)\n",
    "\n",
    "# vetorização do dataframe de teste\n",
    "text_vect_teste = vect.transform(df_teste.lemma_verb)\n",
    "\n",
    "# escoragem da classificação na amostra de teste (textos vetorizados)\n",
    "y_predicao = model.predict(text_vect_teste)\n",
    "\n",
    "# mensuração do resultado pela acurácia\n",
    "y_teste = df_teste.sentimento\n",
    "\n",
    "accuracy = accuracy_score(df_teste.sentimento, y_predicao)\n",
    "f1score = f1_score(df_teste.sentimento, y_predicao, average='weighted')\n",
    "print(\"Decision Tree\")\n",
    "print(f\"Acuracidade: {round(accuracy,4)}\")\n",
    "print(f\"F1 Score: {round(f1score,4)}\")\n",
    "print(\"=======================================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Roberto Tengan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression\n",
      "Acuracidade: 0.874\n",
      "F1 Score: 0.874\n",
      "=======================================\n",
      "Wall time: 5.71 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "model = LogisticRegression(random_state=42)\n",
    "model.fit(text_vect_treino, df_treino.sentimento)\n",
    "\n",
    "# vetorização do dataframe de teste\n",
    "text_vect_teste = vect.transform(df_teste.lemma_verb)\n",
    "\n",
    "# escoragem da classificação na amostra de teste (textos vetorizados)\n",
    "y_predicao = model.predict(text_vect_teste)\n",
    "\n",
    "# mensuração do resultado pela acurácia\n",
    "y_teste = df_teste.sentimento\n",
    "accuracy = accuracy_score(df_teste.sentimento, y_predicao)\n",
    "f1score = f1_score(df_teste.sentimento, y_predicao, average='weighted')\n",
    "print(\"Logistic Regression\")\n",
    "print(f\"Acuracidade: {round(accuracy,4)}\")\n",
    "print(f\"F1 Score: {round(f1score,4)}\")\n",
    "print(\"=======================================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest\n",
      "Acuracidade: 0.819\n",
      "F1 Score: 0.8188\n",
      "=======================================\n",
      "Wall time: 35.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "model = RandomForestClassifier(random_state=42, n_jobs=-1)\n",
    "model.fit(text_vect_treino, df_treino.sentimento)\n",
    "\n",
    "# vetorização do dataframe de teste\n",
    "text_vect_teste = vect.transform(df_teste.lemma_verb)\n",
    "\n",
    "# escoragem da classificação na amostra de teste (textos vetorizados)\n",
    "y_predicao = model.predict(text_vect_teste)\n",
    "\n",
    "# mensuração do resultado pela acurácia\n",
    "y_teste = df_teste.sentimento\n",
    "accuracy = accuracy_score(df_teste.sentimento, y_predicao)\n",
    "f1score = f1_score(df_teste.sentimento, y_predicao, average='weighted')\n",
    "print(\"Random Forest\")\n",
    "print(f\"Acuracidade: {round(accuracy,4)}\")\n",
    "print(f\"F1 Score: {round(f1score,4)}\")\n",
    "print(\"=======================================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multinomial NB\n",
      "Acuracidade: 0.8779\n",
      "F1 Score: 0.8779\n",
      "=======================================\n",
      "Wall time: 2.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "model = MultinomialNB()\n",
    "model.fit(text_vect_treino, df_treino.sentimento)\n",
    "\n",
    "# vetorização do dataframe de teste\n",
    "text_vect_teste = vect.transform(df_teste.lemma_verb)\n",
    "\n",
    "# escoragem da classificação na amostra de teste (textos vetorizados)\n",
    "y_predicao = model.predict(text_vect_teste)\n",
    "\n",
    "# mensuração do resultado pela acurácia\n",
    "y_teste = df_teste.sentimento\n",
    "\n",
    "accuracy = accuracy_score(df_teste.sentimento, y_predicao)\n",
    "f1score = f1_score(df_teste.sentimento, y_predicao, average='weighted')\n",
    "print(\"Multinomial NB\")\n",
    "print(f\"Acuracidade: {round(accuracy,4)}\")\n",
    "print(f\"F1 Score: {round(f1score,4)}\")\n",
    "print(\"=======================================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bernoulli NB\n",
      "Acuracidade: 0.8725\n",
      "F1 Score: 0.8724\n",
      "=======================================\n",
      "Wall time: 2.49 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "model = BernoulliNB()\n",
    "model.fit(text_vect_treino, df_treino.sentimento)\n",
    "\n",
    "# vetorização do dataframe de teste\n",
    "text_vect_teste = vect.transform(df_teste.lemma_verb)\n",
    "\n",
    "# escoragem da classificação na amostra de teste (textos vetorizados)\n",
    "y_predicao = model.predict(text_vect_teste)\n",
    "\n",
    "# mensuração do resultado pela acurácia\n",
    "y_teste = df_teste.sentimento\n",
    "\n",
    "accuracy = accuracy_score(df_teste.sentimento, y_predicao)\n",
    "f1score = f1_score(df_teste.sentimento, y_predicao, average='weighted')\n",
    "print(\"Bernoulli NB\")\n",
    "print(f\"Acuracidade: {round(accuracy,4)}\")\n",
    "print(f\"F1 Score: {round(f1score,4)}\")\n",
    "print(\"=======================================\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CountVectorizer Lemma_Verb / Unigrama - Bigrama / MindF = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "vect = CountVectorizer(ngram_range=(1,2), min_df=10)\n",
    "vect.fit(df_treino.lemma_verb)\n",
    "text_vect_treino = vect.transform(df_treino.lemma_verb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree\n",
      "Acuracidade: 0.714\n",
      "F1 Score: 0.714\n",
      "=======================================\n",
      "Wall time: 1min 51s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "model = DecisionTreeClassifier(random_state=42)\n",
    "model.fit(text_vect_treino, df_treino.sentimento)\n",
    "\n",
    "# vetorização do dataframe de teste\n",
    "text_vect_teste = vect.transform(df_teste.lemma_verb)\n",
    "\n",
    "# escoragem da classificação na amostra de teste (textos vetorizados)\n",
    "y_predicao = model.predict(text_vect_teste)\n",
    "\n",
    "# mensuração do resultado pela acurácia\n",
    "y_teste = df_teste.sentimento\n",
    "\n",
    "accuracy = accuracy_score(df_teste.sentimento, y_predicao)\n",
    "f1score = f1_score(df_teste.sentimento, y_predicao, average='weighted')\n",
    "print(\"Decision Tree\")\n",
    "print(f\"Acuracidade: {round(accuracy,4)}\")\n",
    "print(f\"F1 Score: {round(f1score,4)}\")\n",
    "print(\"=======================================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Roberto Tengan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression\n",
      "Acuracidade: 0.8896\n",
      "F1 Score: 0.8896\n",
      "=======================================\n",
      "Wall time: 8.99 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "model = LogisticRegression(random_state=42)\n",
    "model.fit(text_vect_treino, df_treino.sentimento)\n",
    "\n",
    "# vetorização do dataframe de teste\n",
    "text_vect_teste = vect.transform(df_teste.lemma_verb)\n",
    "\n",
    "# escoragem da classificação na amostra de teste (textos vetorizados)\n",
    "y_predicao = model.predict(text_vect_teste)\n",
    "\n",
    "# mensuração do resultado pela acurácia\n",
    "y_teste = df_teste.sentimento\n",
    "accuracy = accuracy_score(df_teste.sentimento, y_predicao)\n",
    "f1score = f1_score(df_teste.sentimento, y_predicao, average='weighted')\n",
    "print(\"Logistic Regression\")\n",
    "print(f\"Acuracidade: {round(accuracy,4)}\")\n",
    "print(f\"F1 Score: {round(f1score,4)}\")\n",
    "print(\"=======================================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest\n",
      "Acuracidade: 0.8488\n",
      "F1 Score: 0.8488\n",
      "=======================================\n",
      "Wall time: 44.6 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "model = RandomForestClassifier(random_state=42, n_jobs=-1)\n",
    "model.fit(text_vect_treino, df_treino.sentimento)\n",
    "\n",
    "# vetorização do dataframe de teste\n",
    "text_vect_teste = vect.transform(df_teste.lemma_verb)\n",
    "\n",
    "# escoragem da classificação na amostra de teste (textos vetorizados)\n",
    "y_predicao = model.predict(text_vect_teste)\n",
    "\n",
    "# mensuração do resultado pela acurácia\n",
    "y_teste = df_teste.sentimento\n",
    "accuracy = accuracy_score(df_teste.sentimento, y_predicao)\n",
    "f1score = f1_score(df_teste.sentimento, y_predicao, average='weighted')\n",
    "print(\"Random Forest\")\n",
    "print(f\"Acuracidade: {round(accuracy,4)}\")\n",
    "print(f\"F1 Score: {round(f1score,4)}\")\n",
    "print(\"=======================================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multinomial NB\n",
      "Acuracidade: 0.875\n",
      "F1 Score: 0.875\n",
      "=======================================\n",
      "Wall time: 2.96 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "model = MultinomialNB()\n",
    "model.fit(text_vect_treino, df_treino.sentimento)\n",
    "\n",
    "# vetorização do dataframe de teste\n",
    "text_vect_teste = vect.transform(df_teste.lemma_verb)\n",
    "\n",
    "# escoragem da classificação na amostra de teste (textos vetorizados)\n",
    "y_predicao = model.predict(text_vect_teste)\n",
    "\n",
    "# mensuração do resultado pela acurácia\n",
    "y_teste = df_teste.sentimento\n",
    "\n",
    "accuracy = accuracy_score(df_teste.sentimento, y_predicao)\n",
    "f1score = f1_score(df_teste.sentimento, y_predicao, average='weighted')\n",
    "print(\"Multinomial NB\")\n",
    "print(f\"Acuracidade: {round(accuracy,4)}\")\n",
    "print(f\"F1 Score: {round(f1score,4)}\")\n",
    "print(\"=======================================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bernoulli NB\n",
      "Acuracidade: 0.8751\n",
      "F1 Score: 0.8751\n",
      "=======================================\n",
      "Wall time: 3.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "model = BernoulliNB()\n",
    "model.fit(text_vect_treino, df_treino.sentimento)\n",
    "\n",
    "# vetorização do dataframe de teste\n",
    "text_vect_teste = vect.transform(df_teste.lemma_verb)\n",
    "\n",
    "# escoragem da classificação na amostra de teste (textos vetorizados)\n",
    "y_predicao = model.predict(text_vect_teste)\n",
    "\n",
    "# mensuração do resultado pela acurácia\n",
    "y_teste = df_teste.sentimento\n",
    "\n",
    "accuracy = accuracy_score(df_teste.sentimento, y_predicao)\n",
    "f1score = f1_score(df_teste.sentimento, y_predicao, average='weighted')\n",
    "print(\"Bernoulli NB\")\n",
    "print(f\"Acuracidade: {round(accuracy,4)}\")\n",
    "print(f\"F1 Score: {round(f1score,4)}\")\n",
    "print(\"=======================================\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CountVectorizer Lemma_Verb / Unigrama / MindF = 10 / token_pattern = Palavras com mais de 3 letras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "vect = CountVectorizer(ngram_range=(1,1), min_df=10, token_pattern='[a-zA-Z0-9]{3,}')\n",
    "vect.fit(df_treino.lemma_verb)\n",
    "text_vect_treino = vect.transform(df_treino.lemma_verb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree\n",
      "Acuracidade: 0.7108\n",
      "F1 Score: 0.7108\n",
      "=======================================\n",
      "Wall time: 50.9 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "model = DecisionTreeClassifier(random_state=42)\n",
    "model.fit(text_vect_treino, df_treino.sentimento)\n",
    "\n",
    "# vetorização do dataframe de teste\n",
    "text_vect_teste = vect.transform(df_teste.lemma_verb)\n",
    "\n",
    "# escoragem da classificação na amostra de teste (textos vetorizados)\n",
    "y_predicao = model.predict(text_vect_teste)\n",
    "\n",
    "# mensuração do resultado pela acurácia\n",
    "y_teste = df_teste.sentimento\n",
    "\n",
    "accuracy = accuracy_score(df_teste.sentimento, y_predicao)\n",
    "f1score = f1_score(df_teste.sentimento, y_predicao, average='weighted')\n",
    "print(\"Decision Tree\")\n",
    "print(f\"Acuracidade: {round(accuracy,4)}\")\n",
    "print(f\"F1 Score: {round(f1score,4)}\")\n",
    "print(\"=======================================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Roberto Tengan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression\n",
      "Acuracidade: 0.8776\n",
      "F1 Score: 0.8776\n",
      "=======================================\n",
      "Wall time: 3.35 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "model = LogisticRegression(random_state=42)\n",
    "model.fit(text_vect_treino, df_treino.sentimento)\n",
    "\n",
    "# vetorização do dataframe de teste\n",
    "text_vect_teste = vect.transform(df_teste.lemma_verb)\n",
    "\n",
    "# escoragem da classificação na amostra de teste (textos vetorizados)\n",
    "y_predicao = model.predict(text_vect_teste)\n",
    "\n",
    "# mensuração do resultado pela acurácia\n",
    "y_teste = df_teste.sentimento\n",
    "accuracy = accuracy_score(df_teste.sentimento, y_predicao)\n",
    "f1score = f1_score(df_teste.sentimento, y_predicao, average='weighted')\n",
    "print(\"Logistic Regression\")\n",
    "print(f\"Acuracidade: {round(accuracy,4)}\")\n",
    "print(f\"F1 Score: {round(f1score,4)}\")\n",
    "print(\"=======================================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest\n",
      "Acuracidade: 0.8456\n",
      "F1 Score: 0.8455\n",
      "=======================================\n",
      "Wall time: 31.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "model = RandomForestClassifier(random_state=42, n_jobs=-1)\n",
    "model.fit(text_vect_treino, df_treino.sentimento)\n",
    "\n",
    "# vetorização do dataframe de teste\n",
    "text_vect_teste = vect.transform(df_teste.lemma_verb)\n",
    "\n",
    "# escoragem da classificação na amostra de teste (textos vetorizados)\n",
    "y_predicao = model.predict(text_vect_teste)\n",
    "\n",
    "# mensuração do resultado pela acurácia\n",
    "y_teste = df_teste.sentimento\n",
    "accuracy = accuracy_score(df_teste.sentimento, y_predicao)\n",
    "f1score = f1_score(df_teste.sentimento, y_predicao, average='weighted')\n",
    "print(\"Random Forest\")\n",
    "print(f\"Acuracidade: {round(accuracy,4)}\")\n",
    "print(f\"F1 Score: {round(f1score,4)}\")\n",
    "print(\"=======================================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multinomial NB\n",
      "Acuracidade: 0.8481\n",
      "F1 Score: 0.8481\n",
      "=======================================\n",
      "Wall time: 1.27 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "model = MultinomialNB()\n",
    "model.fit(text_vect_treino, df_treino.sentimento)\n",
    "\n",
    "# vetorização do dataframe de teste\n",
    "text_vect_teste = vect.transform(df_teste.lemma_verb)\n",
    "\n",
    "# escoragem da classificação na amostra de teste (textos vetorizados)\n",
    "y_predicao = model.predict(text_vect_teste)\n",
    "\n",
    "# mensuração do resultado pela acurácia\n",
    "y_teste = df_teste.sentimento\n",
    "\n",
    "accuracy = accuracy_score(df_teste.sentimento, y_predicao)\n",
    "f1score = f1_score(df_teste.sentimento, y_predicao, average='weighted')\n",
    "print(\"Multinomial NB\")\n",
    "print(f\"Acuracidade: {round(accuracy,4)}\")\n",
    "print(f\"F1 Score: {round(f1score,4)}\")\n",
    "print(\"=======================================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bernoulli NB\n",
      "Acuracidade: 0.8549\n",
      "F1 Score: 0.8548\n",
      "=======================================\n",
      "Wall time: 1.25 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "model = BernoulliNB()\n",
    "model.fit(text_vect_treino, df_treino.sentimento)\n",
    "\n",
    "# vetorização do dataframe de teste\n",
    "text_vect_teste = vect.transform(df_teste.lemma_verb)\n",
    "\n",
    "# escoragem da classificação na amostra de teste (textos vetorizados)\n",
    "y_predicao = model.predict(text_vect_teste)\n",
    "\n",
    "# mensuração do resultado pela acurácia\n",
    "y_teste = df_teste.sentimento\n",
    "\n",
    "accuracy = accuracy_score(df_teste.sentimento, y_predicao)\n",
    "f1score = f1_score(df_teste.sentimento, y_predicao, average='weighted')\n",
    "print(\"Bernoulli NB\")\n",
    "print(f\"Acuracidade: {round(accuracy,4)}\")\n",
    "print(f\"F1 Score: {round(f1score,4)}\")\n",
    "print(\"=======================================\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CountVectorizer Lemma_Verb / Bigrama / MindF = 10 / token_pattern = Palavras com mais de 3 letras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [],
   "source": [
    "vect = CountVectorizer(ngram_range=(2,2), min_df=10, token_pattern='[a-zA-Z0-9]{3,}')\n",
    "vect.fit(df_treino.lemma_verb)\n",
    "text_vect_treino = vect.transform(df_treino.lemma_verb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree\n",
      "Acuracidade: 0.7138\n",
      "F1 Score: 0.7138\n",
      "=======================================\n",
      "Wall time: 54.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "model = DecisionTreeClassifier(random_state=42)\n",
    "model.fit(text_vect_treino, df_treino.sentimento)\n",
    "\n",
    "# vetorização do dataframe de teste\n",
    "text_vect_teste = vect.transform(df_teste.lemma_verb)\n",
    "\n",
    "# escoragem da classificação na amostra de teste (textos vetorizados)\n",
    "y_predicao = model.predict(text_vect_teste)\n",
    "\n",
    "# mensuração do resultado pela acurácia\n",
    "y_teste = df_teste.sentimento\n",
    "\n",
    "accuracy = accuracy_score(df_teste.sentimento, y_predicao)\n",
    "f1score = f1_score(df_teste.sentimento, y_predicao, average='weighted')\n",
    "print(\"Decision Tree\")\n",
    "print(f\"Acuracidade: {round(accuracy,4)}\")\n",
    "print(f\"F1 Score: {round(f1score,4)}\")\n",
    "print(\"=======================================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Roberto Tengan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression\n",
      "Acuracidade: 0.8713\n",
      "F1 Score: 0.8713\n",
      "=======================================\n",
      "Wall time: 4.18 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "model = LogisticRegression(random_state=42)\n",
    "model.fit(text_vect_treino, df_treino.sentimento)\n",
    "\n",
    "# vetorização do dataframe de teste\n",
    "text_vect_teste = vect.transform(df_teste.lemma_verb)\n",
    "\n",
    "# escoragem da classificação na amostra de teste (textos vetorizados)\n",
    "y_predicao = model.predict(text_vect_teste)\n",
    "\n",
    "# mensuração do resultado pela acurácia\n",
    "y_teste = df_teste.sentimento\n",
    "accuracy = accuracy_score(df_teste.sentimento, y_predicao)\n",
    "f1score = f1_score(df_teste.sentimento, y_predicao, average='weighted')\n",
    "print(\"Logistic Regression\")\n",
    "print(f\"Acuracidade: {round(accuracy,4)}\")\n",
    "print(f\"F1 Score: {round(f1score,4)}\")\n",
    "print(\"=======================================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest\n",
      "Acuracidade: 0.8203\n",
      "F1 Score: 0.8202\n",
      "=======================================\n",
      "Wall time: 30.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "model = RandomForestClassifier(random_state=42, n_jobs=-1)\n",
    "model.fit(text_vect_treino, df_treino.sentimento)\n",
    "\n",
    "# vetorização do dataframe de teste\n",
    "text_vect_teste = vect.transform(df_teste.lemma_verb)\n",
    "\n",
    "# escoragem da classificação na amostra de teste (textos vetorizados)\n",
    "y_predicao = model.predict(text_vect_teste)\n",
    "\n",
    "# mensuração do resultado pela acurácia\n",
    "y_teste = df_teste.sentimento\n",
    "accuracy = accuracy_score(df_teste.sentimento, y_predicao)\n",
    "f1score = f1_score(df_teste.sentimento, y_predicao, average='weighted')\n",
    "print(\"Random Forest\")\n",
    "print(f\"Acuracidade: {round(accuracy,4)}\")\n",
    "print(f\"F1 Score: {round(f1score,4)}\")\n",
    "print(\"=======================================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multinomial NB\n",
      "Acuracidade: 0.877\n",
      "F1 Score: 0.877\n",
      "=======================================\n",
      "Wall time: 1.89 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "model = MultinomialNB()\n",
    "model.fit(text_vect_treino, df_treino.sentimento)\n",
    "\n",
    "# vetorização do dataframe de teste\n",
    "text_vect_teste = vect.transform(df_teste.lemma_verb)\n",
    "\n",
    "# escoragem da classificação na amostra de teste (textos vetorizados)\n",
    "y_predicao = model.predict(text_vect_teste)\n",
    "\n",
    "# mensuração do resultado pela acurácia\n",
    "y_teste = df_teste.sentimento\n",
    "\n",
    "accuracy = accuracy_score(df_teste.sentimento, y_predicao)\n",
    "f1score = f1_score(df_teste.sentimento, y_predicao, average='weighted')\n",
    "print(\"Multinomial NB\")\n",
    "print(f\"Acuracidade: {round(accuracy,4)}\")\n",
    "print(f\"F1 Score: {round(f1score,4)}\")\n",
    "print(\"=======================================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bernoulli NB\n",
      "Acuracidade: 0.8711\n",
      "F1 Score: 0.8709\n",
      "=======================================\n",
      "Wall time: 1.85 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "model = BernoulliNB()\n",
    "model.fit(text_vect_treino, df_treino.sentimento)\n",
    "\n",
    "# vetorização do dataframe de teste\n",
    "text_vect_teste = vect.transform(df_teste.lemma_verb)\n",
    "\n",
    "# escoragem da classificação na amostra de teste (textos vetorizados)\n",
    "y_predicao = model.predict(text_vect_teste)\n",
    "\n",
    "# mensuração do resultado pela acurácia\n",
    "y_teste = df_teste.sentimento\n",
    "\n",
    "accuracy = accuracy_score(df_teste.sentimento, y_predicao)\n",
    "f1score = f1_score(df_teste.sentimento, y_predicao, average='weighted')\n",
    "print(\"Bernoulli NB\")\n",
    "print(f\"Acuracidade: {round(accuracy,4)}\")\n",
    "print(f\"F1 Score: {round(f1score,4)}\")\n",
    "print(\"=======================================\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CountVectorizer Lemma_Verb / Unigrama - Bigrama / MindF = 10 / token_pattern = Palavras com mais de 3 letras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [],
   "source": [
    "vect = CountVectorizer(ngram_range=(1,2), min_df=10, token_pattern='[a-zA-Z0-9]{3,}')\n",
    "vect.fit(df_treino.lemma_verb)\n",
    "text_vect_treino = vect.transform(df_treino.lemma_verb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree\n",
      "Acuracidade: 0.7132\n",
      "F1 Score: 0.7132\n",
      "=======================================\n",
      "Wall time: 1min 32s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "model = DecisionTreeClassifier(random_state=42)\n",
    "model.fit(text_vect_treino, df_treino.sentimento)\n",
    "\n",
    "# vetorização do dataframe de teste\n",
    "text_vect_teste = vect.transform(df_teste.lemma_verb)\n",
    "\n",
    "# escoragem da classificação na amostra de teste (textos vetorizados)\n",
    "y_predicao = model.predict(text_vect_teste)\n",
    "\n",
    "# mensuração do resultado pela acurácia\n",
    "y_teste = df_teste.sentimento\n",
    "\n",
    "accuracy = accuracy_score(df_teste.sentimento, y_predicao)\n",
    "f1score = f1_score(df_teste.sentimento, y_predicao, average='weighted')\n",
    "print(\"Decision Tree\")\n",
    "print(f\"Acuracidade: {round(accuracy,4)}\")\n",
    "print(f\"F1 Score: {round(f1score,4)}\")\n",
    "print(\"=======================================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Roberto Tengan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression\n",
      "Acuracidade: 0.8893\n",
      "F1 Score: 0.8892\n",
      "=======================================\n",
      "Wall time: 7.37 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "model = LogisticRegression(random_state=42)\n",
    "model.fit(text_vect_treino, df_treino.sentimento)\n",
    "\n",
    "# vetorização do dataframe de teste\n",
    "text_vect_teste = vect.transform(df_teste.lemma_verb)\n",
    "\n",
    "# escoragem da classificação na amostra de teste (textos vetorizados)\n",
    "y_predicao = model.predict(text_vect_teste)\n",
    "\n",
    "# mensuração do resultado pela acurácia\n",
    "y_teste = df_teste.sentimento\n",
    "accuracy = accuracy_score(df_teste.sentimento, y_predicao)\n",
    "f1score = f1_score(df_teste.sentimento, y_predicao, average='weighted')\n",
    "print(\"Logistic Regression\")\n",
    "print(f\"Acuracidade: {round(accuracy,4)}\")\n",
    "print(f\"F1 Score: {round(f1score,4)}\")\n",
    "print(\"=======================================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest\n",
      "Acuracidade: 0.8545\n",
      "F1 Score: 0.8545\n",
      "=======================================\n",
      "Wall time: 39.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "model = RandomForestClassifier(random_state=42, n_jobs=-1)\n",
    "model.fit(text_vect_treino, df_treino.sentimento)\n",
    "\n",
    "# vetorização do dataframe de teste\n",
    "text_vect_teste = vect.transform(df_teste.lemma_verb)\n",
    "\n",
    "# escoragem da classificação na amostra de teste (textos vetorizados)\n",
    "y_predicao = model.predict(text_vect_teste)\n",
    "\n",
    "# mensuração do resultado pela acurácia\n",
    "y_teste = df_teste.sentimento\n",
    "accuracy = accuracy_score(df_teste.sentimento, y_predicao)\n",
    "f1score = f1_score(df_teste.sentimento, y_predicao, average='weighted')\n",
    "print(\"Random Forest\")\n",
    "print(f\"Acuracidade: {round(accuracy,4)}\")\n",
    "print(f\"F1 Score: {round(f1score,4)}\")\n",
    "print(\"=======================================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multinomial NB\n",
      "Acuracidade: 0.8732\n",
      "F1 Score: 0.8732\n",
      "=======================================\n",
      "Wall time: 2.48 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "model = MultinomialNB()\n",
    "model.fit(text_vect_treino, df_treino.sentimento)\n",
    "\n",
    "# vetorização do dataframe de teste\n",
    "text_vect_teste = vect.transform(df_teste.lemma_verb)\n",
    "\n",
    "# escoragem da classificação na amostra de teste (textos vetorizados)\n",
    "y_predicao = model.predict(text_vect_teste)\n",
    "\n",
    "# mensuração do resultado pela acurácia\n",
    "y_teste = df_teste.sentimento\n",
    "\n",
    "accuracy = accuracy_score(df_teste.sentimento, y_predicao)\n",
    "f1score = f1_score(df_teste.sentimento, y_predicao, average='weighted')\n",
    "print(\"Multinomial NB\")\n",
    "print(f\"Acuracidade: {round(accuracy,4)}\")\n",
    "print(f\"F1 Score: {round(f1score,4)}\")\n",
    "print(\"=======================================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bernoulli NB\n",
      "Acuracidade: 0.876\n",
      "F1 Score: 0.876\n",
      "=======================================\n",
      "Wall time: 2.46 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "model = BernoulliNB()\n",
    "model.fit(text_vect_treino, df_treino.sentimento)\n",
    "\n",
    "# vetorização do dataframe de teste\n",
    "text_vect_teste = vect.transform(df_teste.lemma_verb)\n",
    "\n",
    "# escoragem da classificação na amostra de teste (textos vetorizados)\n",
    "y_predicao = model.predict(text_vect_teste)\n",
    "\n",
    "# mensuração do resultado pela acurácia\n",
    "y_teste = df_teste.sentimento\n",
    "\n",
    "accuracy = accuracy_score(df_teste.sentimento, y_predicao)\n",
    "f1score = f1_score(df_teste.sentimento, y_predicao, average='weighted')\n",
    "print(\"Bernoulli NB\")\n",
    "print(f\"Acuracidade: {round(accuracy,4)}\")\n",
    "print(f\"F1 Score: {round(f1score,4)}\")\n",
    "print(\"=======================================\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "68SiMjcWqD_m"
   },
   "source": [
    "#### **Validação do professor**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "T24EasckqG2I"
   },
   "source": [
    "Consolidar apenas os scripts do seu **modelo campeão**, desde o carregamento do dataframe, separação das amostras, tratamentos utilizados (funções, limpezas, etc.), criação dos objetos de vetorização dos textos e modelo treinado e outras implementações utilizadas no processo de desenvolvimento do modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {
    "id": "ZxqHA-XCrqsD"
   },
   "outputs": [],
   "source": [
    "#import plotly.express as px\n",
    "\n",
    "#fig = px.line(x=[\"a\",\"b\",\"c\"], y=[1,3,2], title=\"sample figure\")\n",
    "#print(fig)\n",
    "#fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BuJtvcfXo3J4"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6ULYNH6-o3Hf"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3ClM-JTJo3FK"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "TemplateTrabalhoFinal-NLP.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "metadata": {
   "interpreter": {
    "hash": "63fd5069d213b44bf678585dea6b12cceca9941eaf7f819626cde1f2670de90d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
