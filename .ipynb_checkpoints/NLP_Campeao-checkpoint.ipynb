{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1d6f00b3-34ae-44e8-8119-05b48538ca0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to C:\\Users\\Roberto\n",
      "[nltk_data]     Tengan\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import spacy\n",
    "import nltk\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "nlp = spacy.load('pt_core_news_sm')\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "346d3e66-d124-473a-95ac-ad090d98ac1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# função de lematização completa do documento\n",
    "def lemmatizer(frase):\n",
    "  doc = nlp(frase)\n",
    "  tokens = [w.lemma_ for w in doc]\n",
    "  return \" \".join(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3792e2b3-7fd2-465e-8ee7-218335e3aa6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "stops = list(set(nlp.Defaults.stop_words).union(set(nltk.corpus.stopwords.words('portuguese'))))\n",
    "df = pd.read_csv('./data/reviews-pt-br.csv', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "519f1782-d82c-401f-bf18-54b56255bb1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 21min 23s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df['lemma'] = df.texto.apply(lemmatizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "76818cd7-2f7c-4a77-9fb6-9c01f7db7549",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_treino, df_teste = train_test_split(\n",
    "      df, \n",
    "      test_size = 0.2, \n",
    "      random_state = 42\n",
    "  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a78116df-ad8f-4e8a-89c6-39179c07d3eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 28.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "vect = CountVectorizer(ngram_range=(1,2))\n",
    "vect.fit(df_treino.lemma)\n",
    "text_vect_treino = vect.transform(df_treino.lemma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "53ea5e40-f4c6-4312-abb3-54edcf9c981e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\FIAP\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression\n",
      "Acuracidade: 0.9007\n",
      "F1 Score: 0.9007\n",
      "=======================================\n",
      "Wall time: 48.9 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "model = LogisticRegression(random_state=42)\n",
    "model.fit(text_vect_treino, df_treino.sentimento)\n",
    "\n",
    "# vetorização do dataframe de teste\n",
    "text_vect_teste = vect.transform(df_teste.lemma)\n",
    "\n",
    "# escoragem da classificação na amostra de teste (textos vetorizados)\n",
    "y_predicao = model.predict(text_vect_teste)\n",
    "\n",
    "# mensuração do resultado pela acurácia\n",
    "y_teste = df_teste.sentimento\n",
    "accuracy = accuracy_score(df_teste.sentimento, y_predicao)\n",
    "f1score = f1_score(df_teste.sentimento, y_predicao, average='weighted')\n",
    "print(\"Logistic Regression\")\n",
    "print(f\"Acuracidade: {round(accuracy,4)}\")\n",
    "print(f\"F1 Score: {round(f1score,4)}\")\n",
    "print(\"=======================================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebc0f45a-874d-4205-ad78-4c96d18608a4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
