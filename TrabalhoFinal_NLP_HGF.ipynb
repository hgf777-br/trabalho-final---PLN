{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VDbi6PDS9MYO"
      },
      "source": [
        "***Participantes (RM - NOME):***<br>\n",
        "339624 - Camila<br>\n",
        "339656 - Cleiton<br>\n",
        "340214 - Henrique<br>\n",
        "339708 - Roberto<br>\n",
        "340192 - Sergio<br>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7xw6WhaNo4k3"
      },
      "source": [
        "## **Criar um classificador de sentimento aplicando técnicas de PLN**\n",
        "---\n",
        "\n",
        "Utilizando o dataset de revisões de filmes em português [1], criar um classificador de sentimentos que consiga um score na métrica F1 Score superior a 70%.\n",
        "\n",
        "Devem utilizar uma amostra de 20% e randon_state igual a 42 para testar as implementações e mensurar a métrica F1 Score (usar o parâmetro average = 'weighted') o restante dos dados devem ser utilizados para o treinamento (80%).\n",
        "\n",
        "Fique a vontade para testar os métodos de pré-processamento, abordagens, algoritmos e bibliotecas, mas explique e justifique suas decisões.\n",
        "O trabalho poderá ser feito em grupo de até 4 pessoas (mesmo grupo do Startup One).\n",
        "\n",
        "Separe a implementação do seu modelo campeão junto com a parte de validação/teste de forma que o professor consiga executar todo o pipeline do modelo campeão.\n",
        "\n",
        "Composição da nota:\n",
        "- 50% - Demonstrações das aplicações das técnicas de PLN (regras, pré-processamentos, tratamentos, variedade de modelos aplicados, etc.)\n",
        "- 50% - Baseado na performance obtida com o dataset de teste (conforme recomendação da amostra) no seu modelo campeão e na validação que o professor processar (Métrica F1 Score)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fzhQpodBpRpX"
      },
      "source": [
        "[1] - https://dados-ml-pln.s3-sa-east-1.amazonaws.com/reviews-pt-br.csv"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Bibliotecas utilizadas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sb\n",
        "import matplotlib.pyplot as plt\n",
        "import wordcloud as wd\n",
        "import re\n",
        "from collections import Counter\n",
        "\n",
        "import spacy\n",
        "\n",
        "import nltk\n",
        "from nltk.stem.rslp import RSLPStemmer\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
        "from sklearn.metrics import accuracy_score, f1_score\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer, HashingVectorizer\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, BaggingClassifier, ExtraTreesClassifier, GradientBoostingClassifier\n",
        "from sklearn.linear_model import LogisticRegression, PassiveAggressiveClassifier, Perceptron, RidgeClassifier, SGDClassifier\n",
        "from sklearn.naive_bayes import BernoulliNB, ComplementNB, MultinomialNB\n",
        "from sklearn.svm import LinearSVC\n",
        "\n",
        "\n",
        "import tensorflow as tf\n",
        "import keras\n",
        "from keras.backend import clear_session\n",
        "from keras.callbacks import ModelCheckpoint   \n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.models import Sequential, Model, load_model\n",
        "from keras.layers import Input, Dense, SpatialDropout1D, LSTM\n",
        "from keras.layers import Dropout, Flatten, Conv1D, Embedding\n",
        "from keras.layers import GlobalMaxPooling1D\n",
        "from keras.utils.vis_utils import plot_model\n",
        "from keras.layers.convolutional import Conv1D, MaxPooling1D\n",
        "from keras.layers.convolutional import MaxPooling1D\n",
        "import pydot\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "sb.set_theme(context='notebook', style='whitegrid')\n",
        "\n",
        "nlp = spacy.load('pt_core_news_md')\n",
        "rslp = RSLPStemmer()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2.3.0\n",
            "True\n",
            "Num GPUs Available:  1\n"
          ]
        }
      ],
      "source": [
        "print(tf.__version__)\n",
        "#print(keras.__version__)\n",
        "print(tf.test.is_built_with_cuda())\n",
        "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Funções externas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "# função de Stemização completa do documento\n",
        "def stemmer_text(frase):\n",
        "  tokens = [rslp.stem(w) for w in frase.split()]\n",
        "  return \" \".join(tokens)\n",
        "\n",
        "# função de lematização completa do documento\n",
        "def lemmatizer_text(frase):\n",
        "  doc = nlp(frase)\n",
        "  tokens = [w.lemma_ for w in doc]\n",
        "  return \" \".join(tokens)\n",
        "\n",
        "# função de lematização somente para os verbos do documento\n",
        "def lemmatizer_verbs(frase):\n",
        "  doc = nlp(frase)\n",
        "  tokens = [w.lemma_ if w.pos_ == 'VERB' else w.text for w in doc]\n",
        "  return \" \".join(tokens)\n",
        "\n",
        "# função de lematização apenas ADV e ADJ\n",
        "def lemmatizer_adv_adj(frase):\n",
        "  doc = nlp(frase)\n",
        "  tokens = [w.lemma_ for w in doc if (w.pos_ == 'ADV' or w.pos_ == 'ADJ')]\n",
        "  return \" \".join(tokens)  \n",
        "\n",
        "# função para retiral o plural das palavras em português\n",
        "def plural_singular(palavra):\n",
        "  r2 = r\"ses$|zes$|res$\"\n",
        "  r3 = r\"ões$|ães$\"\n",
        "  r4 = r\"ais$|éis$|óis$|uis$\"\n",
        "  r5 = r\"is$\"\n",
        "  r6 = r\"eis$\"\n",
        "  if palavra.endswith('s'):\n",
        "    if re.findall(r2, palavra):\n",
        "      return palavra[:-2]\n",
        "    if re.findall(r3, palavra):\n",
        "      return palavra[:-3] + \"ão\"\n",
        "    if re.findall(r4, palavra):\n",
        "      return palavra[:-2] + \"l\"\n",
        "    if re.findall(r5, palavra):\n",
        "      return palavra[:-1] + \"l\"\n",
        "    if re.findall(r6, palavra):\n",
        "      return palavra[:-1] + \"il\"\n",
        "    if palavra.endswith('ns'):\n",
        "      return palavra[:-2] + \"m\"\n",
        "    return palavra[:-1]\n",
        "  return palavra  \n",
        "\n",
        "# função para executar o pré processamento\n",
        "def pre(frase):\n",
        "  regex = r\"[`,.?:;!&\\\"]\"\n",
        "  palavras = frase.split()\n",
        "  palavras = [p.lower() for p in palavras if p not in stops]\n",
        "  palavras = [re.sub(regex, \"\", p) for p in palavras]\n",
        "  palavras = [p for p in palavras if len(p) >= 3]\n",
        "  palavras = [p for p in palavras if not p.isnumeric()]\n",
        "  palavras = [plural_singular(p) for p in palavras]\n",
        "\n",
        "  return \" \".join(palavras)\n",
        "\n",
        "# função para criar as bases de treino e teste vetorizadas, com Unigramas, Bigramas e Trigramas\n",
        "def criar_vetores(base_treino, base_teste, coluna):\n",
        "    nomes = ['CV ngram(1,1)', 'CV ngram(1,2)', 'CV ngram(1,3)', 'CV ngram(2,2)', 'CV ngram(2,3)', 'CV ngram(3,3)',\n",
        "                'TF ngram(1,1)', 'TF ngram(1,2)', 'TF ngram(1,3)', 'TF ngram(2,2)', 'TF ngram(2,3)', 'TF ngram(3,3)',]\n",
        "    vetores = []\n",
        "    idx = 0\n",
        "\n",
        "    for x in range(1,4):\n",
        "        for y in range(1,4): \n",
        "            if (y < x):\n",
        "                continue\n",
        "            vect = CountVectorizer(ngram_range=(x,y), stop_words = stops, min_df=10)\n",
        "            vect.fit(df_treino[coluna])\n",
        "            vect_treino = vect.transform(df_treino[coluna])\n",
        "            vect_teste = vect.transform(df_teste[coluna])\n",
        "            vetores.append([nomes[idx], vect_treino, vect_teste])\n",
        "            idx += 1\n",
        "\n",
        "    for x in range(1,4):\n",
        "        for y in range(1,4): \n",
        "            if (y < x):\n",
        "                continue\n",
        "            vect = TfidfVectorizer(ngram_range=(x,y), stop_words = stops, min_df=10)\n",
        "            vect.fit(df_treino['texto'])\n",
        "            vect_treino = vect.transform(df_treino[coluna])\n",
        "            vect_teste = vect.transform(df_teste[coluna])\n",
        "            vetores.append([nomes[idx], vect_treino, vect_teste])\n",
        "            idx += 1\n",
        "\n",
        "    return vetores\n",
        "\n",
        "def testar_modelo(modelo, base_treino, base_teste, vetores, coluna):\n",
        "    f1score = 0\n",
        "    nome = \"\"\n",
        "    for x in vetores:\n",
        "        modelo.fit(x[1], base_treino[coluna])\n",
        "        predito = modelo.predict(x[2])\n",
        "        f1 = f1_score(base_teste[coluna], predito, average='weighted')\n",
        "        print(x[0], f1)\n",
        "        if (f1score < f1):\n",
        "            f1score = f1\n",
        "            nome = x[0]\n",
        "\n",
        "    return (nome, f1score)    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "t = \"Este fime é muito bom e especial\"\n",
        "\n",
        "d = nlp(t)\n",
        "for w in d:\n",
        "    print(w.text, w.pos_, w.lemma_, w.dep_)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Carregando os Dados"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DMBI8SQtps1n"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv('./data/reviews-pt-br.csv', encoding='utf-8')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s__lBzDQwrcG",
        "outputId": "0bd3d84d-be60-4da3-c598-62f4a045b6c6"
      },
      "outputs": [],
      "source": [
        "df.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ue0nV0uVo3OZ"
      },
      "outputs": [],
      "source": [
        "df.head(10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FyKC9Vhkp0BK"
      },
      "source": [
        "## Conferindo se temos dados nulos ou duplicados"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nze8UbKhosm9"
      },
      "outputs": [],
      "source": [
        "df.isna().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df[df.duplicated()].count()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Distribuição das respostas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df.groupby('sentimento').count()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# em percentual\n",
        "round(df.groupby('sentimento').count().texto / df.shape[0] * 100, 2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FziwgqJmw9OD"
      },
      "outputs": [],
      "source": [
        "sb.countplot(x=df.sentimento)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Criando o conjunto de stopwords (NLTK + SPACY)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['a', 'acerca', 'ademais', 'adeus', 'agora', 'ainda', 'algo', 'algumas', 'alguns', 'ali', 'além', 'ambas', 'ambos', 'antes', 'ao', 'aos', 'apenas', 'apoia', 'apoio', 'apontar', 'após', 'aquela', 'aquelas', 'aquele', 'aqueles', 'aqui', 'aquilo', 'as', 'assim', 'através', 'atrás', 'até', 'aí', 'baixo', 'bastante', 'bem', 'boa', 'bom', 'breve', 'cada', 'caminho', 'catorze', 'cedo', 'cento', 'certamente', 'certeza', 'cima', 'cinco', 'coisa', 'com', 'como', 'comprida', 'comprido', 'conhecida', 'conhecido', 'conselho', 'contra', 'contudo', 'corrente', 'cuja', 'cujo', 'custa', 'cá', 'da', 'daquela', 'daquele', 'dar', 'das', 'de', 'debaixo', 'dela', 'delas', 'dele', 'deles', 'demais', 'dentro', 'depois', 'des', 'desde', 'dessa', 'desse', 'desta', 'deste', 'deve', 'devem', 'deverá', 'dez', 'dezanove', 'dezasseis', 'dezassete', 'dezoito', 'diante', 'direita', 'disso', 'diz', 'dizem', 'dizer', 'do', 'dois', 'dos', 'doze', 'duas', 'dá', 'dão', 'e', 'ela', 'elas', 'ele', 'eles', 'em', 'embora', 'enquanto', 'entre', 'então', 'era', 'eram', 'essa', 'essas', 'esse', 'esses', 'esta', 'estado', 'estamos', 'estar', 'estará', 'estas', 'estava', 'estavam', 'este', 'esteja', 'estejam', 'estejamos', 'estes', 'esteve', 'estive', 'estivemos', 'estiver', 'estivera', 'estiveram', 'estiverem', 'estivermos', 'estivesse', 'estivessem', 'estiveste', 'estivestes', 'estivéramos', 'estivéssemos', 'estou', 'está', 'estás', 'estávamos', 'estão', 'eu', 'eventual', 'exemplo', 'falta', 'fará', 'favor', 'faz', 'fazeis', 'fazem', 'fazemos', 'fazer', 'fazes', 'fazia', 'faço', 'fez', 'fim', 'final', 'foi', 'fomos', 'for', 'fora', 'foram', 'forem', 'forma', 'formos', 'fosse', 'fossem', 'foste', 'fostes', 'fui', 'fôramos', 'fôssemos', 'geral', 'grande', 'grandes', 'grupo', 'haja', 'hajam', 'hajamos', 'havemos', 'hei', 'houve', 'houvemos', 'houver', 'houvera', 'houveram', 'houverei', 'houverem', 'houveremos', 'houveria', 'houveriam', 'houvermos', 'houverá', 'houverão', 'houveríamos', 'houvesse', 'houvessem', 'houvéramos', 'houvéssemos', 'há', 'hão', 'inclusive', 'iniciar', 'inicio', 'ir', 'irá', 'isso', 'isto', 'já', 'lado', 'lhe', 'lhes', 'ligado', 'local', 'logo', 'longe', 'lugar', 'lá', 'maior', 'maioria', 'maiorias', 'mais', 'mal', 'mas', 'me', 'meio', 'menor', 'menos', 'meses', 'mesmo', 'meu', 'meus', 'mil', 'minha', 'minhas', 'momento', 'muito', 'muitos', 'máximo', 'mês', 'na', 'nada', 'naquela', 'naquele', 'nas', 'nem', 'nenhuma', 'nessa', 'nesse', 'nesta', 'neste', 'no', 'nos', 'nossa', 'nossas', 'nosso', 'nossos', 'nova', 'novas', 'nove', 'novo', 'novos', 'num', 'numa', 'nunca', 'nuns', 'não', 'nível', 'nós', 'número', 'números', 'o', 'obrigada', 'obrigado', 'oitava', 'oitavo', 'oito', 'onde', 'ontem', 'onze', 'ora', 'os', 'ou', 'outra', 'outras', 'outros', 'para', 'parece', 'parte', 'partir', 'pegar', 'pela', 'pelas', 'pelo', 'pelos', 'perto', 'pode', 'podem', 'poder', 'poderá', 'podia', 'pois', 'ponto', 'pontos', 'por', 'porquanto', 'porque', 'porquê', 'portanto', 'porém', 'posição', 'possivelmente', 'posso', 'possível', 'pouca', 'pouco', 'povo', 'primeira', 'primeiro', 'próprio', 'próxima', 'próximo', 'puderam', 'pôde', 'põe', 'põem', 'quais', 'qual', 'qualquer', 'quando', 'quanto', 'quarta', 'quarto', 'quatro', 'que', 'quem', 'quer', 'querem', 'quero', 'questão', 'quieta', 'quieto', 'quinta', 'quinto', 'quinze', 'quê', 'relação', 'sabe', 'saber', 'se', 'segunda', 'segundo', 'sei', 'seis', 'seja', 'sejam', 'sejamos', 'sem', 'sempre', 'ser', 'serei', 'seremos', 'seria', 'seriam', 'será', 'serão', 'seríamos', 'sete', 'seu', 'seus', 'sexta', 'sexto', 'sim', 'sistema', 'sob', 'sobre', 'sois', 'somente', 'somos', 'sou', 'sua', 'suas', 'são', 'sétima', 'sétimo', 'só', 'tais', 'tal', 'talvez', 'também', 'tanta', 'tanto', 'tarde', 'te', 'tem', 'temos', 'tempo', 'tendes', 'tenha', 'tenham', 'tenhamos', 'tenho', 'tens', 'tentar', 'tentaram', 'tente', 'tentei', 'ter', 'terceira', 'terceiro', 'terei', 'teremos', 'teria', 'teriam', 'terá', 'terão', 'teríamos', 'teu', 'teus', 'teve', 'tinha', 'tinham', 'tipo', 'tive', 'tivemos', 'tiver', 'tivera', 'tiveram', 'tiverem', 'tivermos', 'tivesse', 'tivessem', 'tiveste', 'tivestes', 'tivéramos', 'tivéssemos', 'toda', 'todas', 'todo', 'todos', 'treze', 'três', 'tu', 'tua', 'tuas', 'tudo', 'tão', 'tém', 'têm', 'tínhamos', 'um', 'uma', 'umas', 'uns', 'usa', 'usar', 'vai', 'vais', 'valor', 'veja', 'vem', 'vens', 'ver', 'vez', 'vezes', 'vinda', 'vindo', 'vinte', 'você', 'vocês', 'vos', 'vossa', 'vossas', 'vosso', 'vossos', 'vários', 'vão', 'vêm', 'vós', 'zero', 'à', 'às', 'área', 'é', 'éramos', 'és', 'último']\n"
          ]
        }
      ],
      "source": [
        "stopwords_nltk = nltk.corpus.stopwords.words('portuguese')\n",
        "stopwords_spacy = nlp.Defaults.stop_words\n",
        "stops = list(set(stopwords_spacy).union(stopwords_nltk))\n",
        "print(sorted(stops))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Analisando o conjunto total das palavras"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# exemplo de críticas no nosso dataframe\n",
        "print(df.texto[0])\n",
        "print(\"-\" * 40)\n",
        "print(df.texto[1536])\n",
        "print(\"-\" * 40)\n",
        "print(df.texto[8192])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# criando um texto completo com todas as críticas\n",
        "texto_completo = \" \".join([texto for texto in df.texto])\n",
        "texto_completo_pos = \" \".join([texto for texto in df[df.sentimento == 'pos'].texto])\n",
        "texto_completo_neg = \" \".join([texto for texto in df[df.sentimento == 'neg'].texto])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"QTD de todas as palvaras\", len(texto_completo.split()))\n",
        "print(\"QTD de todas as palvaras das críticas positivas\", len(texto_completo_pos.split()))\n",
        "print(\"QTD de todas as palvaras das críticas negativas\", len(texto_completo_neg.split()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# criando uma wordcloud de todas as palavra sem as stopwords\n",
        "wordcloud = wd.WordCloud(width = 3000, height = 2000, max_words=50, random_state=42, background_color='black', colormap='Blues', collocations=False, stopwords = stops).generate(texto_completo)\n",
        "\n",
        "plt.figure(figsize=(20, 10))\n",
        "plt.title(\"Todas as palavras da Base de Dados retirando as StopWords\", fontdict={'fontsize':24})\n",
        "plt.imshow(wordcloud) \n",
        "plt.axis(\"off\");\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# criando uma wordcloud de todas as palavra sem as stopwords\n",
        "wordcloud = wd.WordCloud(width = 3000, height = 2000, max_words=50, random_state=42, background_color='black', colormap='Blues', collocations=False, stopwords = stops).generate(texto_completo_pos)\n",
        "\n",
        "plt.figure(figsize=(20, 10))\n",
        "plt.title(\"Todas as palavras POSITIVAS da Base de Dados retirando as StopWords\", fontdict={'fontsize':24})\n",
        "plt.imshow(wordcloud) \n",
        "plt.axis(\"off\");\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# criando uma wordcloud de todas as palavra sem as stopwords\n",
        "wordcloud = wd.WordCloud(width = 3000, height = 2000, max_words=50, random_state=42, background_color='black', colormap='Blues', collocations=False, stopwords = stops).generate(texto_completo_neg)\n",
        "\n",
        "plt.figure(figsize=(20, 10))\n",
        "plt.title(\"Todas as palavras NEGATIVAS da Base de Dados retirando as StopWords\", fontdict={'fontsize':24})\n",
        "plt.imshow(wordcloud) \n",
        "plt.axis(\"off\");\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Criando uma função de pré processamento"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "palavras = texto_completo.split()\n",
        "len(palavras)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# retirando as stopwords das palavras\n",
        "palavras = [p.lower() for p in palavras if p not in stops]\n",
        "len(palavras)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# retirando pontuações das palavras\n",
        "regex = r\"[`,.?:;!&\\\"]\"\n",
        "palavras = [re.sub(regex, \"\", p) for p in palavras]\n",
        "len(palavras)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#retirando palavras menores que 3 caracteres\n",
        "palavras = [p for p in palavras if len(p) >= 3]\n",
        "len(palavras)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# retirando os números das palavras\n",
        "palavras = [p for p in palavras if not p.isnumeric()]\n",
        "len(palavras)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#convertendo as palavras para o singular\n",
        "palavras = [plural_singular(p) for p in palavras]\n",
        "len(palavras)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Criamos uma função chamada \"pre\" que iremos usar em nossas análises dos modelos"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Vamos analisar quais palavras são comuns as críticas negativas e positivas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# criando uma wordcloud das palavras filtradas\n",
        "wordcloud = wd.WordCloud(width = 3000, height = 2000, max_words=50, random_state=42, background_color='black', colormap='Blues', collocations=False).fit_words(dict(ctp))\n",
        "\n",
        "plt.figure(figsize=(20, 10))\n",
        "plt.title(\"Todas as palavras da Base de Dados após o Pré Pocessamento\", fontdict={'fontsize':24})\n",
        "plt.imshow(wordcloud) \n",
        "plt.axis(\"off\");\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "todas_palavras_pos = texto_completo_pos.split()\n",
        "todas_palavras_pos = [pre(w) for w in todas_palavras_pos]\n",
        "todas_palavras_pos = [w for w in todas_palavras_pos if w != '']\n",
        "ctpp = Counter()\n",
        "ctpp.update(todas_palavras_pos)\n",
        "ctpp.most_common(50)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "todas_palavras_neg = texto_completo_neg.split()\n",
        "todas_palavras_neg = [pre(w) for w in todas_palavras_neg]\n",
        "todas_palavras_neg = [w for w in todas_palavras_neg if w != '']\n",
        "ctpn = Counter()\n",
        "ctpn.update(todas_palavras_neg)\n",
        "ctpn.most_common(50)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%%time\n",
        "p = ctpp.most_common()\n",
        "n = ctpn.most_common()\n",
        "r = [[x for x in p if x[0] == y[0]] for y in n]\n",
        "r = [x for x in r if len(x) != 0]\n",
        "len(r)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "palavras_comuns = [w[0][0] for w in r]\n",
        "palavras_comuns[:100]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Criando as colunas tratadas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%%time\n",
        "#df['stem'] = df.texto.apply(stemmer_text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%time\n",
        "#df['lemm'] = df.texto.apply(lemmatizer_text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%%time\n",
        "#df['verb'] = df.texto.apply(lemmatizer_verbs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%%time\n",
        "#df['pre'] = df.texto.apply(pre)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Wall time: 26min 16s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "#df['adj'] = df.texto.apply(lemmatizer_adv_adj)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "#df.to_csv(\"./data/criticas.csv\")\n",
        "df = pd.read_csv('../criticas.csv')\n",
        "df = df.drop(['Unnamed: 0', 'codigo'], axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>texto</th>\n",
              "      <th>sentimento</th>\n",
              "      <th>stem</th>\n",
              "      <th>lemm</th>\n",
              "      <th>verb</th>\n",
              "      <th>pre</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Esse bocejo de pia de cozinha de orçamento mui...</td>\n",
              "      <td>neg</td>\n",
              "      <td>ess bocej de pia de co de orç muit baix é o ti...</td>\n",
              "      <td>Esse bocejar de pio de cozinhar de orçamentar ...</td>\n",
              "      <td>Esse bocejo de pia de cozinha de orçamento mui...</td>\n",
              "      <td>esse bocejo pia cozinha orçamento filme feito ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>O Bravo parece indicar que o personagem princi...</td>\n",
              "      <td>neg</td>\n",
              "      <td>o brav parec indic que o person principal, cla...</td>\n",
              "      <td>O Bravo parecer indicar que o personagem princ...</td>\n",
              "      <td>O Bravo parecer indicar que o personagem princ...</td>\n",
              "      <td>bravo indicar personagem principal claro coraj...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Durante a Guerra pela Independência do Sul, GE...</td>\n",
              "      <td>pos</td>\n",
              "      <td>dur a guerr pel independ do sul, gener spanky ...</td>\n",
              "      <td>Durante o Guerra pelar Independência do Sul , ...</td>\n",
              "      <td>Durante a Guerra pela Independência do Sul , G...</td>\n",
              "      <td>durante guerra independência sul general spank...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>É fora de questão que a verdadeira Anna Anders...</td>\n",
              "      <td>pos</td>\n",
              "      <td>é for de quest que a verd ann anderson não era...</td>\n",
              "      <td>É ser de questão que o verdadeiro Anna Anderso...</td>\n",
              "      <td>É fora de questão que a verdadeira Anna Anders...</td>\n",
              "      <td>verdadeira anna anderson princesa anastasia al...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Concordo totalmente com outro dos revisores aq...</td>\n",
              "      <td>neg</td>\n",
              "      <td>concord total com outr do revi aqu que fic sat...</td>\n",
              "      <td>Concordo totalmente com outro dos revisor aqui...</td>\n",
              "      <td>Concordo totalmente com outro dos revisores aq...</td>\n",
              "      <td>concordo totalmente outro revisor ficou satisf...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>Obra-prima absoluta de um filme! Boa noite Mr....</td>\n",
              "      <td>pos</td>\n",
              "      <td>obra-pr absolut de um filme! boa noit mr.tom r...</td>\n",
              "      <td>Obra-prima absoluto de um filmar ! Boa noite M...</td>\n",
              "      <td>Obra-prima absoluta de um filme ! Boa noite Mr...</td>\n",
              "      <td>obra-prima absoluta filme boa noite mrtom rapi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>Embora a palavra megalmania seja muito usada p...</td>\n",
              "      <td>pos</td>\n",
              "      <td>emb a palavr megalman sej muit us par descrev ...</td>\n",
              "      <td>Embora o palavra megalmania ser muito usar par...</td>\n",
              "      <td>Embora a palavra megalmania seja muito usar pa...</td>\n",
              "      <td>embora palavra megalmania usada descrever gene...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>Esta tem que ser a peça mais incrível de porca...</td>\n",
              "      <td>neg</td>\n",
              "      <td>est tem que ser a peç mais incr de porc cinema...</td>\n",
              "      <td>Esta ter que ser o pedir mais incrível de porc...</td>\n",
              "      <td>Esta tem que ser a peça mais incrível de porca...</td>\n",
              "      <td>esta peça incrível porcaria cinematográfica as...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>Eu suponho que todas as piadas internas são o ...</td>\n",
              "      <td>neg</td>\n",
              "      <td>eu suponh que tod as pi intern são o que fez d...</td>\n",
              "      <td>Eu supor que todo o piar interno ser o que faz...</td>\n",
              "      <td>Eu supor que todas as piadas internas são o qu...</td>\n",
              "      <td>suponho piada interna munchie clássico cult pe...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>Se há um tema deste filme, é que as pessoas po...</td>\n",
              "      <td>pos</td>\n",
              "      <td>se há um tem dest filme, é que as pesso pod li...</td>\n",
              "      <td>Se haver um temer dar filmar , ser que o pesso...</td>\n",
              "      <td>Se haver um tema deste filme , ser que as pess...</td>\n",
              "      <td>tema filme pessoa lidar dificuldade imaginação...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                               texto sentimento  \\\n",
              "0  Esse bocejo de pia de cozinha de orçamento mui...        neg   \n",
              "1  O Bravo parece indicar que o personagem princi...        neg   \n",
              "2  Durante a Guerra pela Independência do Sul, GE...        pos   \n",
              "3  É fora de questão que a verdadeira Anna Anders...        pos   \n",
              "4  Concordo totalmente com outro dos revisores aq...        neg   \n",
              "5  Obra-prima absoluta de um filme! Boa noite Mr....        pos   \n",
              "6  Embora a palavra megalmania seja muito usada p...        pos   \n",
              "7  Esta tem que ser a peça mais incrível de porca...        neg   \n",
              "8  Eu suponho que todas as piadas internas são o ...        neg   \n",
              "9  Se há um tema deste filme, é que as pessoas po...        pos   \n",
              "\n",
              "                                                stem  \\\n",
              "0  ess bocej de pia de co de orç muit baix é o ti...   \n",
              "1  o brav parec indic que o person principal, cla...   \n",
              "2  dur a guerr pel independ do sul, gener spanky ...   \n",
              "3  é for de quest que a verd ann anderson não era...   \n",
              "4  concord total com outr do revi aqu que fic sat...   \n",
              "5  obra-pr absolut de um filme! boa noit mr.tom r...   \n",
              "6  emb a palavr megalman sej muit us par descrev ...   \n",
              "7  est tem que ser a peç mais incr de porc cinema...   \n",
              "8  eu suponh que tod as pi intern são o que fez d...   \n",
              "9  se há um tem dest filme, é que as pesso pod li...   \n",
              "\n",
              "                                                lemm  \\\n",
              "0  Esse bocejar de pio de cozinhar de orçamentar ...   \n",
              "1  O Bravo parecer indicar que o personagem princ...   \n",
              "2  Durante o Guerra pelar Independência do Sul , ...   \n",
              "3  É ser de questão que o verdadeiro Anna Anderso...   \n",
              "4  Concordo totalmente com outro dos revisor aqui...   \n",
              "5  Obra-prima absoluto de um filmar ! Boa noite M...   \n",
              "6  Embora o palavra megalmania ser muito usar par...   \n",
              "7  Esta ter que ser o pedir mais incrível de porc...   \n",
              "8  Eu supor que todo o piar interno ser o que faz...   \n",
              "9  Se haver um temer dar filmar , ser que o pesso...   \n",
              "\n",
              "                                                verb  \\\n",
              "0  Esse bocejo de pia de cozinha de orçamento mui...   \n",
              "1  O Bravo parecer indicar que o personagem princ...   \n",
              "2  Durante a Guerra pela Independência do Sul , G...   \n",
              "3  É fora de questão que a verdadeira Anna Anders...   \n",
              "4  Concordo totalmente com outro dos revisores aq...   \n",
              "5  Obra-prima absoluta de um filme ! Boa noite Mr...   \n",
              "6  Embora a palavra megalmania seja muito usar pa...   \n",
              "7  Esta tem que ser a peça mais incrível de porca...   \n",
              "8  Eu supor que todas as piadas internas são o qu...   \n",
              "9  Se haver um tema deste filme , ser que as pess...   \n",
              "\n",
              "                                                 pre  \n",
              "0  esse bocejo pia cozinha orçamento filme feito ...  \n",
              "1  bravo indicar personagem principal claro coraj...  \n",
              "2  durante guerra independência sul general spank...  \n",
              "3  verdadeira anna anderson princesa anastasia al...  \n",
              "4  concordo totalmente outro revisor ficou satisf...  \n",
              "5  obra-prima absoluta filme boa noite mrtom rapi...  \n",
              "6  embora palavra megalmania usada descrever gene...  \n",
              "7  esta peça incrível porcaria cinematográfica as...  \n",
              "8  suponho piada interna munchie clássico cult pe...  \n",
              "9  tema filme pessoa lidar dificuldade imaginação...  "
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.head(10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Dividindo a base em treino e teste"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {},
      "outputs": [],
      "source": [
        "# dividindo com 20% para o treino e random state = 42\n",
        "df_treino, df_teste = train_test_split(\n",
        "      df, \n",
        "      test_size = 0.2, \n",
        "      random_state = 42\n",
        "  )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "sentimento\n",
              "neg    40.07\n",
              "pos    39.93\n",
              "Name: texto, dtype: float64"
            ]
          },
          "execution_count": 37,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# distribuição das respostas do treino em %\n",
        "round(df_treino.groupby('sentimento').count() / df.shape[0] * 100, 2).texto"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "sentimento\n",
              "neg    10.04\n",
              "pos     9.96\n",
              "Name: texto, dtype: float64"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# distribuição das respostas do teste em %\n",
        "round(df_teste.groupby('sentimento').count() / df.shape[0] * 100, 2).texto"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Testando diversos modelos com a base total de palavras sem stopwords"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Criando os vetores com CountVectorizer e TfidfVectorizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Wall time: 4min 23s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "# criando os vetores para Unigramas, Bigramas, Trigramas com CountVectorizer e TfidfVectorizer\n",
        "vetores = criar_vetores(df_treino, df_teste, 'texto')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Testando diversos modelos com os vetores criados"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CV ngram(1,1) 0.7334065607517617\n",
            "CV ngram(1,2) 0.7389972124839376\n",
            "CV ngram(1,3) 0.7416456410429769\n",
            "CV ngram(2,2) 0.6132194031871322\n",
            "CV ngram(2,3) 0.6143754350124869\n",
            "CV ngram(3,3) 0.440902916358259\n",
            "TF ngram(1,1) 0.7242198298707084\n",
            "TF ngram(1,2) 0.7260879021556159\n",
            "TF ngram(1,3) 0.7269344378693082\n",
            "TF ngram(2,2) 0.611408385276224\n",
            "TF ngram(2,3) 0.6152997395176724\n",
            "TF ngram(3,3) 0.4438377004527155\n",
            "\n",
            "Árvore de Decisão - CV ngram(1,3) - F1 Score: 74.16%\n",
            "Wall time: 3min 53s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "# modelo Árvore de Decisão\n",
        "modelo = DecisionTreeClassifier(random_state=42, max_depth=50)\n",
        "# calculo com todos os vetores.\n",
        "f1score = testar_modelo(modelo, df_treino, df_teste, vetores, 'sentimento')\n",
        "\n",
        "print()\n",
        "print(f\"Árvore de Decisão - {f1score[0]} - F1 Score: {round(f1score[1]*100,2)}%\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CV ngram(1,1) 0.8570091422646389\n",
            "CV ngram(1,2) 0.8580194411160453\n",
            "CV ngram(1,3) 0.8610559351736565\n",
            "CV ngram(2,2) 0.7738974149816571\n",
            "CV ngram(2,3) 0.7747957289121654\n",
            "CV ngram(3,3) 0.5939805367253124\n",
            "TF ngram(1,1) 0.8527194695341529\n",
            "TF ngram(1,2) 0.8548498155717084\n",
            "TF ngram(1,3) 0.8569934729963394\n",
            "TF ngram(2,2) 0.7777573321458281\n",
            "TF ngram(2,3) 0.7803476027605121\n",
            "TF ngram(3,3) 0.5922386561501604\n",
            "\n",
            "Random Forest - CV ngram(1,3) - F1 Score: 86.11%\n",
            "Wall time: 6min 19s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "# modelo Random Forest\n",
        "modelo = RandomForestClassifier(n_estimators=200, random_state=42, n_jobs=-1)\n",
        "# calculo com todos os vetores.\n",
        "f1score = testar_modelo(modelo, df_treino, df_teste, vetores, 'sentimento')\n",
        "\n",
        "print()\n",
        "print(f\"Random Forest - {f1score[0]} - F1 Score: {round(f1score[1]*100,2)}%\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CV ngram(1,1) 0.8113072237344358\n",
            "CV ngram(1,2) 0.8119893681619048\n",
            "CV ngram(1,3) 0.8119893681619048\n",
            "CV ngram(2,2) 0.6631463063565599\n",
            "CV ngram(2,3) 0.6630078264083823\n",
            "CV ngram(3,3) 0.46169500243275796\n",
            "TF ngram(1,1) 0.8087066011318896\n",
            "TF ngram(1,2) 0.8060494093349827\n",
            "TF ngram(1,3) 0.8055787156701836\n",
            "TF ngram(2,2) 0.668940166492079\n",
            "TF ngram(2,3) 0.6717980213185778\n",
            "TF ngram(3,3) 0.46618350077771004\n",
            "\n",
            "AdaBoost - CV ngram(1,2) - F1 Score: 81.2%\n",
            "Wall time: 3min 46s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "# modelo AdaBoost\n",
        "modelo = AdaBoostClassifier(n_estimators=100, random_state=42)\n",
        "# calculo com todos os vetores.\n",
        "f1score = testar_modelo(modelo, df_treino, df_teste, vetores, 'sentimento')\n",
        "\n",
        "print()\n",
        "print(f\"AdaBoost - {f1score[0]} - F1 Score: {round(f1score[1]*100,2)}%\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CV ngram(1,1) 0.7829529863109658\n",
            "CV ngram(1,2) 0.7822625447604084\n",
            "CV ngram(1,3) 0.7840829303681472\n",
            "CV ngram(2,2) 0.7470878093253949\n",
            "CV ngram(2,3) 0.7506578822171368\n",
            "CV ngram(3,3) 0.5922569249811895\n",
            "TF ngram(1,1) 0.7935963307402973\n",
            "TF ngram(1,2) 0.787549924702114\n",
            "TF ngram(1,3) 0.793389110907307\n",
            "TF ngram(2,2) 0.749359985803243\n",
            "TF ngram(2,3) 0.7512825374870906\n",
            "TF ngram(3,3) 0.592533692930128\n",
            "\n",
            "Bagging - TF ngram(1,1) - F1 Score: 79.36%\n",
            "Wall time: 27min 30s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "# modelo Bagging Classifier\n",
        "modelo = BaggingClassifier(n_estimators=20, random_state=42, n_jobs=-1)\n",
        "# calculo com todos os vetores.\n",
        "f1score = testar_modelo(modelo, df_treino, df_teste, vetores, 'sentimento')\n",
        "\n",
        "print()\n",
        "print(f\"Bagging - {f1score[0]} - F1 Score: {round(f1score[1]*100,2)}%\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CV ngram(1,1) 0.8708200533848273\n",
            "CV ngram(1,2) 0.8759927433580862\n",
            "CV ngram(1,3) 0.8758795252960768\n",
            "CV ngram(2,2) 0.7811582020103887\n",
            "CV ngram(2,3) 0.7781320574766459\n",
            "CV ngram(3,3) 0.5925747779938603\n",
            "TF ngram(1,1) 0.8709188943514428\n",
            "TF ngram(1,2) 0.8750847464964969\n",
            "TF ngram(1,3) 0.8756461176623055\n",
            "TF ngram(2,2) 0.7963599859499786\n",
            "TF ngram(2,3) 0.7935512034983379\n",
            "TF ngram(3,3) 0.5923588709500518\n",
            "\n",
            "Extra Trees Regressor - CV ngram(1,2) - F1 Score: 87.6%\n",
            "Wall time: 9min 20s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "# modelo Extra Trees Regressor\n",
        "modelo = ExtraTreesClassifier(n_estimators=200, random_state=42, n_jobs=-1)\n",
        "# calculo com todos os vetores.\n",
        "f1score = testar_modelo(modelo, df_treino, df_teste, vetores, 'sentimento')\n",
        "\n",
        "print()\n",
        "print(f\"Extra Trees Regressor - {f1score[0]} - F1 Score: {round(f1score[1]*100,2)}%\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CV ngram(1,1) 0.8131037840926045\n",
            "CV ngram(1,2) 0.8154661088177287\n",
            "CV ngram(1,3) 0.8136564531371888\n",
            "CV ngram(2,2) 0.703771331017916\n",
            "CV ngram(2,3) 0.7053132711254233\n",
            "CV ngram(3,3) 0.5000896766537951\n",
            "TF ngram(1,1) 0.8132784816099118\n",
            "TF ngram(1,2) 0.8164773941162936\n",
            "TF ngram(1,3) 0.814008556621088\n",
            "TF ngram(2,2) 0.7067345728742199\n",
            "TF ngram(2,3) 0.7063127642730296\n",
            "TF ngram(3,3) 0.500132627555598\n",
            "\n",
            "Gradient Boosting - TF ngram(1,2) - F1 Score: 81.65%\n",
            "Wall time: 13min 26s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "# modelo Gradient Boosting\n",
        "modelo = GradientBoostingClassifier(n_estimators=200, random_state=42)\n",
        "# calculo com todos os vetores.\n",
        "f1score = testar_modelo(modelo, df_treino, df_teste, vetores, 'sentimento')\n",
        "\n",
        "print()\n",
        "print(f\"Gradient Boosting - {f1score[0]} - F1 Score: {round(f1score[1]*100,2)}%\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\hgf77\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\"The max_iter was reached which means \"\n",
            "CV ngram(1,1) 0.8701556226033939\n",
            "C:\\Users\\hgf77\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\"The max_iter was reached which means \"\n",
            "CV ngram(1,2) 0.8791421062562188\n",
            "C:\\Users\\hgf77\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\"The max_iter was reached which means \"\n",
            "CV ngram(1,3) 0.8792543850650043\n",
            "CV ngram(2,2) 0.8180140954546817\n",
            "CV ngram(2,3) 0.8157729065954192\n",
            "CV ngram(3,3) 0.5957558146768905\n",
            "TF ngram(1,1) 0.8809187826450897\n",
            "TF ngram(1,2) 0.889348947719393\n",
            "TF ngram(1,3) 0.8890110656229786\n",
            "TF ngram(2,2) 0.8275236995216966\n",
            "TF ngram(2,3) 0.8272959671164328\n",
            "TF ngram(3,3) 0.5968758108946228\n",
            "\n",
            "Regressão Logística - TF ngram(1,2) - F1 Score: 88.93%\n",
            "Wall time: 2min 51s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "# modelo Regressão Logística\n",
        "modelo = LogisticRegression(solver='saga', max_iter=1000, random_state=42, n_jobs=-1)\n",
        "# calculo com todos os vetores.\n",
        "f1score = testar_modelo(modelo, df_treino, df_teste, vetores, 'sentimento')\n",
        "\n",
        "print()\n",
        "print(f\"Regressão Logística - {f1score[0]} - F1 Score: {round(f1score[1]*100,2)}%\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CV ngram(1,1) 0.8456691927963159\n",
            "CV ngram(1,2) 0.8662239768753464\n",
            "CV ngram(1,3) 0.8673472012508682\n",
            "CV ngram(2,2) 0.7765912918116423\n",
            "CV ngram(2,3) 0.7743456179758983\n",
            "CV ngram(3,3) 0.5423155547597628\n",
            "TF ngram(1,1) 0.8507237969132462\n",
            "TF ngram(1,2) 0.8715043635253087\n",
            "TF ngram(1,3) 0.8717270286280259\n",
            "TF ngram(2,2) 0.7825432505960539\n",
            "TF ngram(2,3) 0.7844517846905066\n",
            "TF ngram(3,3) 0.5502119859308695\n",
            "\n",
            "Passive Agressive - TF ngram(1,3) - F1 Score: 87.17%\n",
            "Wall time: 3.44 s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "# modelo Passive Agressive\n",
        "modelo = PassiveAggressiveClassifier(random_state=42, n_jobs=-1)\n",
        "# calculo com todos os vetores.\n",
        "f1score = testar_modelo(modelo, df_treino, df_teste, vetores, 'sentimento')\n",
        "\n",
        "print()\n",
        "print(f\"Passive Agressive - {f1score[0]} - F1 Score: {round(f1score[1]*100,2)}%\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CV ngram(1,1) 0.7585067593071052\n",
            "CV ngram(1,2) 0.7477234170084225\n",
            "CV ngram(1,3) 0.7525534828089833\n",
            "CV ngram(2,2) 0.7399582036362565\n",
            "CV ngram(2,3) 0.7370462071476761\n",
            "CV ngram(3,3) 0.5925886471995548\n",
            "TF ngram(1,1) 0.8773200856296003\n",
            "TF ngram(1,2) 0.8891242755320212\n",
            "TF ngram(1,3) 0.8883345753860943\n",
            "TF ngram(2,2) 0.8149814872678168\n",
            "TF ngram(2,3) 0.8167834743557018\n",
            "TF ngram(3,3) 0.595673890235394\n",
            "\n",
            "Ridge - TF ngram(1,2) - F1 Score: 88.91%\n",
            "Wall time: 23 s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "# modelo Ridge\n",
        "modelo = RidgeClassifier(solver='sparse_cg', random_state=42)\n",
        "# calculo com todos os vetores.\n",
        "f1score = testar_modelo(modelo, df_treino, df_teste, vetores, 'sentimento')\n",
        "\n",
        "print()\n",
        "print(f\"Ridge - {f1score[0]} - F1 Score: {round(f1score[1]*100,2)}%\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CV ngram(1,1) 0.8548745222099186\n",
            "CV ngram(1,2) 0.8677979087343012\n",
            "CV ngram(1,3) 0.8672275315382145\n",
            "CV ngram(2,2) 0.807559686093767\n",
            "CV ngram(2,3) 0.8044276726022707\n",
            "CV ngram(3,3) 0.5798838824002565\n",
            "TF ngram(1,1) 0.8816760564524672\n",
            "TF ngram(1,2) 0.8879717331315884\n",
            "TF ngram(1,3) 0.8878598659072925\n",
            "TF ngram(2,2) 0.8247457475321708\n",
            "TF ngram(2,3) 0.8234283422807653\n",
            "TF ngram(3,3) 0.5883600913938836\n",
            "\n",
            "SGD - TF ngram(1,2) - F1 Score: 88.8%\n",
            "Wall time: 2.75 s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "# modelo SGD\n",
        "modelo = SGDClassifier(random_state=42, n_jobs=-1)\n",
        "# calculo com todos os vetores.\n",
        "f1score = testar_modelo(modelo, df_treino, df_teste, vetores, 'sentimento')\n",
        "\n",
        "print()\n",
        "print(f\"SGD - {f1score[0]} - F1 Score: {round(f1score[1]*100,2)}%\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CV ngram(1,1) 0.8561785530659148\n",
            "CV ngram(1,2) 0.8746468123072807\n",
            "CV ngram(1,3) 0.8753162962608646\n",
            "CV ngram(2,2) 0.8410494096777025\n",
            "CV ngram(2,3) 0.8381562881984885\n",
            "CV ngram(3,3) 0.5979569271742787\n",
            "TF ngram(1,1) 0.8561785530659148\n",
            "TF ngram(1,2) 0.8746468123072807\n",
            "TF ngram(1,3) 0.8753162962608646\n",
            "TF ngram(2,2) 0.8410494096777025\n",
            "TF ngram(2,3) 0.8381562881984885\n",
            "TF ngram(3,3) 0.5979569271742787\n",
            "\n",
            "Naive Bayes Bernoulli - CV ngram(1,3) - F1 Score: 87.53%\n",
            "Wall time: 1.66 s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "# modelo Naive Bayes Bernoulli\n",
        "modelo = BernoulliNB()\n",
        "# calculo com todos os vetores.\n",
        "f1score = testar_modelo(modelo, df_treino, df_teste, vetores, 'sentimento')\n",
        "\n",
        "print()\n",
        "print(f\"Naive Bayes Bernoulli - {f1score[0]} - F1 Score: {round(f1score[1]*100,2)}%\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CV ngram(1,1) 0.8541920098423615\n",
            "CV ngram(1,2) 0.8710538417137474\n",
            "CV ngram(1,3) 0.8718351898036343\n",
            "CV ngram(2,2) 0.8401366622752207\n",
            "CV ngram(2,3) 0.8396681025173632\n",
            "CV ngram(3,3) 0.5734863253834386\n",
            "TF ngram(1,1) 0.8618447927514207\n",
            "TF ngram(1,2) 0.8746325936041583\n",
            "TF ngram(1,3) 0.8748477005896964\n",
            "TF ngram(2,2) 0.8393536418952174\n",
            "TF ngram(2,3) 0.8395563782718626\n",
            "TF ngram(3,3) 0.5747816408564258\n",
            "\n",
            "Naive Bayes Complement - TF ngram(1,3) - F1 Score: 87.48%\n",
            "Wall time: 1.4 s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "# modelo Naive Bayes Complement\n",
        "modelo = ComplementNB()\n",
        "# calculo com todos os vetores.\n",
        "f1score = testar_modelo(modelo, df_treino, df_teste, vetores, 'sentimento')\n",
        "\n",
        "print()\n",
        "print(f\"Naive Bayes Complement - {f1score[0]} - F1 Score: {round(f1score[1]*100,2)}%\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CV ngram(1,1) 0.8540793419186162\n",
            "CV ngram(1,2) 0.8710538417137474\n",
            "CV ngram(1,3) 0.871723063743025\n",
            "CV ngram(2,2) 0.8400257852209359\n",
            "CV ngram(2,3) 0.8395563782718626\n",
            "CV ngram(3,3) 0.5726916420207792\n",
            "TF ngram(1,1) 0.8613950353813321\n",
            "TF ngram(1,2) 0.8747465261210724\n",
            "TF ngram(1,3) 0.8746261871797448\n",
            "TF ngram(2,2) 0.839021536888149\n",
            "TF ngram(2,3) 0.8397859898224573\n",
            "TF ngram(3,3) 0.5748707653722428\n",
            "\n",
            "Naive Bayes Multinomial - TF ngram(1,2) - F1 Score: 87.47%\n",
            "Wall time: 1.48 s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "# modelo Naive Bayes Multinomial\n",
        "modelo = MultinomialNB()\n",
        "# calculo com todos os vetores.\n",
        "f1score = testar_modelo(modelo, df_treino, df_teste, vetores, 'sentimento')\n",
        "\n",
        "print()\n",
        "print(f\"Naive Bayes Multinomial - {f1score[0]} - F1 Score: {round(f1score[1]*100,2)}%\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\hgf77\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
            "CV ngram(1,1) 0.8427503134500534\n",
            "C:\\Users\\hgf77\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
            "CV ngram(1,2) 0.8593696786901172\n",
            "C:\\Users\\hgf77\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
            "CV ngram(1,3) 0.8592543708124906\n",
            "CV ngram(2,2) 0.7835525602249629\n",
            "CV ngram(2,3) 0.7817598993091702\n",
            "CV ngram(3,3) 0.5928683562102969\n",
            "TF ngram(1,1) 0.8785747941960814\n",
            "TF ngram(1,2) 0.8899243167399011\n",
            "TF ngram(1,3) 0.8908224226768418\n",
            "TF ngram(2,2) 0.8137665791374764\n",
            "TF ngram(2,3) 0.8117400847029504\n",
            "TF ngram(3,3) 0.595624170891155\n",
            "\n",
            "SVM Linear - TF ngram(1,3) - F1 Score: 89.08%\n",
            "Wall time: 35.2 s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "# modelo Linear SVM\n",
        "modelo = LinearSVC(random_state=42, max_iter=2000)\n",
        "# calculo com todos os vetores.\n",
        "f1score = testar_modelo(modelo, df_treino, df_teste, vetores, 'sentimento')\n",
        "\n",
        "print()\n",
        "print(f\"SVM Linear - {f1score[0]} - F1 Score: {round(f1score[1]*100,2)}%\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Testando os modelos com a base stematizada sem stopwords"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 94,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Wall time: 4min 35s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "# criando os vetores para Unigramas, Bigramas, Trigramas com CountVectorizer e TfidfVectorizer\n",
        "vetores = criar_vetores(df_treino, df_teste, 'stem')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## apenas modelos com mais de 85% no passo anterior e tempo inferior a 5 minutos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 95,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\hgf77\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\"The max_iter was reached which means \"\n",
            "CV ngram(1,1) 0.8706031610913865\n",
            "C:\\Users\\hgf77\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\"The max_iter was reached which means \"\n",
            "CV ngram(1,2) 0.8840837095164026\n",
            "C:\\Users\\hgf77\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\"The max_iter was reached which means \"\n",
            "CV ngram(1,3) 0.8848676248811861\n",
            "CV ngram(2,2) 0.8376838758268568\n",
            "CV ngram(2,3) 0.8376805377601975\n",
            "CV ngram(3,3) 0.7150445510051537\n",
            "TF ngram(1,1) 0.8225359724241443\n",
            "TF ngram(1,2) 0.8231228787398793\n",
            "TF ngram(1,3) 0.8235723758714172\n",
            "TF ngram(2,2) 0.6149723776050718\n",
            "TF ngram(2,3) 0.6150512107052606\n",
            "TF ngram(3,3) 0.3748284219463762\n",
            "\n",
            "Regressão Logística - CV ngram(1,3) - F1 Score: 88.49%\n",
            "Wall time: 3min 53s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "# modelo Regressão Logística\n",
        "modelo = LogisticRegression(solver='saga', max_iter=1000, random_state=42, n_jobs=-1)\n",
        "# calculo com todos os vetores.\n",
        "f1score = testar_modelo(modelo, df_treino, df_teste, vetores, 'sentimento')\n",
        "\n",
        "print()\n",
        "print(f\"Regressão Logística - {f1score[0]} - F1 Score: {round(f1score[1]*100,2)}%\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 96,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CV ngram(1,1) 0.8447715624515739\n",
            "CV ngram(1,2) 0.8720642271552428\n",
            "CV ngram(1,3) 0.8737499306282133\n",
            "CV ngram(2,2) 0.8154524423713615\n",
            "CV ngram(2,3) 0.8211824042196831\n",
            "CV ngram(3,3) 0.670711521878216\n",
            "TF ngram(1,1) 0.7824273705555479\n",
            "TF ngram(1,2) 0.7946762938640037\n",
            "TF ngram(1,3) 0.7944521435751063\n",
            "TF ngram(2,2) 0.594318686498427\n",
            "TF ngram(2,3) 0.5929128015931685\n",
            "TF ngram(3,3) 0.35665806113545495\n",
            "\n",
            "Passive Agressive - CV ngram(1,3) - F1 Score: 87.37%\n",
            "Wall time: 4.73 s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "# modelo Passive Agressive\n",
        "modelo = PassiveAggressiveClassifier(random_state=42, n_jobs=-1)\n",
        "# calculo com todos os vetores.\n",
        "f1score = testar_modelo(modelo, df_treino, df_teste, vetores, 'sentimento')\n",
        "\n",
        "print()\n",
        "print(f\"Passive Agressive - {f1score[0]} - F1 Score: {round(f1score[1]*100,2)}%\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 97,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CV ngram(1,1) 0.7800723288078767\n",
            "CV ngram(1,2) 0.7776023312377306\n",
            "CV ngram(1,3) 0.7891719816823664\n",
            "CV ngram(2,2) 0.7305320606980007\n",
            "CV ngram(2,3) 0.7366007736035252\n",
            "CV ngram(3,3) 0.6931774787857015\n",
            "TF ngram(1,1) 0.8310286072770471\n",
            "TF ngram(1,2) 0.8360933383775296\n",
            "TF ngram(1,3) 0.8357547960627466\n",
            "TF ngram(2,2) 0.610473749539492\n",
            "TF ngram(2,3) 0.6107622720271955\n",
            "TF ngram(3,3) 0.3740804219182571\n",
            "\n",
            "Ridge - TF ngram(1,2) - F1 Score: 83.61%\n",
            "Wall time: 39.1 s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "# modelo Ridge\n",
        "modelo = RidgeClassifier(solver='sparse_cg', random_state=42)\n",
        "# calculo com todos os vetores.\n",
        "f1score = testar_modelo(modelo, df_treino, df_teste, vetores, 'sentimento')\n",
        "\n",
        "print()\n",
        "print(f\"Ridge - {f1score[0]} - F1 Score: {round(f1score[1]*100,2)}%\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 98,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CV ngram(1,1) 0.8593501815753932\n",
            "CV ngram(1,2) 0.8739129241828761\n",
            "CV ngram(1,3) 0.8732718898722627\n",
            "CV ngram(2,2) 0.816242022298419\n",
            "CV ngram(2,3) 0.8228637616258457\n",
            "CV ngram(3,3) 0.7094704488293562\n",
            "TF ngram(1,1) 0.8164689388996369\n",
            "TF ngram(1,2) 0.819060757664068\n",
            "TF ngram(1,3) 0.8184998012692756\n",
            "TF ngram(2,2) 0.612289585227973\n",
            "TF ngram(2,3) 0.6125923903751722\n",
            "TF ngram(3,3) 0.373464245097864\n",
            "\n",
            "SGD - CV ngram(1,2) - F1 Score: 87.39%\n",
            "Wall time: 3 s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "# modelo SGD\n",
        "modelo = SGDClassifier(random_state=42, n_jobs=-1)\n",
        "# calculo com todos os vetores.\n",
        "f1score = testar_modelo(modelo, df_treino, df_teste, vetores, 'sentimento')\n",
        "\n",
        "print()\n",
        "print(f\"SGD - {f1score[0]} - F1 Score: {round(f1score[1]*100,2)}%\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 99,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CV ngram(1,1) 0.853279813727806\n",
            "CV ngram(1,2) 0.8726032412689158\n",
            "CV ngram(1,3) 0.8748100562187059\n",
            "CV ngram(2,2) 0.8460315157127096\n",
            "CV ngram(2,3) 0.8445608675521092\n",
            "CV ngram(3,3) 0.7242011371467321\n",
            "TF ngram(1,1) 0.8198725818996544\n",
            "TF ngram(1,2) 0.8152285233285822\n",
            "TF ngram(1,3) 0.8152326385312899\n",
            "TF ngram(2,2) 0.6169621086941445\n",
            "TF ngram(2,3) 0.6161082603679379\n",
            "TF ngram(3,3) 0.37557593287108426\n",
            "\n",
            "Naive Bayes Bernoulli - CV ngram(1,3) - F1 Score: 87.48%\n",
            "Wall time: 1.52 s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "# modelo Naive Bayes Bernoulli\n",
        "modelo = BernoulliNB()\n",
        "# calculo com todos os vetores.\n",
        "f1score = testar_modelo(modelo, df_treino, df_teste, vetores, 'sentimento')\n",
        "\n",
        "print()\n",
        "print(f\"Naive Bayes Bernoulli - {f1score[0]} - F1 Score: {round(f1score[1]*100,2)}%\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 100,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CV ngram(1,1) 0.8475371319702153\n",
            "CV ngram(1,2) 0.8686958159758584\n",
            "CV ngram(1,3) 0.8714971557859723\n",
            "CV ngram(2,2) 0.8591156073972187\n",
            "CV ngram(2,3) 0.8594120043129988\n",
            "CV ngram(3,3) 0.7150760022360954\n",
            "TF ngram(1,1) 0.8136591938472498\n",
            "TF ngram(1,2) 0.8143208959389149\n",
            "TF ngram(1,3) 0.8145369026247485\n",
            "TF ngram(2,2) 0.618029123817186\n",
            "TF ngram(2,3) 0.6168547481595895\n",
            "TF ngram(3,3) 0.37369042341230274\n",
            "\n",
            "Naive Bayes Complement - CV ngram(1,3) - F1 Score: 87.15%\n",
            "Wall time: 1.35 s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "# modelo Naive Bayes Complement\n",
        "modelo = ComplementNB()\n",
        "# calculo com todos os vetores.\n",
        "f1score = testar_modelo(modelo, df_treino, df_teste, vetores, 'sentimento')\n",
        "\n",
        "print()\n",
        "print(f\"Naive Bayes Complement - {f1score[0]} - F1 Score: {round(f1score[1]*100,2)}%\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 101,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CV ngram(1,1) 0.8473112660817483\n",
            "CV ngram(1,2) 0.868583560494826\n",
            "CV ngram(1,3) 0.8714971557859723\n",
            "CV ngram(2,2) 0.8590047111285145\n",
            "CV ngram(2,3) 0.8595265442310434\n",
            "CV ngram(3,3) 0.715056211064448\n",
            "TF ngram(1,1) 0.8130790345962262\n",
            "TF ngram(1,2) 0.8137398018967721\n",
            "TF ngram(1,3) 0.8138439492218046\n",
            "TF ngram(2,2) 0.6180576030656999\n",
            "TF ngram(2,3) 0.617623906023027\n",
            "TF ngram(3,3) 0.37369042341230274\n",
            "\n",
            "Naive Bayes Multinomial - CV ngram(1,3) - F1 Score: 87.15%\n",
            "Wall time: 1.33 s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "# modelo Naive Bayes Multinomial\n",
        "modelo = MultinomialNB()\n",
        "# calculo com todos os vetores.\n",
        "f1score = testar_modelo(modelo, df_treino, df_teste, vetores, 'sentimento')\n",
        "\n",
        "print()\n",
        "print(f\"Naive Bayes Multinomial - {f1score[0]} - F1 Score: {round(f1score[1]*100,2)}%\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 102,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\hgf77\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
            "CV ngram(1,1) 0.8427503015472957\n",
            "C:\\Users\\hgf77\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
            "CV ngram(1,2) 0.8681338243394326\n",
            "C:\\Users\\hgf77\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
            "CV ngram(1,3) 0.8676849865494912\n",
            "CV ngram(2,2) 0.8082677036133574\n",
            "CV ngram(2,3) 0.8142200102456199\n",
            "CV ngram(3,3) 0.7003582313157055\n",
            "TF ngram(1,1) 0.8324071297488379\n",
            "TF ngram(1,2) 0.8368966062975588\n",
            "TF ngram(1,3) 0.8364479335806516\n",
            "TF ngram(2,2) 0.611141878648815\n",
            "TF ngram(2,3) 0.6095122075614553\n",
            "TF ngram(3,3) 0.37385064541276897\n",
            "\n",
            "SVM Linear - CV ngram(1,2) - F1 Score: 86.81%\n",
            "Wall time: 48.4 s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "# modelo Linear SVM\n",
        "modelo = LinearSVC(random_state=42, max_iter=2000)\n",
        "# calculo com todos os vetores.\n",
        "f1score = testar_modelo(modelo, df_treino, df_teste, vetores, 'sentimento')\n",
        "\n",
        "print()\n",
        "print(f\"SVM Linear - {f1score[0]} - F1 Score: {round(f1score[1]*100,2)}%\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Testando os modelos com a base lematizada sem stopwords"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Wall time: 4min 27s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "# criando os vetores para Unigramas, Bigramas, Trigramas com CountVectorizer e TfidfVectorizer\n",
        "vetores = criar_vetores(df_treino, df_teste, 'lemm')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## continuamos com os mesmos modelos da Stematização"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\hgf77\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\"The max_iter was reached which means \"\n",
            "CV ngram(1,1) 0.871388712672154\n",
            "C:\\Users\\hgf77\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\"The max_iter was reached which means \"\n",
            "CV ngram(1,2) 0.8831840902003822\n",
            "C:\\Users\\hgf77\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\"The max_iter was reached which means \"\n",
            "CV ngram(1,3) 0.8838571020911938\n",
            "CV ngram(2,2) 0.8256702193560315\n",
            "CV ngram(2,3) 0.8261200186940448\n",
            "CV ngram(3,3) 0.6730479197760227\n",
            "TF ngram(1,1) 0.8775423544457769\n",
            "TF ngram(1,2) 0.8792318425480409\n",
            "TF ngram(1,3) 0.8786705037223337\n",
            "TF ngram(2,2) 0.740324177033005\n",
            "TF ngram(2,3) 0.7393240632537916\n",
            "TF ngram(3,3) 0.43368442556992287\n",
            "\n",
            "Regressão Logística - CV ngram(1,3) - F1 Score: 88.39%\n",
            "Wall time: 3min 21s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "# modelo Regressão Logística\n",
        "modelo = LogisticRegression(solver='saga', max_iter=1000, random_state=42, n_jobs=-1)\n",
        "# calculo com todos os vetores.\n",
        "f1score = testar_modelo(modelo, df_treino, df_teste, vetores, 'sentimento')\n",
        "\n",
        "print()\n",
        "print(f\"Regressão Logística - {f1score[0]} - F1 Score: {round(f1score[1]*100,2)}%\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CV ngram(1,1) 0.8408389855380523\n",
            "CV ngram(1,2) 0.8666747300463125\n",
            "CV ngram(1,3) 0.8664500539380493\n",
            "CV ngram(2,2) 0.8026515935821301\n",
            "CV ngram(2,3) 0.8045589586950525\n",
            "CV ngram(3,3) 0.6414821974069701\n",
            "TF ngram(1,1) 0.8362152276889182\n",
            "TF ngram(1,2) 0.8453316405746953\n",
            "TF ngram(1,3) 0.8440970821790377\n",
            "TF ngram(2,2) 0.7042333934504862\n",
            "TF ngram(2,3) 0.7034864100161662\n",
            "TF ngram(3,3) 0.426228830088564\n",
            "\n",
            "Passive Agressive - CV ngram(1,2) - F1 Score: 86.67%\n",
            "Wall time: 4.95 s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "# modelo Passive Agressive\n",
        "modelo = PassiveAggressiveClassifier(random_state=42, n_jobs=-1)\n",
        "# calculo com todos os vetores.\n",
        "f1score = testar_modelo(modelo, df_treino, df_teste, vetores, 'sentimento')\n",
        "\n",
        "print()\n",
        "print(f\"Passive Agressive - {f1score[0]} - F1 Score: {round(f1score[1]*100,2)}%\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CV ngram(1,1) 0.7930718870256565\n",
            "CV ngram(1,2) 0.7563640573646133\n",
            "CV ngram(1,3) 0.7627614477664536\n",
            "CV ngram(2,2) 0.7099646734239303\n",
            "CV ngram(2,3) 0.7109814167922218\n",
            "CV ngram(3,3) 0.6578369862851161\n",
            "TF ngram(1,1) 0.8750777970541831\n",
            "TF ngram(1,2) 0.8778925056788156\n",
            "TF ngram(1,3) 0.8777810502291562\n",
            "TF ngram(2,2) 0.7345770756710226\n",
            "TF ngram(2,3) 0.734707728277097\n",
            "TF ngram(3,3) 0.4339715409253568\n",
            "\n",
            "Ridge - TF ngram(1,2) - F1 Score: 87.79%\n",
            "Wall time: 44.3 s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "# modelo Ridge\n",
        "modelo = RidgeClassifier(solver='sparse_cg', random_state=42)\n",
        "# calculo com todos os vetores.\n",
        "f1score = testar_modelo(modelo, df_treino, df_teste, vetores, 'sentimento')\n",
        "\n",
        "print()\n",
        "print(f\"Ridge - {f1score[0]} - F1 Score: {round(f1score[1]*100,2)}%\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CV ngram(1,1) 0.8623617960213429\n",
            "CV ngram(1,2) 0.871497372620912\n",
            "CV ngram(1,3) 0.870374314193577\n",
            "CV ngram(2,2) 0.8077055153414473\n",
            "CV ngram(2,3) 0.8072390361561478\n",
            "CV ngram(3,3) 0.6664971386701526\n",
            "TF ngram(1,1) 0.8739266227935694\n",
            "TF ngram(1,2) 0.877184658287689\n",
            "TF ngram(1,3) 0.8775265394726719\n",
            "TF ngram(2,2) 0.7332294758492905\n",
            "TF ngram(2,3) 0.7321043365656521\n",
            "TF ngram(3,3) 0.43024935042331097\n",
            "\n",
            "SGD - TF ngram(1,3) - F1 Score: 87.75%\n",
            "Wall time: 4.09 s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "# modelo SGD\n",
        "modelo = SGDClassifier(random_state=42, n_jobs=-1)\n",
        "# calculo com todos os vetores.\n",
        "f1score = testar_modelo(modelo, df_treino, df_teste, vetores, 'sentimento')\n",
        "\n",
        "print()\n",
        "print(f\"SGD - {f1score[0]} - F1 Score: {round(f1score[1]*100,2)}%\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CV ngram(1,1) 0.8447624849630707\n",
            "CV ngram(1,2) 0.8679099133392059\n",
            "CV ngram(1,3) 0.8676851100781984\n",
            "CV ngram(2,2) 0.8486296058287263\n",
            "CV ngram(2,3) 0.8444070061166389\n",
            "CV ngram(3,3) 0.6779522151235321\n",
            "TF ngram(1,1) 0.8388849014361389\n",
            "TF ngram(1,2) 0.8432095299986397\n",
            "TF ngram(1,3) 0.8432077205217546\n",
            "TF ngram(2,2) 0.7449479689390794\n",
            "TF ngram(2,3) 0.7437976162984026\n",
            "TF ngram(3,3) 0.4342236652287708\n",
            "\n",
            "Naive Bayes Bernoulli - CV ngram(1,2) - F1 Score: 86.79%\n",
            "Wall time: 2.09 s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "# modelo Naive Bayes Bernoulli\n",
        "modelo = BernoulliNB()\n",
        "# calculo com todos os vetores.\n",
        "f1score = testar_modelo(modelo, df_treino, df_teste, vetores, 'sentimento')\n",
        "\n",
        "print()\n",
        "print(f\"Naive Bayes Bernoulli - {f1score[0]} - F1 Score: {round(f1score[1]*100,2)}%\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CV ngram(1,1) 0.8501206808852098\n",
            "CV ngram(1,2) 0.8644278954564537\n",
            "CV ngram(1,3) 0.8655506597041437\n",
            "CV ngram(2,2) 0.849586365803061\n",
            "CV ngram(2,3) 0.8468772105981207\n",
            "CV ngram(3,3) 0.6716025539832963\n",
            "TF ngram(1,1) 0.850040407437503\n",
            "TF ngram(1,2) 0.8542037543227335\n",
            "TF ngram(1,3) 0.8535288027251701\n",
            "TF ngram(2,2) 0.7456897381922211\n",
            "TF ngram(2,3) 0.7438856610224384\n",
            "TF ngram(3,3) 0.43283308739509896\n",
            "\n",
            "Naive Bayes Complement - CV ngram(1,3) - F1 Score: 86.56%\n",
            "Wall time: 2 s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "# modelo Naive Bayes Complement\n",
        "modelo = ComplementNB()\n",
        "# calculo com todos os vetores.\n",
        "f1score = testar_modelo(modelo, df_treino, df_teste, vetores, 'sentimento')\n",
        "\n",
        "print()\n",
        "print(f\"Naive Bayes Complement - {f1score[0]} - F1 Score: {round(f1score[1]*100,2)}%\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CV ngram(1,1) 0.8501206808852098\n",
            "CV ngram(1,2) 0.8644278954564537\n",
            "CV ngram(1,3) 0.8655506597041437\n",
            "CV ngram(2,2) 0.849586365803061\n",
            "CV ngram(2,3) 0.8471028331266741\n",
            "CV ngram(3,3) 0.671337498542541\n",
            "TF ngram(1,1) 0.8502613703817574\n",
            "TF ngram(1,2) 0.8540894865264704\n",
            "TF ngram(1,3) 0.8536393655701684\n",
            "TF ngram(2,2) 0.745793668857829\n",
            "TF ngram(2,3) 0.7442139392415841\n",
            "TF ngram(3,3) 0.43283308739509896\n",
            "\n",
            "Naive Bayes Multinomial - CV ngram(1,3) - F1 Score: 86.56%\n",
            "Wall time: 1.92 s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "# modelo Naive Bayes Multinomial\n",
        "modelo = MultinomialNB()\n",
        "# calculo com todos os vetores.\n",
        "f1score = testar_modelo(modelo, df_treino, df_teste, vetores, 'sentimento')\n",
        "\n",
        "print()\n",
        "print(f\"Naive Bayes Multinomial - {f1score[0]} - F1 Score: {round(f1score[1]*100,2)}%\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\hgf77\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
            "CV ngram(1,1) 0.8398293437788718\n",
            "C:\\Users\\hgf77\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
            "CV ngram(1,2) 0.864315334254487\n",
            "C:\\Users\\hgf77\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
            "CV ngram(1,3) 0.8658884105520414\n",
            "CV ngram(2,2) 0.7960214498114365\n",
            "CV ngram(2,3) 0.7998407799606694\n",
            "CV ngram(3,3) 0.6615620550736362\n",
            "TF ngram(1,1) 0.8770001249107156\n",
            "TF ngram(1,2) 0.8786852751069337\n",
            "TF ngram(1,3) 0.8786869280902067\n",
            "TF ngram(2,2) 0.7345770756710226\n",
            "TF ngram(2,3) 0.7340139395308587\n",
            "TF ngram(3,3) 0.43389987405354263\n",
            "\n",
            "SVM Linear - TF ngram(1,3) - F1 Score: 87.87%\n",
            "Wall time: 49.5 s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "# modelo Linear SVM\n",
        "modelo = LinearSVC(random_state=42, max_iter=2000)\n",
        "# calculo com todos os vetores.\n",
        "f1score = testar_modelo(modelo, df_treino, df_teste, vetores, 'sentimento')\n",
        "\n",
        "print()\n",
        "print(f\"SVM Linear - {f1score[0]} - F1 Score: {round(f1score[1]*100,2)}%\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Testando os modelos com a base Pré Processada"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Wall time: 3min 35s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "# criando os vetores para Unigramas, Bigramas, Trigramas com CountVectorizer e TfidfVectorizer\n",
        "vetores = criar_vetores(df_treino, df_teste, 'pre')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Vamos testar apenas os 5 melhores modelos até agora"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\hgf77\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\"The max_iter was reached which means \"\n",
            "CV ngram(1,1) 0.8710502464216818\n",
            "C:\\Users\\hgf77\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\"The max_iter was reached which means \"\n",
            "CV ngram(1,2) 0.8774559330914977\n",
            "C:\\Users\\hgf77\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\"The max_iter was reached which means \"\n",
            "CV ngram(1,3) 0.8776816803324722\n",
            "CV ngram(2,2) 0.8173581035263575\n",
            "CV ngram(2,3) 0.8176989129450517\n",
            "CV ngram(3,3) 0.5823323573969434\n",
            "TF ngram(1,1) 0.8793422820203212\n",
            "TF ngram(1,2) 0.8814828731267541\n",
            "TF ngram(1,3) 0.8822675641302015\n",
            "TF ngram(2,2) 0.8192275645635757\n",
            "TF ngram(2,3) 0.8203536567381056\n",
            "TF ngram(3,3) 0.550074551964366\n",
            "\n",
            "Regressão Logística - TF ngram(1,3) - F1 Score: 88.23%\n",
            "Wall time: 2min 58s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "# modelo Regressão Logística\n",
        "modelo = LogisticRegression(solver='saga', max_iter=1000, random_state=42, n_jobs=-1)\n",
        "# calculo com todos os vetores.\n",
        "f1score = testar_modelo(modelo, df_treino, df_teste, vetores, 'sentimento')\n",
        "\n",
        "print()\n",
        "print(f\"Regressão Logística - {f1score[0]} - F1 Score: {round(f1score[1]*100,2)}%\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CV ngram(1,1) 0.8566230581640968\n",
            "CV ngram(1,2) 0.872402934409747\n",
            "CV ngram(1,3) 0.8731882368059104\n",
            "CV ngram(2,2) 0.8376724046397828\n",
            "CV ngram(2,3) 0.8341166119244173\n",
            "CV ngram(3,3) 0.5800057220981744\n",
            "TF ngram(1,1) 0.8548384097609529\n",
            "TF ngram(1,2) 0.8703811139394094\n",
            "TF ngram(1,3) 0.8707165710250357\n",
            "TF ngram(2,2) 0.8315366363425195\n",
            "TF ngram(2,3) 0.8285702947618924\n",
            "TF ngram(3,3) 0.5490119257158181\n",
            "\n",
            "Naive Bayes Bernoulli - CV ngram(1,3) - F1 Score: 87.32%\n",
            "Wall time: 1.53 s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "# modelo Naive Bayes Bernoulli\n",
        "modelo = BernoulliNB()\n",
        "# calculo com todos os vetores.\n",
        "f1score = testar_modelo(modelo, df_treino, df_teste, vetores, 'sentimento')\n",
        "\n",
        "print()\n",
        "print(f\"Naive Bayes Bernoulli - {f1score[0]} - F1 Score: {round(f1score[1]*100,2)}%\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CV ngram(1,1) 0.8549689146984613\n",
            "CV ngram(1,2) 0.871279720804199\n",
            "CV ngram(1,3) 0.8706058252865331\n",
            "CV ngram(2,2) 0.8393629612386887\n",
            "CV ngram(2,3) 0.8381114215778313\n",
            "CV ngram(3,3) 0.5669038489313839\n",
            "TF ngram(1,1) 0.8572385781259917\n",
            "TF ngram(1,2) 0.8692540765131808\n",
            "TF ngram(1,3) 0.8693631510801997\n",
            "TF ngram(2,2) 0.830718784892549\n",
            "TF ngram(2,3) 0.8289155312346619\n",
            "TF ngram(3,3) 0.5304598351357982\n",
            "\n",
            "Naive Bayes Multinomial - CV ngram(1,2) - F1 Score: 87.13%\n",
            "Wall time: 1.32 s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "# modelo Naive Bayes Multinomial\n",
        "modelo = MultinomialNB()\n",
        "# calculo com todos os vetores.\n",
        "f1score = testar_modelo(modelo, df_treino, df_teste, vetores, 'sentimento')\n",
        "\n",
        "print()\n",
        "print(f\"Naive Bayes Multinomial - {f1score[0]} - F1 Score: {round(f1score[1]*100,2)}%\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\hgf77\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
            "CV ngram(1,1) 0.8385940582663615\n",
            "C:\\Users\\hgf77\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
            "CV ngram(1,2) 0.8606092865148899\n",
            "C:\\Users\\hgf77\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
            "CV ngram(1,3) 0.8588115688380807\n",
            "CV ngram(2,2) 0.7843429278714612\n",
            "CV ngram(2,3) 0.7837810263079318\n",
            "CV ngram(3,3) 0.5809716450216716\n",
            "TF ngram(1,1) 0.8727269249102824\n",
            "TF ngram(1,2) 0.8821718424393796\n",
            "TF ngram(1,3) 0.8825077776359189\n",
            "TF ngram(2,2) 0.8074796189613431\n",
            "TF ngram(2,3) 0.8052325935407856\n",
            "TF ngram(3,3) 0.5491340454518127\n",
            "\n",
            "SVM Linear - TF ngram(1,3) - F1 Score: 88.25%\n",
            "Wall time: 34.1 s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "# modelo Linear SVM\n",
        "modelo = LinearSVC(random_state=42, max_iter=2000)\n",
        "# calculo com todos os vetores.\n",
        "f1score = testar_modelo(modelo, df_treino, df_teste, vetores, 'sentimento')\n",
        "\n",
        "print()\n",
        "print(f\"SVM Linear - {f1score[0]} - F1 Score: {round(f1score[1]*100,2)}%\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CV ngram(1,1) 0.869804742882215\n",
            "CV ngram(1,2) 0.8773451980664928\n",
            "CV ngram(1,3) 0.8731893407202223\n",
            "CV ngram(2,2) 0.7833276888688427\n",
            "CV ngram(2,3) 0.7818720223766333\n",
            "CV ngram(3,3) 0.5791479442966332\n",
            "TF ngram(1,1) 0.8688068632711418\n",
            "TF ngram(1,2) 0.8736381569092341\n",
            "TF ngram(1,3) 0.869255920598093\n",
            "TF ngram(2,2) 0.7914191755566119\n",
            "TF ngram(2,3) 0.7888359433924155\n",
            "TF ngram(3,3) 0.5482169793053899\n",
            "\n",
            "Extra Trees Regressor - CV ngram(1,2) - F1 Score: 87.73%\n",
            "Wall time: 11min 53s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "# modelo Extra Trees Regressor\n",
        "modelo = ExtraTreesClassifier(n_estimators=10, random_state=42, n_jobs=-1)\n",
        "# calculo com todos os vetores.\n",
        "f1score = testar_modelo(modelo, df_treino, df_teste, vetores, 'sentimento')\n",
        "\n",
        "print()\n",
        "print(f\"Extra Trees Regressor - {f1score[0]} - F1 Score: {round(f1score[1]*100,2)}%\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Testando os modelos com a base Lemmatizando apenas os verbos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Wall time: 4min 15s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "# criando os vetores para Unigramas, Bigramas, Trigramas com CountVectorizer e TfidfVectorizer\n",
        "vetores = criar_vetores(df_treino, df_teste, 'verb')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\hgf77\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\"The max_iter was reached which means \"\n",
            "CV ngram(1,1) 0.870153296431196\n",
            "C:\\Users\\hgf77\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\"The max_iter was reached which means \"\n",
            "CV ngram(1,2) 0.8807144201214318\n",
            "C:\\Users\\hgf77\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\"The max_iter was reached which means \"\n",
            "CV ngram(1,3) 0.8803775065185797\n",
            "CV ngram(2,2) 0.8181405669162283\n",
            "CV ngram(2,3) 0.816677177326182\n",
            "CV ngram(3,3) 0.6083813643871504\n",
            "TF ngram(1,1) 0.8815791618433787\n",
            "TF ngram(1,2) 0.8833923011577803\n",
            "TF ngram(1,3) 0.8840656758535709\n",
            "TF ngram(2,2) 0.8156931177451451\n",
            "TF ngram(2,3) 0.8168244677751976\n",
            "TF ngram(3,3) 0.5535472807839507\n",
            "\n",
            "Regressão Logística - TF ngram(1,3) - F1 Score: 88.41%\n",
            "Wall time: 2min 55s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "# modelo Regressão Logística\n",
        "modelo = LogisticRegression(solver='saga', max_iter=1000, random_state=42, n_jobs=-1)\n",
        "# calculo com todos os vetores.\n",
        "f1score = testar_modelo(modelo, df_treino, df_teste, vetores, 'sentimento')\n",
        "\n",
        "print()\n",
        "print(f\"Regressão Logística - {f1score[0]} - F1 Score: {round(f1score[1]*100,2)}%\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CV ngram(1,1) 0.8523465209719742\n",
            "CV ngram(1,2) 0.8693658968702689\n",
            "CV ngram(1,3) 0.8708181374622521\n",
            "CV ngram(2,2) 0.8382154163101594\n",
            "CV ngram(2,3) 0.8343883584984358\n",
            "CV ngram(3,3) 0.6104436506306223\n",
            "TF ngram(1,1) 0.8491853644511781\n",
            "TF ngram(1,2) 0.8643153993036056\n",
            "TF ngram(1,3) 0.8661130294291304\n",
            "TF ngram(2,2) 0.8245641873793927\n",
            "TF ngram(2,3) 0.823035042943178\n",
            "TF ngram(3,3) 0.5549469693311997\n",
            "\n",
            "Naive Bayes Bernoulli - CV ngram(1,3) - F1 Score: 87.08%\n",
            "Wall time: 1.53 s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "# modelo Naive Bayes Bernoulli\n",
        "modelo = BernoulliNB()\n",
        "# calculo com todos os vetores.\n",
        "f1score = testar_modelo(modelo, df_treino, df_teste, vetores, 'sentimento')\n",
        "\n",
        "print()\n",
        "print(f\"Naive Bayes Bernoulli - {f1score[0]} - F1 Score: {round(f1score[1]*100,2)}%\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CV ngram(1,1) 0.8547519694104435\n",
            "CV ngram(1,2) 0.8674575171183488\n",
            "CV ngram(1,3) 0.8691380503682982\n",
            "CV ngram(2,2) 0.8393507595582753\n",
            "CV ngram(2,3) 0.83808436444916\n",
            "CV ngram(3,3) 0.5821947914866082\n",
            "TF ngram(1,1) 0.8562226506034619\n",
            "TF ngram(1,2) 0.8685807584987018\n",
            "TF ngram(1,3) 0.8675690392878072\n",
            "TF ngram(2,2) 0.8261059209984754\n",
            "TF ngram(2,3) 0.8217167619124149\n",
            "TF ngram(3,3) 0.5321065959946548\n",
            "\n",
            "Naive Bayes Multinomial - CV ngram(1,3) - F1 Score: 86.91%\n",
            "Wall time: 1.33 s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "# modelo Naive Bayes Multinomial\n",
        "modelo = MultinomialNB()\n",
        "# calculo com todos os vetores.\n",
        "f1score = testar_modelo(modelo, df_treino, df_teste, vetores, 'sentimento')\n",
        "\n",
        "print()\n",
        "print(f\"Naive Bayes Multinomial - {f1score[0]} - F1 Score: {round(f1score[1]*100,2)}%\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\hgf77\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
            "CV ngram(1,1) 0.8410647334175689\n",
            "C:\\Users\\hgf77\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
            "CV ngram(1,2) 0.860609381477054\n",
            "C:\\Users\\hgf77\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
            "CV ngram(1,3) 0.8612832597208612\n",
            "CV ngram(2,2) 0.7828827497851002\n",
            "CV ngram(2,3) 0.7850171328747871\n",
            "CV ngram(3,3) 0.6063563428006253\n",
            "TF ngram(1,1) 0.8798012987840483\n",
            "TF ngram(1,2) 0.884864722673612\n",
            "TF ngram(1,3) 0.8844164904569981\n",
            "TF ngram(2,2) 0.7996060470284906\n",
            "TF ngram(2,3) 0.7994979936498946\n",
            "TF ngram(3,3) 0.5540617172968947\n",
            "\n",
            "SVM Linear - TF ngram(1,2) - F1 Score: 88.49%\n",
            "Wall time: 35.4 s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "# modelo Linear SVM\n",
        "modelo = LinearSVC(random_state=42, max_iter=2000)\n",
        "# calculo com todos os vetores.\n",
        "f1score = testar_modelo(modelo, df_treino, df_teste, vetores, 'sentimento')\n",
        "\n",
        "print()\n",
        "print(f\"SVM Linear - {f1score[0]} - F1 Score: {round(f1score[1]*100,2)}%\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CV ngram(1,1) 0.8206323129981713\n",
            "CV ngram(1,2) 0.8358892722027663\n",
            "CV ngram(1,3) 0.8392513624566394\n",
            "CV ngram(2,2) 0.7719570506569801\n",
            "CV ngram(2,3) 0.7752217592590233\n",
            "CV ngram(3,3) 0.6005473916262247\n",
            "TF ngram(1,1) 0.8207255925203217\n",
            "TF ngram(1,2) 0.8268384099628575\n",
            "TF ngram(1,3) 0.8304706452942974\n",
            "TF ngram(2,2) 0.7744291715602897\n",
            "TF ngram(2,3) 0.7700497492243219\n",
            "TF ngram(3,3) 0.5548242496040003\n",
            "\n",
            "Extra Trees Regressor - CV ngram(1,3) - F1 Score: 83.93%\n",
            "Wall time: 1min 21s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "# modelo Extra Trees Regressor\n",
        "modelo = ExtraTreesClassifier(n_estimators=20, random_state=42, n_jobs=-1)\n",
        "# calculo com todos os vetores.\n",
        "f1score = testar_modelo(modelo, df_treino, df_teste, vetores, 'sentimento')\n",
        "\n",
        "print()\n",
        "print(f\"Extra Trees Regressor - {f1score[0]} - F1 Score: {round(f1score[1]*100,2)}%\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# MLP"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "def plot_history(history):\n",
        "    acc = history.history['accuracy']\n",
        "    val_acc = history.history['val_accuracy']\n",
        "    loss = history.history['loss']\n",
        "    val_loss = history.history['val_loss']\n",
        "    x = range(1, len(acc) + 1)\n",
        "\n",
        "    plt.figure(figsize=(12, 5))\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.plot(x, acc, 'b', label='Training acc')\n",
        "    plt.plot(x, val_acc, 'r', label='Validation acc')\n",
        "    plt.title('Training and validation accuracy')\n",
        "    plt.legend()\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.plot(x, loss, 'b', label='Training loss')\n",
        "    plt.plot(x, val_loss, 'r', label='Validation loss')\n",
        "    plt.title('Training and validation loss')\n",
        "    plt.legend()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>texto</th>\n",
              "      <th>sentimento</th>\n",
              "      <th>stem</th>\n",
              "      <th>lemm</th>\n",
              "      <th>verb</th>\n",
              "      <th>pre</th>\n",
              "      <th>adj</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Esse bocejo de pia de cozinha de orçamento mui...</td>\n",
              "      <td>neg</td>\n",
              "      <td>ess bocej de pia de co de orç muit baix é o ti...</td>\n",
              "      <td>Esse bocejar de pio de cozinhar de orçamentar ...</td>\n",
              "      <td>Esse bocejo de pia de cozinha de orçamento mui...</td>\n",
              "      <td>esse bocejo pia cozinha orçamento filme feito ...</td>\n",
              "      <td>muito baixar só antar ver Provavelmente auto-f...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>O Bravo parece indicar que o personagem princi...</td>\n",
              "      <td>neg</td>\n",
              "      <td>o brav parec indic que o person principal, cla...</td>\n",
              "      <td>O Bravo parecer indicar que o personagem princ...</td>\n",
              "      <td>O Bravo parecer indicar que o personagem princ...</td>\n",
              "      <td>bravo indicar personagem principal claro coraj...</td>\n",
              "      <td>principal claro corajoso mais corajoso brutalm...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Durante a Guerra pela Independência do Sul, GE...</td>\n",
              "      <td>pos</td>\n",
              "      <td>dur a guerr pel independ do sul, gener spanky ...</td>\n",
              "      <td>Durante o Guerra pelar Independência do Sul , ...</td>\n",
              "      <td>Durante a Guerra pela Independência do Sul , G...</td>\n",
              "      <td>durante guerra independência sul general spank...</td>\n",
              "      <td>locar popular GANG ocasionar grande natural me...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>É fora de questão que a verdadeira Anna Anders...</td>\n",
              "      <td>pos</td>\n",
              "      <td>é for de quest que a verd ann anderson não era...</td>\n",
              "      <td>É ser de questão que o verdadeiro Anna Anderso...</td>\n",
              "      <td>É fora de questão que a verdadeira Anna Anders...</td>\n",
              "      <td>verdadeira anna anderson princesa anastasia al...</td>\n",
              "      <td>ser verdadeiro não Além muito distinto físico ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Concordo totalmente com outro dos revisores aq...</td>\n",
              "      <td>neg</td>\n",
              "      <td>concord total com outr do revi aqu que fic sat...</td>\n",
              "      <td>Concordo totalmente com outro dos revisor aqui...</td>\n",
              "      <td>Concordo totalmente com outro dos revisores aq...</td>\n",
              "      <td>concordo totalmente outro revisor ficou satisf...</td>\n",
              "      <td>totalmente aqui satisfazer Melhor não doente p...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                               texto sentimento  \\\n",
              "0  Esse bocejo de pia de cozinha de orçamento mui...        neg   \n",
              "1  O Bravo parece indicar que o personagem princi...        neg   \n",
              "2  Durante a Guerra pela Independência do Sul, GE...        pos   \n",
              "3  É fora de questão que a verdadeira Anna Anders...        pos   \n",
              "4  Concordo totalmente com outro dos revisores aq...        neg   \n",
              "\n",
              "                                                stem  \\\n",
              "0  ess bocej de pia de co de orç muit baix é o ti...   \n",
              "1  o brav parec indic que o person principal, cla...   \n",
              "2  dur a guerr pel independ do sul, gener spanky ...   \n",
              "3  é for de quest que a verd ann anderson não era...   \n",
              "4  concord total com outr do revi aqu que fic sat...   \n",
              "\n",
              "                                                lemm  \\\n",
              "0  Esse bocejar de pio de cozinhar de orçamentar ...   \n",
              "1  O Bravo parecer indicar que o personagem princ...   \n",
              "2  Durante o Guerra pelar Independência do Sul , ...   \n",
              "3  É ser de questão que o verdadeiro Anna Anderso...   \n",
              "4  Concordo totalmente com outro dos revisor aqui...   \n",
              "\n",
              "                                                verb  \\\n",
              "0  Esse bocejo de pia de cozinha de orçamento mui...   \n",
              "1  O Bravo parecer indicar que o personagem princ...   \n",
              "2  Durante a Guerra pela Independência do Sul , G...   \n",
              "3  É fora de questão que a verdadeira Anna Anders...   \n",
              "4  Concordo totalmente com outro dos revisores aq...   \n",
              "\n",
              "                                                 pre  \\\n",
              "0  esse bocejo pia cozinha orçamento filme feito ...   \n",
              "1  bravo indicar personagem principal claro coraj...   \n",
              "2  durante guerra independência sul general spank...   \n",
              "3  verdadeira anna anderson princesa anastasia al...   \n",
              "4  concordo totalmente outro revisor ficou satisf...   \n",
              "\n",
              "                                                 adj  \n",
              "0  muito baixar só antar ver Provavelmente auto-f...  \n",
              "1  principal claro corajoso mais corajoso brutalm...  \n",
              "2  locar popular GANG ocasionar grande natural me...  \n",
              "3  ser verdadeiro não Além muito distinto físico ...  \n",
              "4  totalmente aqui satisfazer Melhor não doente p...  "
            ]
          },
          "execution_count": 45,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>texto</th>\n",
              "      <th>pre</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Esse bocejo de pia de cozinha de orçamento mui...</td>\n",
              "      <td>esse bocejo pia cozinha orçamento filme feito ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>O Bravo parece indicar que o personagem princi...</td>\n",
              "      <td>bravo indicar personagem principal claro coraj...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Durante a Guerra pela Independência do Sul, GE...</td>\n",
              "      <td>durante guerra independência sul general spank...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>É fora de questão que a verdadeira Anna Anders...</td>\n",
              "      <td>verdadeira anna anderson princesa anastasia al...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Concordo totalmente com outro dos revisores aq...</td>\n",
              "      <td>concordo totalmente outro revisor ficou satisf...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                               texto  \\\n",
              "0  Esse bocejo de pia de cozinha de orçamento mui...   \n",
              "1  O Bravo parece indicar que o personagem princi...   \n",
              "2  Durante a Guerra pela Independência do Sul, GE...   \n",
              "3  É fora de questão que a verdadeira Anna Anders...   \n",
              "4  Concordo totalmente com outro dos revisores aq...   \n",
              "\n",
              "                                                 pre  target  \n",
              "0  esse bocejo pia cozinha orçamento filme feito ...       0  \n",
              "1  bravo indicar personagem principal claro coraj...       0  \n",
              "2  durante guerra independência sul general spank...       1  \n",
              "3  verdadeira anna anderson princesa anastasia al...       1  \n",
              "4  concordo totalmente outro revisor ficou satisf...       0  "
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_mlp = df[['texto', 'pre']].copy()\n",
        "df_mlp['target'] = [0 if x == 'neg' else 1 for x in df.sentimento]\n",
        "df_mlp.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 44514 entries, 0 to 44513\n",
            "Data columns (total 3 columns):\n",
            " #   Column  Non-Null Count  Dtype \n",
            "---  ------  --------------  ----- \n",
            " 0   texto   44514 non-null  object\n",
            " 1   pre     44514 non-null  object\n",
            " 2   target  44514 non-null  int64 \n",
            "dtypes: int64(1), object(2)\n",
            "memory usage: 1.0+ MB\n"
          ]
        }
      ],
      "source": [
        "# dividindo com 20% para o treino e random state = 42\n",
        "df_treino_mlp, df_teste_mlp = train_test_split(\n",
        "      df_mlp, \n",
        "      test_size = 0.2, \n",
        "      random_state = 42\n",
        "  )\n",
        "df_mlp.info()  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "target\n",
              "0    40.07\n",
              "1    39.93\n",
              "Name: texto, dtype: float64"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# distribuição das respostas do treino em %\n",
        "round(df_treino_mlp.groupby('target').count() / df_mlp.shape[0] * 100, 2).texto"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "target\n",
              "0    10.04\n",
              "1     9.96\n",
              "Name: texto, dtype: float64"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# distribuição das respostas do teste em %\n",
        "round(df_teste_mlp.groupby('target').count() / df_mlp.shape[0] * 100, 2).texto"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 101,
      "metadata": {},
      "outputs": [],
      "source": [
        "# vetorização em unigramas + Bigramas com CountVectorizer e sem stopwords\n",
        "vect_MLP = CountVectorizer(ngram_range=(1,1), stop_words=stops, min_df=20) \n",
        "#vect = CountVectorizer(ngram_range=(1,1), stop_words=stops) \n",
        "# utilizando a base completa sem ajustes\n",
        "vect_MLP.fit(df_treino_mlp.texto)\n",
        "X_treino = vect_MLP.transform(df_treino_mlp.texto)\n",
        "X_teste = vect_MLP.transform(df_teste_mlp.texto)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 102,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(35611, 16504)"
            ]
          },
          "execution_count": 102,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X_treino.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(35611, 1)"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y_treino = df_treino_mlp.target.values.reshape(-1,1)\n",
        "y_teste = df_teste_mlp.target.values.reshape(-1,1)\n",
        "y_treino.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {},
      "outputs": [],
      "source": [
        "tokenizer = Tokenizer(num_words=15000)\n",
        "tokenizer.fit_on_texts(df_treino_mlp.pre)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {},
      "outputs": [],
      "source": [
        "X_treino = tokenizer.texts_to_sequences(df_treino_mlp.pre)\n",
        "X_teste = tokenizer.texts_to_sequences(df_teste_mlp.pre)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "106704"
            ]
          },
          "execution_count": 41,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "vocab_size = len(tokenizer.word_index) + 1  # Adding 1 because of reserved 0 index\n",
        "vocab_size"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "durante guerra independência sul general spanky mobiliza força defender mulher criança local invasão yankee hal roach decidiu hora popular garoto our gang transformarem filme ocasional com sucesso shirley temple filme período guerra civil the little colonel the littlest rebel natural roach olhasse mesma direção gang apesar produção generosa distribuída mgm general spanky sucesso crítico bilheteria pequeno gangster passariam dedicar assunto curto embora recebido melhor faturamento papel principal george mcparland rivalizado durante metade filme pequeno billie buckwheat thoma aqui melhor ator jovem apareceram filme americano com experiência profissional experiente antigo gamin podiam roubar cena coração bravata igual uma alegria constante nota falsa ele fornecem razão essencial assistir filme hoje phillip holme apresentação tranquila cavalheiresca protetor adulto spanky quase esquecido agora holme ótimo ator morreu cedo durante segunda guerra mundial genial ralph morgan especialmente simpático general união cena spanky divertida outro nosso gangera aparecem filme notavelmente carl alfafa switzer começa warble logo batalha mãe até bela professora rosina lawrence gang aparece interpretar holme querida irving pichel particularmente viscoso cardife covarde tornou capitão vingativo yankee desvendando willie melhor atrevido louise beaver interpretam escravo mis lawrence deve-se notar racismo filme incomum hollywood época quase completamente ausente série original curta our gangfã música século xix gostar prestar atenção trilha sonora longa sucessão música antiga\n",
            "[932, 1641, 175, 73, 9435, 6500, 5814, 1065, 6, 507, 5755, 665, 3017, 67, 3, 235, 1810, 1895, 1599, 1649, 509, 1274, 177, 66, 9567, 5661, 932, 2, 150, 713, 531, 932, 66, 4103, 757, 8285, 3029, 66, 131, 4517, 253, 430, 305, 306, 170, 665, 702, 623, 124, 771, 108, 1149, 932, 1103, 1467, 932, 2483, 449, 1104, 512, 2, 238, 1425, 4623, 512, 324, 1, 105, 100, 438, 39, 623, 9041, 124, 2664, 1257, 175, 3666, 76, 417, 2792, 818, 733, 206, 277, 665, 678, 477, 272, 3782, 277, 106, 2395, 2596, 582, 5086, 3573, 2448, 755, 1759, 41, 309, 1076, 1875, 1, 2448, 6191, 3666, 93, 1927, 3597, 543, 430, 6565, 206, 3, 68, 4624, 62, 106, 2395, 139, 395, 238, 1776, 477, 105, 512, 3894, 1, 1825, 3, 647, 235, 177, 305, 1940]\n"
          ]
        }
      ],
      "source": [
        "print(df_treino_mlp.pre[2])\n",
        "print(X_treino[2])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "426"
            ]
          },
          "execution_count": 42,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "max(len(x) for x in X_treino)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {},
      "outputs": [],
      "source": [
        "maxlen = 430\n",
        "\n",
        "X_treino = pad_sequences(X_treino, padding='post', maxlen=maxlen)\n",
        "X_teste = pad_sequences(X_teste, padding='post', maxlen=maxlen)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(35611, 430)"
            ]
          },
          "execution_count": 44,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X_treino.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {},
      "outputs": [],
      "source": [
        "#Modelo da Rede MLP\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Embedding(input_dim=vocab_size, output_dim=256, input_length=maxlen))\n",
        "model.add(Dropout(0.3))\n",
        "#model.add(Conv1D(128, 5, activation='relu'))\n",
        "model.add(GlobalMaxPooling1D())\n",
        "#model.add(Flatten())\n",
        "model.add(Dense(64, activation='relu'))\n",
        "model.add(Dropout(0.3))\n",
        "model.add(Dense(32, activation='relu'))\n",
        "#model.add(Dropout(0.2))\n",
        "model.add(Dense(1, activation='sigmoid'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Layer lstm_1 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n"
          ]
        }
      ],
      "source": [
        "model = Sequential()\n",
        "model.add(Embedding(input_dim=vocab_size, output_dim=64, input_length=maxlen))\n",
        "model.add(SpatialDropout1D(0.3))\n",
        "model.add(LSTM(64, dropout=0.2, recurrent_dropout=0.2))\n",
        "#model.add(Dense(32, activation='relu'))\n",
        "model.add(Dense(1, activation='sigmoid'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {},
      "outputs": [],
      "source": [
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 301,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding (Embedding)        (None, 400, 128)          13658112  \n",
            "_________________________________________________________________\n",
            "spatial_dropout1d (SpatialDr (None, 400, 128)          0         \n",
            "_________________________________________________________________\n",
            "lstm (LSTM)                  (None, 128)               131584    \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 2)                 258       \n",
            "=================================================================\n",
            "Total params: 13,789,954\n",
            "Trainable params: 13,789,954\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ]
        }
      ],
      "source": [
        "print(model.summary())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 296,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "execution_count": 296,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "plot_model(model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "18/18 [==============================] - ETA: 0s - loss: 0.6885 - accuracy: 0.5594\n",
            "Epoch 00001: val_accuracy improved from -inf to 0.81422, saving model to .\\modelo_mlp.hdf5\n",
            "18/18 [==============================] - 15s 834ms/step - loss: 0.6885 - accuracy: 0.5594 - val_loss: 0.6809 - val_accuracy: 0.8142\n",
            "Epoch 2/20\n",
            "18/18 [==============================] - ETA: 0s - loss: 0.6517 - accuracy: 0.7627\n",
            "Epoch 00002: val_accuracy improved from 0.81422 to 0.84747, saving model to .\\modelo_mlp.hdf5\n",
            "18/18 [==============================] - 16s 863ms/step - loss: 0.6517 - accuracy: 0.7627 - val_loss: 0.6228 - val_accuracy: 0.8475\n",
            "Epoch 3/20\n",
            "18/18 [==============================] - ETA: 0s - loss: 0.5191 - accuracy: 0.8431\n",
            "Epoch 00003: val_accuracy improved from 0.84747 to 0.85870, saving model to .\\modelo_mlp.hdf5\n",
            "18/18 [==============================] - 15s 854ms/step - loss: 0.5191 - accuracy: 0.8431 - val_loss: 0.4462 - val_accuracy: 0.8587\n",
            "Epoch 4/20\n",
            "18/18 [==============================] - ETA: 0s - loss: 0.3384 - accuracy: 0.8713\n",
            "Epoch 00004: val_accuracy improved from 0.85870 to 0.86757, saving model to .\\modelo_mlp.hdf5\n",
            "18/18 [==============================] - 16s 862ms/step - loss: 0.3384 - accuracy: 0.8713 - val_loss: 0.3193 - val_accuracy: 0.8676\n",
            "Epoch 5/20\n",
            "18/18 [==============================] - ETA: 0s - loss: 0.2542 - accuracy: 0.8993\n",
            "Epoch 00005: val_accuracy improved from 0.86757 to 0.87948, saving model to .\\modelo_mlp.hdf5\n",
            "18/18 [==============================] - 15s 853ms/step - loss: 0.2542 - accuracy: 0.8993 - val_loss: 0.2885 - val_accuracy: 0.8795\n",
            "Epoch 6/20\n",
            "18/18 [==============================] - ETA: 0s - loss: 0.2032 - accuracy: 0.9239\n",
            "Epoch 00006: val_accuracy improved from 0.87948 to 0.88813, saving model to .\\modelo_mlp.hdf5\n",
            "18/18 [==============================] - 15s 852ms/step - loss: 0.2032 - accuracy: 0.9239 - val_loss: 0.2761 - val_accuracy: 0.8881\n",
            "Epoch 7/20\n",
            "18/18 [==============================] - ETA: 0s - loss: 0.1628 - accuracy: 0.9413\n",
            "Epoch 00007: val_accuracy improved from 0.88813 to 0.89094, saving model to .\\modelo_mlp.hdf5\n",
            "18/18 [==============================] - 15s 860ms/step - loss: 0.1628 - accuracy: 0.9413 - val_loss: 0.2712 - val_accuracy: 0.8909\n",
            "Epoch 8/20\n",
            "18/18 [==============================] - ETA: 0s - loss: 0.1308 - accuracy: 0.9562\n",
            "Epoch 00008: val_accuracy improved from 0.89094 to 0.89285, saving model to .\\modelo_mlp.hdf5\n",
            "18/18 [==============================] - 15s 861ms/step - loss: 0.1308 - accuracy: 0.9562 - val_loss: 0.2698 - val_accuracy: 0.8928\n",
            "Epoch 9/20\n",
            "18/18 [==============================] - ETA: 0s - loss: 0.1012 - accuracy: 0.9678\n",
            "Epoch 00009: val_accuracy did not improve from 0.89285\n",
            "18/18 [==============================] - 12s 679ms/step - loss: 0.1012 - accuracy: 0.9678 - val_loss: 0.2762 - val_accuracy: 0.8927\n",
            "Epoch 10/20\n",
            "18/18 [==============================] - ETA: 0s - loss: 0.0772 - accuracy: 0.9778\n",
            "Epoch 00010: val_accuracy did not improve from 0.89285\n",
            "18/18 [==============================] - 12s 678ms/step - loss: 0.0772 - accuracy: 0.9778 - val_loss: 0.2855 - val_accuracy: 0.8897\n",
            "Epoch 11/20\n",
            "18/18 [==============================] - ETA: 0s - loss: 0.0578 - accuracy: 0.9849\n",
            "Epoch 00011: val_accuracy did not improve from 0.89285\n",
            "18/18 [==============================] - 12s 680ms/step - loss: 0.0578 - accuracy: 0.9849 - val_loss: 0.3033 - val_accuracy: 0.8871\n",
            "Epoch 12/20\n",
            "18/18 [==============================] - ETA: 0s - loss: 0.0430 - accuracy: 0.9898\n",
            "Epoch 00012: val_accuracy did not improve from 0.89285\n",
            "18/18 [==============================] - 12s 683ms/step - loss: 0.0430 - accuracy: 0.9898 - val_loss: 0.3175 - val_accuracy: 0.8854\n",
            "Epoch 13/20\n",
            "18/18 [==============================] - ETA: 0s - loss: 0.0322 - accuracy: 0.9929\n",
            "Epoch 00013: val_accuracy did not improve from 0.89285\n",
            "18/18 [==============================] - 12s 682ms/step - loss: 0.0322 - accuracy: 0.9929 - val_loss: 0.3341 - val_accuracy: 0.8840\n",
            "Epoch 14/20\n",
            "18/18 [==============================] - ETA: 0s - loss: 0.0226 - accuracy: 0.9955\n",
            "Epoch 00014: val_accuracy did not improve from 0.89285\n",
            "18/18 [==============================] - 12s 686ms/step - loss: 0.0226 - accuracy: 0.9955 - val_loss: 0.3511 - val_accuracy: 0.8824\n",
            "Epoch 15/20\n",
            "18/18 [==============================] - ETA: 0s - loss: 0.0172 - accuracy: 0.9966\n",
            "Epoch 00015: val_accuracy did not improve from 0.89285\n",
            "18/18 [==============================] - 12s 681ms/step - loss: 0.0172 - accuracy: 0.9966 - val_loss: 0.3678 - val_accuracy: 0.8816\n",
            "Epoch 16/20\n",
            "18/18 [==============================] - ETA: 0s - loss: 0.0140 - accuracy: 0.9973\n",
            "Epoch 00016: val_accuracy did not improve from 0.89285\n",
            "18/18 [==============================] - 12s 685ms/step - loss: 0.0140 - accuracy: 0.9973 - val_loss: 0.3840 - val_accuracy: 0.8807\n",
            "Epoch 17/20\n",
            "18/18 [==============================] - ETA: 0s - loss: 0.0110 - accuracy: 0.9981\n",
            "Epoch 00017: val_accuracy did not improve from 0.89285\n",
            "18/18 [==============================] - 12s 677ms/step - loss: 0.0110 - accuracy: 0.9981 - val_loss: 0.4045 - val_accuracy: 0.8779\n",
            "Epoch 18/20\n",
            "18/18 [==============================] - ETA: 0s - loss: 0.0087 - accuracy: 0.9986\n",
            "Epoch 00018: val_accuracy did not improve from 0.89285\n",
            "18/18 [==============================] - 12s 688ms/step - loss: 0.0087 - accuracy: 0.9986 - val_loss: 0.4136 - val_accuracy: 0.8773\n",
            "Epoch 19/20\n",
            "18/18 [==============================] - ETA: 0s - loss: 0.0075 - accuracy: 0.9988\n",
            "Epoch 00019: val_accuracy did not improve from 0.89285\n",
            "18/18 [==============================] - 12s 686ms/step - loss: 0.0075 - accuracy: 0.9988 - val_loss: 0.4256 - val_accuracy: 0.8761\n",
            "Epoch 20/20\n",
            "18/18 [==============================] - ETA: 0s - loss: 0.0066 - accuracy: 0.9987\n",
            "Epoch 00020: val_accuracy did not improve from 0.89285\n",
            "18/18 [==============================] - 13s 703ms/step - loss: 0.0066 - accuracy: 0.9987 - val_loss: 0.4351 - val_accuracy: 0.8744\n",
            "Wall time: 4min 45s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "clear_session()\n",
        "checkpointer = ModelCheckpoint(filepath='./modelo_mlp.hdf5', verbose=1,  save_best_only=True, monitor='val_accuracy')\n",
        "\n",
        "history  = model.fit(X_treino, y_treino, epochs=20, validation_data=(X_teste, y_teste), callbacks=[checkpointer], batch_size=2000)\n",
        "#history  = model.fit(X_treino, y_treino, epochs=10, validation_split=0.2, batch_size=32)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "image/svg+xml": "<?xml version=\"1.0\" encoding=\"utf-8\" standalone=\"no\"?>\r\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\r\n  \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\r\n<svg height=\"280.963594pt\" version=\"1.1\" viewBox=\"0 0 388.964375 280.963594\" width=\"388.964375pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\r\n <metadata>\r\n  <rdf:RDF xmlns:cc=\"http://creativecommons.org/ns#\" xmlns:dc=\"http://purl.org/dc/elements/1.1/\" xmlns:rdf=\"http://www.w3.org/1999/02/22-rdf-syntax-ns#\">\r\n   <cc:Work>\r\n    <dc:type rdf:resource=\"http://purl.org/dc/dcmitype/StillImage\"/>\r\n    <dc:date>2021-06-15T19:59:28.439570</dc:date>\r\n    <dc:format>image/svg+xml</dc:format>\r\n    <dc:creator>\r\n     <cc:Agent>\r\n      <dc:title>Matplotlib v3.4.2, https://matplotlib.org/</dc:title>\r\n     </cc:Agent>\r\n    </dc:creator>\r\n   </cc:Work>\r\n  </rdf:RDF>\r\n </metadata>\r\n <defs>\r\n  <style type=\"text/css\">*{stroke-linecap:butt;stroke-linejoin:round;}</style>\r\n </defs>\r\n <g id=\"figure_1\">\r\n  <g id=\"patch_1\">\r\n   <path d=\"M -0 280.963594 \r\nL 388.964375 280.963594 \r\nL 388.964375 0 \r\nL -0 0 \r\nz\r\n\" style=\"fill:#ffffff;\"/>\r\n  </g>\r\n  <g id=\"axes_1\">\r\n   <g id=\"patch_2\">\r\n    <path d=\"M 46.964375 239.229375 \r\nL 381.764375 239.229375 \r\nL 381.764375 21.789375 \r\nL 46.964375 21.789375 \r\nz\r\n\" style=\"fill:#ffffff;\"/>\r\n   </g>\r\n   <g id=\"matplotlib.axis_1\">\r\n    <g id=\"xtick_1\">\r\n     <g id=\"line2d_1\">\r\n      <path clip-path=\"url(#p2559377add)\" d=\"M 62.182557 239.229375 \r\nL 62.182557 21.789375 \r\n\" style=\"fill:none;stroke:#cccccc;stroke-linecap:round;\"/>\r\n     </g>\r\n     <g id=\"text_1\">\r\n      <!-- 0.0 -->\r\n      <g style=\"fill:#262626;\" transform=\"translate(54.537557 256.602969)scale(0.11 -0.11)\">\r\n       <defs>\r\n        <path d=\"M 266 2259 \r\nQ 266 3072 433 3567 \r\nQ 600 4063 929 4331 \r\nQ 1259 4600 1759 4600 \r\nQ 2128 4600 2406 4451 \r\nQ 2684 4303 2865 4023 \r\nQ 3047 3744 3150 3342 \r\nQ 3253 2941 3253 2259 \r\nQ 3253 1453 3087 958 \r\nQ 2922 463 2592 192 \r\nQ 2263 -78 1759 -78 \r\nQ 1097 -78 719 397 \r\nQ 266 969 266 2259 \r\nz\r\nM 844 2259 \r\nQ 844 1131 1108 757 \r\nQ 1372 384 1759 384 \r\nQ 2147 384 2411 759 \r\nQ 2675 1134 2675 2259 \r\nQ 2675 3391 2411 3762 \r\nQ 2147 4134 1753 4134 \r\nQ 1366 4134 1134 3806 \r\nQ 844 3388 844 2259 \r\nz\r\n\" id=\"ArialMT-30\" transform=\"scale(0.015625)\"/>\r\n        <path d=\"M 581 0 \r\nL 581 641 \r\nL 1222 641 \r\nL 1222 0 \r\nL 581 0 \r\nz\r\n\" id=\"ArialMT-2e\" transform=\"scale(0.015625)\"/>\r\n       </defs>\r\n       <use xlink:href=\"#ArialMT-30\"/>\r\n       <use x=\"55.615234\" xlink:href=\"#ArialMT-2e\"/>\r\n       <use x=\"83.398438\" xlink:href=\"#ArialMT-30\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_2\">\r\n     <g id=\"line2d_2\">\r\n      <path clip-path=\"url(#p2559377add)\" d=\"M 102.230404 239.229375 \r\nL 102.230404 21.789375 \r\n\" style=\"fill:none;stroke:#cccccc;stroke-linecap:round;\"/>\r\n     </g>\r\n     <g id=\"text_2\">\r\n      <!-- 2.5 -->\r\n      <g style=\"fill:#262626;\" transform=\"translate(94.585404 256.602969)scale(0.11 -0.11)\">\r\n       <defs>\r\n        <path d=\"M 3222 541 \r\nL 3222 0 \r\nL 194 0 \r\nQ 188 203 259 391 \r\nQ 375 700 629 1000 \r\nQ 884 1300 1366 1694 \r\nQ 2113 2306 2375 2664 \r\nQ 2638 3022 2638 3341 \r\nQ 2638 3675 2398 3904 \r\nQ 2159 4134 1775 4134 \r\nQ 1369 4134 1125 3890 \r\nQ 881 3647 878 3216 \r\nL 300 3275 \r\nQ 359 3922 746 4261 \r\nQ 1134 4600 1788 4600 \r\nQ 2447 4600 2831 4234 \r\nQ 3216 3869 3216 3328 \r\nQ 3216 3053 3103 2787 \r\nQ 2991 2522 2730 2228 \r\nQ 2469 1934 1863 1422 \r\nQ 1356 997 1212 845 \r\nQ 1069 694 975 541 \r\nL 3222 541 \r\nz\r\n\" id=\"ArialMT-32\" transform=\"scale(0.015625)\"/>\r\n        <path d=\"M 266 1200 \r\nL 856 1250 \r\nQ 922 819 1161 601 \r\nQ 1400 384 1738 384 \r\nQ 2144 384 2425 690 \r\nQ 2706 997 2706 1503 \r\nQ 2706 1984 2436 2262 \r\nQ 2166 2541 1728 2541 \r\nQ 1456 2541 1237 2417 \r\nQ 1019 2294 894 2097 \r\nL 366 2166 \r\nL 809 4519 \r\nL 3088 4519 \r\nL 3088 3981 \r\nL 1259 3981 \r\nL 1013 2750 \r\nQ 1425 3038 1878 3038 \r\nQ 2478 3038 2890 2622 \r\nQ 3303 2206 3303 1553 \r\nQ 3303 931 2941 478 \r\nQ 2500 -78 1738 -78 \r\nQ 1113 -78 717 272 \r\nQ 322 622 266 1200 \r\nz\r\n\" id=\"ArialMT-35\" transform=\"scale(0.015625)\"/>\r\n       </defs>\r\n       <use xlink:href=\"#ArialMT-32\"/>\r\n       <use x=\"55.615234\" xlink:href=\"#ArialMT-2e\"/>\r\n       <use x=\"83.398438\" xlink:href=\"#ArialMT-35\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_3\">\r\n     <g id=\"line2d_3\">\r\n      <path clip-path=\"url(#p2559377add)\" d=\"M 142.278251 239.229375 \r\nL 142.278251 21.789375 \r\n\" style=\"fill:none;stroke:#cccccc;stroke-linecap:round;\"/>\r\n     </g>\r\n     <g id=\"text_3\">\r\n      <!-- 5.0 -->\r\n      <g style=\"fill:#262626;\" transform=\"translate(134.633251 256.602969)scale(0.11 -0.11)\">\r\n       <use xlink:href=\"#ArialMT-35\"/>\r\n       <use x=\"55.615234\" xlink:href=\"#ArialMT-2e\"/>\r\n       <use x=\"83.398438\" xlink:href=\"#ArialMT-30\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_4\">\r\n     <g id=\"line2d_4\">\r\n      <path clip-path=\"url(#p2559377add)\" d=\"M 182.326097 239.229375 \r\nL 182.326097 21.789375 \r\n\" style=\"fill:none;stroke:#cccccc;stroke-linecap:round;\"/>\r\n     </g>\r\n     <g id=\"text_4\">\r\n      <!-- 7.5 -->\r\n      <g style=\"fill:#262626;\" transform=\"translate(174.681097 256.602969)scale(0.11 -0.11)\">\r\n       <defs>\r\n        <path d=\"M 303 3981 \r\nL 303 4522 \r\nL 3269 4522 \r\nL 3269 4084 \r\nQ 2831 3619 2401 2847 \r\nQ 1972 2075 1738 1259 \r\nQ 1569 684 1522 0 \r\nL 944 0 \r\nQ 953 541 1156 1306 \r\nQ 1359 2072 1739 2783 \r\nQ 2119 3494 2547 3981 \r\nL 303 3981 \r\nz\r\n\" id=\"ArialMT-37\" transform=\"scale(0.015625)\"/>\r\n       </defs>\r\n       <use xlink:href=\"#ArialMT-37\"/>\r\n       <use x=\"55.615234\" xlink:href=\"#ArialMT-2e\"/>\r\n       <use x=\"83.398438\" xlink:href=\"#ArialMT-35\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_5\">\r\n     <g id=\"line2d_5\">\r\n      <path clip-path=\"url(#p2559377add)\" d=\"M 222.373944 239.229375 \r\nL 222.373944 21.789375 \r\n\" style=\"fill:none;stroke:#cccccc;stroke-linecap:round;\"/>\r\n     </g>\r\n     <g id=\"text_5\">\r\n      <!-- 10.0 -->\r\n      <g style=\"fill:#262626;\" transform=\"translate(211.670429 256.602969)scale(0.11 -0.11)\">\r\n       <defs>\r\n        <path d=\"M 2384 0 \r\nL 1822 0 \r\nL 1822 3584 \r\nQ 1619 3391 1289 3197 \r\nQ 959 3003 697 2906 \r\nL 697 3450 \r\nQ 1169 3672 1522 3987 \r\nQ 1875 4303 2022 4600 \r\nL 2384 4600 \r\nL 2384 0 \r\nz\r\n\" id=\"ArialMT-31\" transform=\"scale(0.015625)\"/>\r\n       </defs>\r\n       <use xlink:href=\"#ArialMT-31\"/>\r\n       <use x=\"55.615234\" xlink:href=\"#ArialMT-30\"/>\r\n       <use x=\"111.230469\" xlink:href=\"#ArialMT-2e\"/>\r\n       <use x=\"139.013672\" xlink:href=\"#ArialMT-30\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_6\">\r\n     <g id=\"line2d_6\">\r\n      <path clip-path=\"url(#p2559377add)\" d=\"M 262.421791 239.229375 \r\nL 262.421791 21.789375 \r\n\" style=\"fill:none;stroke:#cccccc;stroke-linecap:round;\"/>\r\n     </g>\r\n     <g id=\"text_6\">\r\n      <!-- 12.5 -->\r\n      <g style=\"fill:#262626;\" transform=\"translate(251.718276 256.602969)scale(0.11 -0.11)\">\r\n       <use xlink:href=\"#ArialMT-31\"/>\r\n       <use x=\"55.615234\" xlink:href=\"#ArialMT-32\"/>\r\n       <use x=\"111.230469\" xlink:href=\"#ArialMT-2e\"/>\r\n       <use x=\"139.013672\" xlink:href=\"#ArialMT-35\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_7\">\r\n     <g id=\"line2d_7\">\r\n      <path clip-path=\"url(#p2559377add)\" d=\"M 302.469638 239.229375 \r\nL 302.469638 21.789375 \r\n\" style=\"fill:none;stroke:#cccccc;stroke-linecap:round;\"/>\r\n     </g>\r\n     <g id=\"text_7\">\r\n      <!-- 15.0 -->\r\n      <g style=\"fill:#262626;\" transform=\"translate(291.766123 256.602969)scale(0.11 -0.11)\">\r\n       <use xlink:href=\"#ArialMT-31\"/>\r\n       <use x=\"55.615234\" xlink:href=\"#ArialMT-35\"/>\r\n       <use x=\"111.230469\" xlink:href=\"#ArialMT-2e\"/>\r\n       <use x=\"139.013672\" xlink:href=\"#ArialMT-30\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_8\">\r\n     <g id=\"line2d_8\">\r\n      <path clip-path=\"url(#p2559377add)\" d=\"M 342.517485 239.229375 \r\nL 342.517485 21.789375 \r\n\" style=\"fill:none;stroke:#cccccc;stroke-linecap:round;\"/>\r\n     </g>\r\n     <g id=\"text_8\">\r\n      <!-- 17.5 -->\r\n      <g style=\"fill:#262626;\" transform=\"translate(331.813969 256.602969)scale(0.11 -0.11)\">\r\n       <use xlink:href=\"#ArialMT-31\"/>\r\n       <use x=\"55.615234\" xlink:href=\"#ArialMT-37\"/>\r\n       <use x=\"111.230469\" xlink:href=\"#ArialMT-2e\"/>\r\n       <use x=\"139.013672\" xlink:href=\"#ArialMT-35\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"text_9\">\r\n     <!-- epoch -->\r\n     <g style=\"fill:#262626;\" transform=\"translate(198.018125 271.378594)scale(0.12 -0.12)\">\r\n      <defs>\r\n       <path d=\"M 2694 1069 \r\nL 3275 997 \r\nQ 3138 488 2766 206 \r\nQ 2394 -75 1816 -75 \r\nQ 1088 -75 661 373 \r\nQ 234 822 234 1631 \r\nQ 234 2469 665 2931 \r\nQ 1097 3394 1784 3394 \r\nQ 2450 3394 2872 2941 \r\nQ 3294 2488 3294 1666 \r\nQ 3294 1616 3291 1516 \r\nL 816 1516 \r\nQ 847 969 1125 678 \r\nQ 1403 388 1819 388 \r\nQ 2128 388 2347 550 \r\nQ 2566 713 2694 1069 \r\nz\r\nM 847 1978 \r\nL 2700 1978 \r\nQ 2663 2397 2488 2606 \r\nQ 2219 2931 1791 2931 \r\nQ 1403 2931 1139 2672 \r\nQ 875 2413 847 1978 \r\nz\r\n\" id=\"ArialMT-65\" transform=\"scale(0.015625)\"/>\r\n       <path d=\"M 422 -1272 \r\nL 422 3319 \r\nL 934 3319 \r\nL 934 2888 \r\nQ 1116 3141 1344 3267 \r\nQ 1572 3394 1897 3394 \r\nQ 2322 3394 2647 3175 \r\nQ 2972 2956 3137 2557 \r\nQ 3303 2159 3303 1684 \r\nQ 3303 1175 3120 767 \r\nQ 2938 359 2589 142 \r\nQ 2241 -75 1856 -75 \r\nQ 1575 -75 1351 44 \r\nQ 1128 163 984 344 \r\nL 984 -1272 \r\nL 422 -1272 \r\nz\r\nM 931 1641 \r\nQ 931 1000 1190 694 \r\nQ 1450 388 1819 388 \r\nQ 2194 388 2461 705 \r\nQ 2728 1022 2728 1688 \r\nQ 2728 2322 2467 2637 \r\nQ 2206 2953 1844 2953 \r\nQ 1484 2953 1207 2617 \r\nQ 931 2281 931 1641 \r\nz\r\n\" id=\"ArialMT-70\" transform=\"scale(0.015625)\"/>\r\n       <path d=\"M 213 1659 \r\nQ 213 2581 725 3025 \r\nQ 1153 3394 1769 3394 \r\nQ 2453 3394 2887 2945 \r\nQ 3322 2497 3322 1706 \r\nQ 3322 1066 3130 698 \r\nQ 2938 331 2570 128 \r\nQ 2203 -75 1769 -75 \r\nQ 1072 -75 642 372 \r\nQ 213 819 213 1659 \r\nz\r\nM 791 1659 \r\nQ 791 1022 1069 705 \r\nQ 1347 388 1769 388 \r\nQ 2188 388 2466 706 \r\nQ 2744 1025 2744 1678 \r\nQ 2744 2294 2464 2611 \r\nQ 2184 2928 1769 2928 \r\nQ 1347 2928 1069 2612 \r\nQ 791 2297 791 1659 \r\nz\r\n\" id=\"ArialMT-6f\" transform=\"scale(0.015625)\"/>\r\n       <path d=\"M 2588 1216 \r\nL 3141 1144 \r\nQ 3050 572 2676 248 \r\nQ 2303 -75 1759 -75 \r\nQ 1078 -75 664 370 \r\nQ 250 816 250 1647 \r\nQ 250 2184 428 2587 \r\nQ 606 2991 970 3192 \r\nQ 1334 3394 1763 3394 \r\nQ 2303 3394 2647 3120 \r\nQ 2991 2847 3088 2344 \r\nL 2541 2259 \r\nQ 2463 2594 2264 2762 \r\nQ 2066 2931 1784 2931 \r\nQ 1359 2931 1093 2626 \r\nQ 828 2322 828 1663 \r\nQ 828 994 1084 691 \r\nQ 1341 388 1753 388 \r\nQ 2084 388 2306 591 \r\nQ 2528 794 2588 1216 \r\nz\r\n\" id=\"ArialMT-63\" transform=\"scale(0.015625)\"/>\r\n       <path d=\"M 422 0 \r\nL 422 4581 \r\nL 984 4581 \r\nL 984 2938 \r\nQ 1378 3394 1978 3394 \r\nQ 2347 3394 2619 3248 \r\nQ 2891 3103 3008 2847 \r\nQ 3125 2591 3125 2103 \r\nL 3125 0 \r\nL 2563 0 \r\nL 2563 2103 \r\nQ 2563 2525 2380 2717 \r\nQ 2197 2909 1863 2909 \r\nQ 1613 2909 1392 2779 \r\nQ 1172 2650 1078 2428 \r\nQ 984 2206 984 1816 \r\nL 984 0 \r\nL 422 0 \r\nz\r\n\" id=\"ArialMT-68\" transform=\"scale(0.015625)\"/>\r\n      </defs>\r\n      <use xlink:href=\"#ArialMT-65\"/>\r\n      <use x=\"55.615234\" xlink:href=\"#ArialMT-70\"/>\r\n      <use x=\"111.230469\" xlink:href=\"#ArialMT-6f\"/>\r\n      <use x=\"166.845703\" xlink:href=\"#ArialMT-63\"/>\r\n      <use x=\"216.845703\" xlink:href=\"#ArialMT-68\"/>\r\n     </g>\r\n    </g>\r\n   </g>\r\n   <g id=\"matplotlib.axis_2\">\r\n    <g id=\"ytick_1\">\r\n     <g id=\"line2d_9\">\r\n      <path clip-path=\"url(#p2559377add)\" d=\"M 46.964375 211.08309 \r\nL 381.764375 211.08309 \r\n\" style=\"fill:none;stroke:#cccccc;stroke-linecap:round;\"/>\r\n     </g>\r\n     <g id=\"text_10\">\r\n      <!-- 0.6 -->\r\n      <g style=\"fill:#262626;\" transform=\"translate(22.174375 215.019887)scale(0.11 -0.11)\">\r\n       <defs>\r\n        <path d=\"M 3184 3459 \r\nL 2625 3416 \r\nQ 2550 3747 2413 3897 \r\nQ 2184 4138 1850 4138 \r\nQ 1581 4138 1378 3988 \r\nQ 1113 3794 959 3422 \r\nQ 806 3050 800 2363 \r\nQ 1003 2672 1297 2822 \r\nQ 1591 2972 1913 2972 \r\nQ 2475 2972 2870 2558 \r\nQ 3266 2144 3266 1488 \r\nQ 3266 1056 3080 686 \r\nQ 2894 316 2569 119 \r\nQ 2244 -78 1831 -78 \r\nQ 1128 -78 684 439 \r\nQ 241 956 241 2144 \r\nQ 241 3472 731 4075 \r\nQ 1159 4600 1884 4600 \r\nQ 2425 4600 2770 4297 \r\nQ 3116 3994 3184 3459 \r\nz\r\nM 888 1484 \r\nQ 888 1194 1011 928 \r\nQ 1134 663 1356 523 \r\nQ 1578 384 1822 384 \r\nQ 2178 384 2434 671 \r\nQ 2691 959 2691 1453 \r\nQ 2691 1928 2437 2201 \r\nQ 2184 2475 1800 2475 \r\nQ 1419 2475 1153 2201 \r\nQ 888 1928 888 1484 \r\nz\r\n\" id=\"ArialMT-36\" transform=\"scale(0.015625)\"/>\r\n       </defs>\r\n       <use xlink:href=\"#ArialMT-30\"/>\r\n       <use x=\"55.615234\" xlink:href=\"#ArialMT-2e\"/>\r\n       <use x=\"83.398438\" xlink:href=\"#ArialMT-36\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"ytick_2\">\r\n     <g id=\"line2d_10\">\r\n      <path clip-path=\"url(#p2559377add)\" d=\"M 46.964375 166.094765 \r\nL 381.764375 166.094765 \r\n\" style=\"fill:none;stroke:#cccccc;stroke-linecap:round;\"/>\r\n     </g>\r\n     <g id=\"text_11\">\r\n      <!-- 0.7 -->\r\n      <g style=\"fill:#262626;\" transform=\"translate(22.174375 170.031562)scale(0.11 -0.11)\">\r\n       <use xlink:href=\"#ArialMT-30\"/>\r\n       <use x=\"55.615234\" xlink:href=\"#ArialMT-2e\"/>\r\n       <use x=\"83.398438\" xlink:href=\"#ArialMT-37\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"ytick_3\">\r\n     <g id=\"line2d_11\">\r\n      <path clip-path=\"url(#p2559377add)\" d=\"M 46.964375 121.10644 \r\nL 381.764375 121.10644 \r\n\" style=\"fill:none;stroke:#cccccc;stroke-linecap:round;\"/>\r\n     </g>\r\n     <g id=\"text_12\">\r\n      <!-- 0.8 -->\r\n      <g style=\"fill:#262626;\" transform=\"translate(22.174375 125.043237)scale(0.11 -0.11)\">\r\n       <defs>\r\n        <path d=\"M 1131 2484 \r\nQ 781 2613 612 2850 \r\nQ 444 3088 444 3419 \r\nQ 444 3919 803 4259 \r\nQ 1163 4600 1759 4600 \r\nQ 2359 4600 2725 4251 \r\nQ 3091 3903 3091 3403 \r\nQ 3091 3084 2923 2848 \r\nQ 2756 2613 2416 2484 \r\nQ 2838 2347 3058 2040 \r\nQ 3278 1734 3278 1309 \r\nQ 3278 722 2862 322 \r\nQ 2447 -78 1769 -78 \r\nQ 1091 -78 675 323 \r\nQ 259 725 259 1325 \r\nQ 259 1772 486 2073 \r\nQ 713 2375 1131 2484 \r\nz\r\nM 1019 3438 \r\nQ 1019 3113 1228 2906 \r\nQ 1438 2700 1772 2700 \r\nQ 2097 2700 2305 2904 \r\nQ 2513 3109 2513 3406 \r\nQ 2513 3716 2298 3927 \r\nQ 2084 4138 1766 4138 \r\nQ 1444 4138 1231 3931 \r\nQ 1019 3725 1019 3438 \r\nz\r\nM 838 1322 \r\nQ 838 1081 952 856 \r\nQ 1066 631 1291 507 \r\nQ 1516 384 1775 384 \r\nQ 2178 384 2440 643 \r\nQ 2703 903 2703 1303 \r\nQ 2703 1709 2433 1975 \r\nQ 2163 2241 1756 2241 \r\nQ 1359 2241 1098 1978 \r\nQ 838 1716 838 1322 \r\nz\r\n\" id=\"ArialMT-38\" transform=\"scale(0.015625)\"/>\r\n       </defs>\r\n       <use xlink:href=\"#ArialMT-30\"/>\r\n       <use x=\"55.615234\" xlink:href=\"#ArialMT-2e\"/>\r\n       <use x=\"83.398438\" xlink:href=\"#ArialMT-38\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"ytick_4\">\r\n     <g id=\"line2d_12\">\r\n      <path clip-path=\"url(#p2559377add)\" d=\"M 46.964375 76.118115 \r\nL 381.764375 76.118115 \r\n\" style=\"fill:none;stroke:#cccccc;stroke-linecap:round;\"/>\r\n     </g>\r\n     <g id=\"text_13\">\r\n      <!-- 0.9 -->\r\n      <g style=\"fill:#262626;\" transform=\"translate(22.174375 80.054912)scale(0.11 -0.11)\">\r\n       <defs>\r\n        <path d=\"M 350 1059 \r\nL 891 1109 \r\nQ 959 728 1153 556 \r\nQ 1347 384 1650 384 \r\nQ 1909 384 2104 503 \r\nQ 2300 622 2425 820 \r\nQ 2550 1019 2634 1356 \r\nQ 2719 1694 2719 2044 \r\nQ 2719 2081 2716 2156 \r\nQ 2547 1888 2255 1720 \r\nQ 1963 1553 1622 1553 \r\nQ 1053 1553 659 1965 \r\nQ 266 2378 266 3053 \r\nQ 266 3750 677 4175 \r\nQ 1088 4600 1706 4600 \r\nQ 2153 4600 2523 4359 \r\nQ 2894 4119 3086 3673 \r\nQ 3278 3228 3278 2384 \r\nQ 3278 1506 3087 986 \r\nQ 2897 466 2520 194 \r\nQ 2144 -78 1638 -78 \r\nQ 1100 -78 759 220 \r\nQ 419 519 350 1059 \r\nz\r\nM 2653 3081 \r\nQ 2653 3566 2395 3850 \r\nQ 2138 4134 1775 4134 \r\nQ 1400 4134 1122 3828 \r\nQ 844 3522 844 3034 \r\nQ 844 2597 1108 2323 \r\nQ 1372 2050 1759 2050 \r\nQ 2150 2050 2401 2323 \r\nQ 2653 2597 2653 3081 \r\nz\r\n\" id=\"ArialMT-39\" transform=\"scale(0.015625)\"/>\r\n       </defs>\r\n       <use xlink:href=\"#ArialMT-30\"/>\r\n       <use x=\"55.615234\" xlink:href=\"#ArialMT-2e\"/>\r\n       <use x=\"83.398438\" xlink:href=\"#ArialMT-39\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"ytick_5\">\r\n     <g id=\"line2d_13\">\r\n      <path clip-path=\"url(#p2559377add)\" d=\"M 46.964375 31.12979 \r\nL 381.764375 31.12979 \r\n\" style=\"fill:none;stroke:#cccccc;stroke-linecap:round;\"/>\r\n     </g>\r\n     <g id=\"text_14\">\r\n      <!-- 1.0 -->\r\n      <g style=\"fill:#262626;\" transform=\"translate(22.174375 35.066587)scale(0.11 -0.11)\">\r\n       <use xlink:href=\"#ArialMT-31\"/>\r\n       <use x=\"55.615234\" xlink:href=\"#ArialMT-2e\"/>\r\n       <use x=\"83.398438\" xlink:href=\"#ArialMT-30\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"text_15\">\r\n     <!-- accuracy -->\r\n     <g style=\"fill:#262626;\" transform=\"translate(15.64875 154.516875)rotate(-90)scale(0.12 -0.12)\">\r\n      <defs>\r\n       <path d=\"M 2588 409 \r\nQ 2275 144 1986 34 \r\nQ 1697 -75 1366 -75 \r\nQ 819 -75 525 192 \r\nQ 231 459 231 875 \r\nQ 231 1119 342 1320 \r\nQ 453 1522 633 1644 \r\nQ 813 1766 1038 1828 \r\nQ 1203 1872 1538 1913 \r\nQ 2219 1994 2541 2106 \r\nQ 2544 2222 2544 2253 \r\nQ 2544 2597 2384 2738 \r\nQ 2169 2928 1744 2928 \r\nQ 1347 2928 1158 2789 \r\nQ 969 2650 878 2297 \r\nL 328 2372 \r\nQ 403 2725 575 2942 \r\nQ 747 3159 1072 3276 \r\nQ 1397 3394 1825 3394 \r\nQ 2250 3394 2515 3294 \r\nQ 2781 3194 2906 3042 \r\nQ 3031 2891 3081 2659 \r\nQ 3109 2516 3109 2141 \r\nL 3109 1391 \r\nQ 3109 606 3145 398 \r\nQ 3181 191 3288 0 \r\nL 2700 0 \r\nQ 2613 175 2588 409 \r\nz\r\nM 2541 1666 \r\nQ 2234 1541 1622 1453 \r\nQ 1275 1403 1131 1340 \r\nQ 988 1278 909 1158 \r\nQ 831 1038 831 891 \r\nQ 831 666 1001 516 \r\nQ 1172 366 1500 366 \r\nQ 1825 366 2078 508 \r\nQ 2331 650 2450 897 \r\nQ 2541 1088 2541 1459 \r\nL 2541 1666 \r\nz\r\n\" id=\"ArialMT-61\" transform=\"scale(0.015625)\"/>\r\n       <path d=\"M 2597 0 \r\nL 2597 488 \r\nQ 2209 -75 1544 -75 \r\nQ 1250 -75 995 37 \r\nQ 741 150 617 320 \r\nQ 494 491 444 738 \r\nQ 409 903 409 1263 \r\nL 409 3319 \r\nL 972 3319 \r\nL 972 1478 \r\nQ 972 1038 1006 884 \r\nQ 1059 663 1231 536 \r\nQ 1403 409 1656 409 \r\nQ 1909 409 2131 539 \r\nQ 2353 669 2445 892 \r\nQ 2538 1116 2538 1541 \r\nL 2538 3319 \r\nL 3100 3319 \r\nL 3100 0 \r\nL 2597 0 \r\nz\r\n\" id=\"ArialMT-75\" transform=\"scale(0.015625)\"/>\r\n       <path d=\"M 416 0 \r\nL 416 3319 \r\nL 922 3319 \r\nL 922 2816 \r\nQ 1116 3169 1280 3281 \r\nQ 1444 3394 1641 3394 \r\nQ 1925 3394 2219 3213 \r\nL 2025 2691 \r\nQ 1819 2813 1613 2813 \r\nQ 1428 2813 1281 2702 \r\nQ 1134 2591 1072 2394 \r\nQ 978 2094 978 1738 \r\nL 978 0 \r\nL 416 0 \r\nz\r\n\" id=\"ArialMT-72\" transform=\"scale(0.015625)\"/>\r\n       <path d=\"M 397 -1278 \r\nL 334 -750 \r\nQ 519 -800 656 -800 \r\nQ 844 -800 956 -737 \r\nQ 1069 -675 1141 -563 \r\nQ 1194 -478 1313 -144 \r\nQ 1328 -97 1363 -6 \r\nL 103 3319 \r\nL 709 3319 \r\nL 1400 1397 \r\nQ 1534 1031 1641 628 \r\nQ 1738 1016 1872 1384 \r\nL 2581 3319 \r\nL 3144 3319 \r\nL 1881 -56 \r\nQ 1678 -603 1566 -809 \r\nQ 1416 -1088 1222 -1217 \r\nQ 1028 -1347 759 -1347 \r\nQ 597 -1347 397 -1278 \r\nz\r\n\" id=\"ArialMT-79\" transform=\"scale(0.015625)\"/>\r\n      </defs>\r\n      <use xlink:href=\"#ArialMT-61\"/>\r\n      <use x=\"55.615234\" xlink:href=\"#ArialMT-63\"/>\r\n      <use x=\"105.615234\" xlink:href=\"#ArialMT-63\"/>\r\n      <use x=\"155.615234\" xlink:href=\"#ArialMT-75\"/>\r\n      <use x=\"211.230469\" xlink:href=\"#ArialMT-72\"/>\r\n      <use x=\"244.53125\" xlink:href=\"#ArialMT-61\"/>\r\n      <use x=\"300.146484\" xlink:href=\"#ArialMT-63\"/>\r\n      <use x=\"350.146484\" xlink:href=\"#ArialMT-79\"/>\r\n     </g>\r\n    </g>\r\n   </g>\r\n   <g id=\"line2d_14\">\r\n    <path clip-path=\"url(#p2559377add)\" d=\"M 62.182557 229.345739 \r\nL 78.201696 137.880881 \r\nL 94.220834 101.699225 \r\nL 110.239973 89.040686 \r\nL 126.259112 76.445324 \r\nL 142.278251 65.353299 \r\nL 158.297389 57.558596 \r\nL 174.316528 50.812419 \r\nL 190.335667 45.632781 \r\nL 206.354806 41.11006 \r\nL 222.373944 37.926488 \r\nL 238.393083 35.715661 \r\nL 254.412222 34.33865 \r\nL 270.431361 33.138485 \r\nL 286.450499 32.645784 \r\nL 302.469638 32.342585 \r\nL 318.488777 31.97621 \r\nL 334.507916 31.774078 \r\nL 350.527054 31.673011 \r\nL 366.546193 31.710928 \r\n\" style=\"fill:none;stroke:#4c72b0;stroke-linecap:round;stroke-width:1.5;\"/>\r\n   </g>\r\n   <g id=\"line2d_15\">\r\n    <path clip-path=\"url(#p2559377add)\" d=\"M 62.182557 114.709122 \r\nL 78.201696 99.751776 \r\nL 94.220834 94.698599 \r\nL 110.239973 90.706603 \r\nL 126.259112 85.350254 \r\nL 142.278251 81.459298 \r\nL 158.297389 80.19601 \r\nL 174.316528 79.336988 \r\nL 190.335667 79.387507 \r\nL 206.354806 80.751861 \r\nL 222.373944 81.914083 \r\nL 238.393083 82.672066 \r\nL 254.412222 83.328983 \r\nL 270.431361 84.03642 \r\nL 286.450499 84.390138 \r\nL 302.469638 84.794403 \r\nL 318.488777 86.057691 \r\nL 334.507916 86.310343 \r\nL 350.527054 86.866194 \r\nL 366.546193 87.624177 \r\n\" style=\"fill:none;stroke:#dd8452;stroke-linecap:round;stroke-width:1.5;\"/>\r\n   </g>\r\n   <g id=\"patch_3\">\r\n    <path d=\"M 46.964375 239.229375 \r\nL 46.964375 21.789375 \r\n\" style=\"fill:none;stroke:#cccccc;stroke-linecap:square;stroke-linejoin:miter;stroke-width:1.25;\"/>\r\n   </g>\r\n   <g id=\"patch_4\">\r\n    <path d=\"M 381.764375 239.229375 \r\nL 381.764375 21.789375 \r\n\" style=\"fill:none;stroke:#cccccc;stroke-linecap:square;stroke-linejoin:miter;stroke-width:1.25;\"/>\r\n   </g>\r\n   <g id=\"patch_5\">\r\n    <path d=\"M 46.964375 239.229375 \r\nL 381.764375 239.229375 \r\n\" style=\"fill:none;stroke:#cccccc;stroke-linecap:square;stroke-linejoin:miter;stroke-width:1.25;\"/>\r\n   </g>\r\n   <g id=\"patch_6\">\r\n    <path d=\"M 46.964375 21.789375 \r\nL 381.764375 21.789375 \r\n\" style=\"fill:none;stroke:#cccccc;stroke-linecap:square;stroke-linejoin:miter;stroke-width:1.25;\"/>\r\n   </g>\r\n   <g id=\"text_16\">\r\n    <!-- model accuracy -->\r\n    <g style=\"fill:#262626;\" transform=\"translate(172.349375 15.789375)scale(0.12 -0.12)\">\r\n     <defs>\r\n      <path d=\"M 422 0 \r\nL 422 3319 \r\nL 925 3319 \r\nL 925 2853 \r\nQ 1081 3097 1340 3245 \r\nQ 1600 3394 1931 3394 \r\nQ 2300 3394 2536 3241 \r\nQ 2772 3088 2869 2813 \r\nQ 3263 3394 3894 3394 \r\nQ 4388 3394 4653 3120 \r\nQ 4919 2847 4919 2278 \r\nL 4919 0 \r\nL 4359 0 \r\nL 4359 2091 \r\nQ 4359 2428 4304 2576 \r\nQ 4250 2725 4106 2815 \r\nQ 3963 2906 3769 2906 \r\nQ 3419 2906 3187 2673 \r\nQ 2956 2441 2956 1928 \r\nL 2956 0 \r\nL 2394 0 \r\nL 2394 2156 \r\nQ 2394 2531 2256 2718 \r\nQ 2119 2906 1806 2906 \r\nQ 1569 2906 1367 2781 \r\nQ 1166 2656 1075 2415 \r\nQ 984 2175 984 1722 \r\nL 984 0 \r\nL 422 0 \r\nz\r\n\" id=\"ArialMT-6d\" transform=\"scale(0.015625)\"/>\r\n      <path d=\"M 2575 0 \r\nL 2575 419 \r\nQ 2259 -75 1647 -75 \r\nQ 1250 -75 917 144 \r\nQ 584 363 401 755 \r\nQ 219 1147 219 1656 \r\nQ 219 2153 384 2558 \r\nQ 550 2963 881 3178 \r\nQ 1213 3394 1622 3394 \r\nQ 1922 3394 2156 3267 \r\nQ 2391 3141 2538 2938 \r\nL 2538 4581 \r\nL 3097 4581 \r\nL 3097 0 \r\nL 2575 0 \r\nz\r\nM 797 1656 \r\nQ 797 1019 1065 703 \r\nQ 1334 388 1700 388 \r\nQ 2069 388 2326 689 \r\nQ 2584 991 2584 1609 \r\nQ 2584 2291 2321 2609 \r\nQ 2059 2928 1675 2928 \r\nQ 1300 2928 1048 2622 \r\nQ 797 2316 797 1656 \r\nz\r\n\" id=\"ArialMT-64\" transform=\"scale(0.015625)\"/>\r\n      <path d=\"M 409 0 \r\nL 409 4581 \r\nL 972 4581 \r\nL 972 0 \r\nL 409 0 \r\nz\r\n\" id=\"ArialMT-6c\" transform=\"scale(0.015625)\"/>\r\n      <path id=\"ArialMT-20\" transform=\"scale(0.015625)\"/>\r\n     </defs>\r\n     <use xlink:href=\"#ArialMT-6d\"/>\r\n     <use x=\"83.300781\" xlink:href=\"#ArialMT-6f\"/>\r\n     <use x=\"138.916016\" xlink:href=\"#ArialMT-64\"/>\r\n     <use x=\"194.53125\" xlink:href=\"#ArialMT-65\"/>\r\n     <use x=\"250.146484\" xlink:href=\"#ArialMT-6c\"/>\r\n     <use x=\"272.363281\" xlink:href=\"#ArialMT-20\"/>\r\n     <use x=\"300.146484\" xlink:href=\"#ArialMT-61\"/>\r\n     <use x=\"355.761719\" xlink:href=\"#ArialMT-63\"/>\r\n     <use x=\"405.761719\" xlink:href=\"#ArialMT-63\"/>\r\n     <use x=\"455.761719\" xlink:href=\"#ArialMT-75\"/>\r\n     <use x=\"511.376953\" xlink:href=\"#ArialMT-72\"/>\r\n     <use x=\"544.677734\" xlink:href=\"#ArialMT-61\"/>\r\n     <use x=\"600.292969\" xlink:href=\"#ArialMT-63\"/>\r\n     <use x=\"650.292969\" xlink:href=\"#ArialMT-79\"/>\r\n    </g>\r\n   </g>\r\n   <g id=\"legend_1\">\r\n    <g id=\"patch_7\">\r\n     <path d=\"M 54.664375 61.709063 \r\nL 136.337656 61.709063 \r\nQ 138.537656 61.709063 138.537656 59.509063 \r\nL 138.537656 29.489375 \r\nQ 138.537656 27.289375 136.337656 27.289375 \r\nL 54.664375 27.289375 \r\nQ 52.464375 27.289375 52.464375 29.489375 \r\nL 52.464375 59.509063 \r\nQ 52.464375 61.709063 54.664375 61.709063 \r\nz\r\n\" style=\"fill:#ffffff;opacity:0.8;stroke:#cccccc;stroke-linejoin:miter;\"/>\r\n    </g>\r\n    <g id=\"line2d_16\">\r\n     <path d=\"M 56.864375 35.712969 \r\nL 78.864375 35.712969 \r\n\" style=\"fill:none;stroke:#4c72b0;stroke-linecap:round;stroke-width:1.5;\"/>\r\n    </g>\r\n    <g id=\"line2d_17\"/>\r\n    <g id=\"text_17\">\r\n     <!-- train -->\r\n     <g style=\"fill:#262626;\" transform=\"translate(87.664375 39.562969)scale(0.11 -0.11)\">\r\n      <defs>\r\n       <path d=\"M 1650 503 \r\nL 1731 6 \r\nQ 1494 -44 1306 -44 \r\nQ 1000 -44 831 53 \r\nQ 663 150 594 308 \r\nQ 525 466 525 972 \r\nL 525 2881 \r\nL 113 2881 \r\nL 113 3319 \r\nL 525 3319 \r\nL 525 4141 \r\nL 1084 4478 \r\nL 1084 3319 \r\nL 1650 3319 \r\nL 1650 2881 \r\nL 1084 2881 \r\nL 1084 941 \r\nQ 1084 700 1114 631 \r\nQ 1144 563 1211 522 \r\nQ 1278 481 1403 481 \r\nQ 1497 481 1650 503 \r\nz\r\n\" id=\"ArialMT-74\" transform=\"scale(0.015625)\"/>\r\n       <path d=\"M 425 3934 \r\nL 425 4581 \r\nL 988 4581 \r\nL 988 3934 \r\nL 425 3934 \r\nz\r\nM 425 0 \r\nL 425 3319 \r\nL 988 3319 \r\nL 988 0 \r\nL 425 0 \r\nz\r\n\" id=\"ArialMT-69\" transform=\"scale(0.015625)\"/>\r\n       <path d=\"M 422 0 \r\nL 422 3319 \r\nL 928 3319 \r\nL 928 2847 \r\nQ 1294 3394 1984 3394 \r\nQ 2284 3394 2536 3286 \r\nQ 2788 3178 2913 3003 \r\nQ 3038 2828 3088 2588 \r\nQ 3119 2431 3119 2041 \r\nL 3119 0 \r\nL 2556 0 \r\nL 2556 2019 \r\nQ 2556 2363 2490 2533 \r\nQ 2425 2703 2258 2804 \r\nQ 2091 2906 1866 2906 \r\nQ 1506 2906 1245 2678 \r\nQ 984 2450 984 1813 \r\nL 984 0 \r\nL 422 0 \r\nz\r\n\" id=\"ArialMT-6e\" transform=\"scale(0.015625)\"/>\r\n      </defs>\r\n      <use xlink:href=\"#ArialMT-74\"/>\r\n      <use x=\"27.783203\" xlink:href=\"#ArialMT-72\"/>\r\n      <use x=\"61.083984\" xlink:href=\"#ArialMT-61\"/>\r\n      <use x=\"116.699219\" xlink:href=\"#ArialMT-69\"/>\r\n      <use x=\"138.916016\" xlink:href=\"#ArialMT-6e\"/>\r\n     </g>\r\n    </g>\r\n    <g id=\"line2d_18\">\r\n     <path d=\"M 56.864375 51.272813 \r\nL 78.864375 51.272813 \r\n\" style=\"fill:none;stroke:#dd8452;stroke-linecap:round;stroke-width:1.5;\"/>\r\n    </g>\r\n    <g id=\"line2d_19\"/>\r\n    <g id=\"text_18\">\r\n     <!-- validation -->\r\n     <g style=\"fill:#262626;\" transform=\"translate(87.664375 55.122813)scale(0.11 -0.11)\">\r\n      <defs>\r\n       <path d=\"M 1344 0 \r\nL 81 3319 \r\nL 675 3319 \r\nL 1388 1331 \r\nQ 1503 1009 1600 663 \r\nQ 1675 925 1809 1294 \r\nL 2547 3319 \r\nL 3125 3319 \r\nL 1869 0 \r\nL 1344 0 \r\nz\r\n\" id=\"ArialMT-76\" transform=\"scale(0.015625)\"/>\r\n      </defs>\r\n      <use xlink:href=\"#ArialMT-76\"/>\r\n      <use x=\"50\" xlink:href=\"#ArialMT-61\"/>\r\n      <use x=\"105.615234\" xlink:href=\"#ArialMT-6c\"/>\r\n      <use x=\"127.832031\" xlink:href=\"#ArialMT-69\"/>\r\n      <use x=\"150.048828\" xlink:href=\"#ArialMT-64\"/>\r\n      <use x=\"205.664062\" xlink:href=\"#ArialMT-61\"/>\r\n      <use x=\"261.279297\" xlink:href=\"#ArialMT-74\"/>\r\n      <use x=\"289.0625\" xlink:href=\"#ArialMT-69\"/>\r\n      <use x=\"311.279297\" xlink:href=\"#ArialMT-6f\"/>\r\n      <use x=\"366.894531\" xlink:href=\"#ArialMT-6e\"/>\r\n     </g>\r\n    </g>\r\n   </g>\r\n  </g>\r\n </g>\r\n <defs>\r\n  <clipPath id=\"p2559377add\">\r\n   <rect height=\"217.44\" width=\"334.8\" x=\"46.964375\" y=\"21.789375\"/>\r\n  </clipPath>\r\n </defs>\r\n</svg>\r\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'validation'], loc='upper left')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "image/svg+xml": "<?xml version=\"1.0\" encoding=\"utf-8\" standalone=\"no\"?>\r\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\r\n  \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\r\n<svg height=\"280.963594pt\" version=\"1.1\" viewBox=\"0 0 388.964375 280.963594\" width=\"388.964375pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\r\n <metadata>\r\n  <rdf:RDF xmlns:cc=\"http://creativecommons.org/ns#\" xmlns:dc=\"http://purl.org/dc/elements/1.1/\" xmlns:rdf=\"http://www.w3.org/1999/02/22-rdf-syntax-ns#\">\r\n   <cc:Work>\r\n    <dc:type rdf:resource=\"http://purl.org/dc/dcmitype/StillImage\"/>\r\n    <dc:date>2021-06-15T19:59:42.012504</dc:date>\r\n    <dc:format>image/svg+xml</dc:format>\r\n    <dc:creator>\r\n     <cc:Agent>\r\n      <dc:title>Matplotlib v3.4.2, https://matplotlib.org/</dc:title>\r\n     </cc:Agent>\r\n    </dc:creator>\r\n   </cc:Work>\r\n  </rdf:RDF>\r\n </metadata>\r\n <defs>\r\n  <style type=\"text/css\">*{stroke-linecap:butt;stroke-linejoin:round;}</style>\r\n </defs>\r\n <g id=\"figure_1\">\r\n  <g id=\"patch_1\">\r\n   <path d=\"M 0 280.963594 \r\nL 388.964375 280.963594 \r\nL 388.964375 0 \r\nL 0 0 \r\nz\r\n\" style=\"fill:#ffffff;\"/>\r\n  </g>\r\n  <g id=\"axes_1\">\r\n   <g id=\"patch_2\">\r\n    <path d=\"M 46.964375 239.229375 \r\nL 381.764375 239.229375 \r\nL 381.764375 21.789375 \r\nL 46.964375 21.789375 \r\nz\r\n\" style=\"fill:#ffffff;\"/>\r\n   </g>\r\n   <g id=\"matplotlib.axis_1\">\r\n    <g id=\"xtick_1\">\r\n     <g id=\"line2d_1\">\r\n      <path clip-path=\"url(#p9b01c13afe)\" d=\"M 62.182557 239.229375 \r\nL 62.182557 21.789375 \r\n\" style=\"fill:none;stroke:#cccccc;stroke-linecap:round;\"/>\r\n     </g>\r\n     <g id=\"text_1\">\r\n      <!-- 0.0 -->\r\n      <g style=\"fill:#262626;\" transform=\"translate(54.537557 256.602969)scale(0.11 -0.11)\">\r\n       <defs>\r\n        <path d=\"M 266 2259 \r\nQ 266 3072 433 3567 \r\nQ 600 4063 929 4331 \r\nQ 1259 4600 1759 4600 \r\nQ 2128 4600 2406 4451 \r\nQ 2684 4303 2865 4023 \r\nQ 3047 3744 3150 3342 \r\nQ 3253 2941 3253 2259 \r\nQ 3253 1453 3087 958 \r\nQ 2922 463 2592 192 \r\nQ 2263 -78 1759 -78 \r\nQ 1097 -78 719 397 \r\nQ 266 969 266 2259 \r\nz\r\nM 844 2259 \r\nQ 844 1131 1108 757 \r\nQ 1372 384 1759 384 \r\nQ 2147 384 2411 759 \r\nQ 2675 1134 2675 2259 \r\nQ 2675 3391 2411 3762 \r\nQ 2147 4134 1753 4134 \r\nQ 1366 4134 1134 3806 \r\nQ 844 3388 844 2259 \r\nz\r\n\" id=\"ArialMT-30\" transform=\"scale(0.015625)\"/>\r\n        <path d=\"M 581 0 \r\nL 581 641 \r\nL 1222 641 \r\nL 1222 0 \r\nL 581 0 \r\nz\r\n\" id=\"ArialMT-2e\" transform=\"scale(0.015625)\"/>\r\n       </defs>\r\n       <use xlink:href=\"#ArialMT-30\"/>\r\n       <use x=\"55.615234\" xlink:href=\"#ArialMT-2e\"/>\r\n       <use x=\"83.398438\" xlink:href=\"#ArialMT-30\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_2\">\r\n     <g id=\"line2d_2\">\r\n      <path clip-path=\"url(#p9b01c13afe)\" d=\"M 102.230404 239.229375 \r\nL 102.230404 21.789375 \r\n\" style=\"fill:none;stroke:#cccccc;stroke-linecap:round;\"/>\r\n     </g>\r\n     <g id=\"text_2\">\r\n      <!-- 2.5 -->\r\n      <g style=\"fill:#262626;\" transform=\"translate(94.585404 256.602969)scale(0.11 -0.11)\">\r\n       <defs>\r\n        <path d=\"M 3222 541 \r\nL 3222 0 \r\nL 194 0 \r\nQ 188 203 259 391 \r\nQ 375 700 629 1000 \r\nQ 884 1300 1366 1694 \r\nQ 2113 2306 2375 2664 \r\nQ 2638 3022 2638 3341 \r\nQ 2638 3675 2398 3904 \r\nQ 2159 4134 1775 4134 \r\nQ 1369 4134 1125 3890 \r\nQ 881 3647 878 3216 \r\nL 300 3275 \r\nQ 359 3922 746 4261 \r\nQ 1134 4600 1788 4600 \r\nQ 2447 4600 2831 4234 \r\nQ 3216 3869 3216 3328 \r\nQ 3216 3053 3103 2787 \r\nQ 2991 2522 2730 2228 \r\nQ 2469 1934 1863 1422 \r\nQ 1356 997 1212 845 \r\nQ 1069 694 975 541 \r\nL 3222 541 \r\nz\r\n\" id=\"ArialMT-32\" transform=\"scale(0.015625)\"/>\r\n        <path d=\"M 266 1200 \r\nL 856 1250 \r\nQ 922 819 1161 601 \r\nQ 1400 384 1738 384 \r\nQ 2144 384 2425 690 \r\nQ 2706 997 2706 1503 \r\nQ 2706 1984 2436 2262 \r\nQ 2166 2541 1728 2541 \r\nQ 1456 2541 1237 2417 \r\nQ 1019 2294 894 2097 \r\nL 366 2166 \r\nL 809 4519 \r\nL 3088 4519 \r\nL 3088 3981 \r\nL 1259 3981 \r\nL 1013 2750 \r\nQ 1425 3038 1878 3038 \r\nQ 2478 3038 2890 2622 \r\nQ 3303 2206 3303 1553 \r\nQ 3303 931 2941 478 \r\nQ 2500 -78 1738 -78 \r\nQ 1113 -78 717 272 \r\nQ 322 622 266 1200 \r\nz\r\n\" id=\"ArialMT-35\" transform=\"scale(0.015625)\"/>\r\n       </defs>\r\n       <use xlink:href=\"#ArialMT-32\"/>\r\n       <use x=\"55.615234\" xlink:href=\"#ArialMT-2e\"/>\r\n       <use x=\"83.398438\" xlink:href=\"#ArialMT-35\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_3\">\r\n     <g id=\"line2d_3\">\r\n      <path clip-path=\"url(#p9b01c13afe)\" d=\"M 142.278251 239.229375 \r\nL 142.278251 21.789375 \r\n\" style=\"fill:none;stroke:#cccccc;stroke-linecap:round;\"/>\r\n     </g>\r\n     <g id=\"text_3\">\r\n      <!-- 5.0 -->\r\n      <g style=\"fill:#262626;\" transform=\"translate(134.633251 256.602969)scale(0.11 -0.11)\">\r\n       <use xlink:href=\"#ArialMT-35\"/>\r\n       <use x=\"55.615234\" xlink:href=\"#ArialMT-2e\"/>\r\n       <use x=\"83.398438\" xlink:href=\"#ArialMT-30\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_4\">\r\n     <g id=\"line2d_4\">\r\n      <path clip-path=\"url(#p9b01c13afe)\" d=\"M 182.326097 239.229375 \r\nL 182.326097 21.789375 \r\n\" style=\"fill:none;stroke:#cccccc;stroke-linecap:round;\"/>\r\n     </g>\r\n     <g id=\"text_4\">\r\n      <!-- 7.5 -->\r\n      <g style=\"fill:#262626;\" transform=\"translate(174.681097 256.602969)scale(0.11 -0.11)\">\r\n       <defs>\r\n        <path d=\"M 303 3981 \r\nL 303 4522 \r\nL 3269 4522 \r\nL 3269 4084 \r\nQ 2831 3619 2401 2847 \r\nQ 1972 2075 1738 1259 \r\nQ 1569 684 1522 0 \r\nL 944 0 \r\nQ 953 541 1156 1306 \r\nQ 1359 2072 1739 2783 \r\nQ 2119 3494 2547 3981 \r\nL 303 3981 \r\nz\r\n\" id=\"ArialMT-37\" transform=\"scale(0.015625)\"/>\r\n       </defs>\r\n       <use xlink:href=\"#ArialMT-37\"/>\r\n       <use x=\"55.615234\" xlink:href=\"#ArialMT-2e\"/>\r\n       <use x=\"83.398438\" xlink:href=\"#ArialMT-35\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_5\">\r\n     <g id=\"line2d_5\">\r\n      <path clip-path=\"url(#p9b01c13afe)\" d=\"M 222.373944 239.229375 \r\nL 222.373944 21.789375 \r\n\" style=\"fill:none;stroke:#cccccc;stroke-linecap:round;\"/>\r\n     </g>\r\n     <g id=\"text_5\">\r\n      <!-- 10.0 -->\r\n      <g style=\"fill:#262626;\" transform=\"translate(211.670429 256.602969)scale(0.11 -0.11)\">\r\n       <defs>\r\n        <path d=\"M 2384 0 \r\nL 1822 0 \r\nL 1822 3584 \r\nQ 1619 3391 1289 3197 \r\nQ 959 3003 697 2906 \r\nL 697 3450 \r\nQ 1169 3672 1522 3987 \r\nQ 1875 4303 2022 4600 \r\nL 2384 4600 \r\nL 2384 0 \r\nz\r\n\" id=\"ArialMT-31\" transform=\"scale(0.015625)\"/>\r\n       </defs>\r\n       <use xlink:href=\"#ArialMT-31\"/>\r\n       <use x=\"55.615234\" xlink:href=\"#ArialMT-30\"/>\r\n       <use x=\"111.230469\" xlink:href=\"#ArialMT-2e\"/>\r\n       <use x=\"139.013672\" xlink:href=\"#ArialMT-30\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_6\">\r\n     <g id=\"line2d_6\">\r\n      <path clip-path=\"url(#p9b01c13afe)\" d=\"M 262.421791 239.229375 \r\nL 262.421791 21.789375 \r\n\" style=\"fill:none;stroke:#cccccc;stroke-linecap:round;\"/>\r\n     </g>\r\n     <g id=\"text_6\">\r\n      <!-- 12.5 -->\r\n      <g style=\"fill:#262626;\" transform=\"translate(251.718276 256.602969)scale(0.11 -0.11)\">\r\n       <use xlink:href=\"#ArialMT-31\"/>\r\n       <use x=\"55.615234\" xlink:href=\"#ArialMT-32\"/>\r\n       <use x=\"111.230469\" xlink:href=\"#ArialMT-2e\"/>\r\n       <use x=\"139.013672\" xlink:href=\"#ArialMT-35\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_7\">\r\n     <g id=\"line2d_7\">\r\n      <path clip-path=\"url(#p9b01c13afe)\" d=\"M 302.469638 239.229375 \r\nL 302.469638 21.789375 \r\n\" style=\"fill:none;stroke:#cccccc;stroke-linecap:round;\"/>\r\n     </g>\r\n     <g id=\"text_7\">\r\n      <!-- 15.0 -->\r\n      <g style=\"fill:#262626;\" transform=\"translate(291.766123 256.602969)scale(0.11 -0.11)\">\r\n       <use xlink:href=\"#ArialMT-31\"/>\r\n       <use x=\"55.615234\" xlink:href=\"#ArialMT-35\"/>\r\n       <use x=\"111.230469\" xlink:href=\"#ArialMT-2e\"/>\r\n       <use x=\"139.013672\" xlink:href=\"#ArialMT-30\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_8\">\r\n     <g id=\"line2d_8\">\r\n      <path clip-path=\"url(#p9b01c13afe)\" d=\"M 342.517485 239.229375 \r\nL 342.517485 21.789375 \r\n\" style=\"fill:none;stroke:#cccccc;stroke-linecap:round;\"/>\r\n     </g>\r\n     <g id=\"text_8\">\r\n      <!-- 17.5 -->\r\n      <g style=\"fill:#262626;\" transform=\"translate(331.813969 256.602969)scale(0.11 -0.11)\">\r\n       <use xlink:href=\"#ArialMT-31\"/>\r\n       <use x=\"55.615234\" xlink:href=\"#ArialMT-37\"/>\r\n       <use x=\"111.230469\" xlink:href=\"#ArialMT-2e\"/>\r\n       <use x=\"139.013672\" xlink:href=\"#ArialMT-35\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"text_9\">\r\n     <!-- epoch -->\r\n     <g style=\"fill:#262626;\" transform=\"translate(198.018125 271.378594)scale(0.12 -0.12)\">\r\n      <defs>\r\n       <path d=\"M 2694 1069 \r\nL 3275 997 \r\nQ 3138 488 2766 206 \r\nQ 2394 -75 1816 -75 \r\nQ 1088 -75 661 373 \r\nQ 234 822 234 1631 \r\nQ 234 2469 665 2931 \r\nQ 1097 3394 1784 3394 \r\nQ 2450 3394 2872 2941 \r\nQ 3294 2488 3294 1666 \r\nQ 3294 1616 3291 1516 \r\nL 816 1516 \r\nQ 847 969 1125 678 \r\nQ 1403 388 1819 388 \r\nQ 2128 388 2347 550 \r\nQ 2566 713 2694 1069 \r\nz\r\nM 847 1978 \r\nL 2700 1978 \r\nQ 2663 2397 2488 2606 \r\nQ 2219 2931 1791 2931 \r\nQ 1403 2931 1139 2672 \r\nQ 875 2413 847 1978 \r\nz\r\n\" id=\"ArialMT-65\" transform=\"scale(0.015625)\"/>\r\n       <path d=\"M 422 -1272 \r\nL 422 3319 \r\nL 934 3319 \r\nL 934 2888 \r\nQ 1116 3141 1344 3267 \r\nQ 1572 3394 1897 3394 \r\nQ 2322 3394 2647 3175 \r\nQ 2972 2956 3137 2557 \r\nQ 3303 2159 3303 1684 \r\nQ 3303 1175 3120 767 \r\nQ 2938 359 2589 142 \r\nQ 2241 -75 1856 -75 \r\nQ 1575 -75 1351 44 \r\nQ 1128 163 984 344 \r\nL 984 -1272 \r\nL 422 -1272 \r\nz\r\nM 931 1641 \r\nQ 931 1000 1190 694 \r\nQ 1450 388 1819 388 \r\nQ 2194 388 2461 705 \r\nQ 2728 1022 2728 1688 \r\nQ 2728 2322 2467 2637 \r\nQ 2206 2953 1844 2953 \r\nQ 1484 2953 1207 2617 \r\nQ 931 2281 931 1641 \r\nz\r\n\" id=\"ArialMT-70\" transform=\"scale(0.015625)\"/>\r\n       <path d=\"M 213 1659 \r\nQ 213 2581 725 3025 \r\nQ 1153 3394 1769 3394 \r\nQ 2453 3394 2887 2945 \r\nQ 3322 2497 3322 1706 \r\nQ 3322 1066 3130 698 \r\nQ 2938 331 2570 128 \r\nQ 2203 -75 1769 -75 \r\nQ 1072 -75 642 372 \r\nQ 213 819 213 1659 \r\nz\r\nM 791 1659 \r\nQ 791 1022 1069 705 \r\nQ 1347 388 1769 388 \r\nQ 2188 388 2466 706 \r\nQ 2744 1025 2744 1678 \r\nQ 2744 2294 2464 2611 \r\nQ 2184 2928 1769 2928 \r\nQ 1347 2928 1069 2612 \r\nQ 791 2297 791 1659 \r\nz\r\n\" id=\"ArialMT-6f\" transform=\"scale(0.015625)\"/>\r\n       <path d=\"M 2588 1216 \r\nL 3141 1144 \r\nQ 3050 572 2676 248 \r\nQ 2303 -75 1759 -75 \r\nQ 1078 -75 664 370 \r\nQ 250 816 250 1647 \r\nQ 250 2184 428 2587 \r\nQ 606 2991 970 3192 \r\nQ 1334 3394 1763 3394 \r\nQ 2303 3394 2647 3120 \r\nQ 2991 2847 3088 2344 \r\nL 2541 2259 \r\nQ 2463 2594 2264 2762 \r\nQ 2066 2931 1784 2931 \r\nQ 1359 2931 1093 2626 \r\nQ 828 2322 828 1663 \r\nQ 828 994 1084 691 \r\nQ 1341 388 1753 388 \r\nQ 2084 388 2306 591 \r\nQ 2528 794 2588 1216 \r\nz\r\n\" id=\"ArialMT-63\" transform=\"scale(0.015625)\"/>\r\n       <path d=\"M 422 0 \r\nL 422 4581 \r\nL 984 4581 \r\nL 984 2938 \r\nQ 1378 3394 1978 3394 \r\nQ 2347 3394 2619 3248 \r\nQ 2891 3103 3008 2847 \r\nQ 3125 2591 3125 2103 \r\nL 3125 0 \r\nL 2563 0 \r\nL 2563 2103 \r\nQ 2563 2525 2380 2717 \r\nQ 2197 2909 1863 2909 \r\nQ 1613 2909 1392 2779 \r\nQ 1172 2650 1078 2428 \r\nQ 984 2206 984 1816 \r\nL 984 0 \r\nL 422 0 \r\nz\r\n\" id=\"ArialMT-68\" transform=\"scale(0.015625)\"/>\r\n      </defs>\r\n      <use xlink:href=\"#ArialMT-65\"/>\r\n      <use x=\"55.615234\" xlink:href=\"#ArialMT-70\"/>\r\n      <use x=\"111.230469\" xlink:href=\"#ArialMT-6f\"/>\r\n      <use x=\"166.845703\" xlink:href=\"#ArialMT-63\"/>\r\n      <use x=\"216.845703\" xlink:href=\"#ArialMT-68\"/>\r\n     </g>\r\n    </g>\r\n   </g>\r\n   <g id=\"matplotlib.axis_2\">\r\n    <g id=\"ytick_1\">\r\n     <g id=\"line2d_9\">\r\n      <path clip-path=\"url(#p9b01c13afe)\" d=\"M 46.964375 231.267622 \r\nL 381.764375 231.267622 \r\n\" style=\"fill:none;stroke:#cccccc;stroke-linecap:round;\"/>\r\n     </g>\r\n     <g id=\"text_10\">\r\n      <!-- 0.0 -->\r\n      <g style=\"fill:#262626;\" transform=\"translate(22.174375 235.204419)scale(0.11 -0.11)\">\r\n       <use xlink:href=\"#ArialMT-30\"/>\r\n       <use x=\"55.615234\" xlink:href=\"#ArialMT-2e\"/>\r\n       <use x=\"83.398438\" xlink:href=\"#ArialMT-30\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"ytick_2\">\r\n     <g id=\"line2d_10\">\r\n      <path clip-path=\"url(#p9b01c13afe)\" d=\"M 46.964375 202.278251 \r\nL 381.764375 202.278251 \r\n\" style=\"fill:none;stroke:#cccccc;stroke-linecap:round;\"/>\r\n     </g>\r\n     <g id=\"text_11\">\r\n      <!-- 0.1 -->\r\n      <g style=\"fill:#262626;\" transform=\"translate(22.174375 206.215048)scale(0.11 -0.11)\">\r\n       <use xlink:href=\"#ArialMT-30\"/>\r\n       <use x=\"55.615234\" xlink:href=\"#ArialMT-2e\"/>\r\n       <use x=\"83.398438\" xlink:href=\"#ArialMT-31\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"ytick_3\">\r\n     <g id=\"line2d_11\">\r\n      <path clip-path=\"url(#p9b01c13afe)\" d=\"M 46.964375 173.288881 \r\nL 381.764375 173.288881 \r\n\" style=\"fill:none;stroke:#cccccc;stroke-linecap:round;\"/>\r\n     </g>\r\n     <g id=\"text_12\">\r\n      <!-- 0.2 -->\r\n      <g style=\"fill:#262626;\" transform=\"translate(22.174375 177.225678)scale(0.11 -0.11)\">\r\n       <use xlink:href=\"#ArialMT-30\"/>\r\n       <use x=\"55.615234\" xlink:href=\"#ArialMT-2e\"/>\r\n       <use x=\"83.398438\" xlink:href=\"#ArialMT-32\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"ytick_4\">\r\n     <g id=\"line2d_12\">\r\n      <path clip-path=\"url(#p9b01c13afe)\" d=\"M 46.964375 144.299511 \r\nL 381.764375 144.299511 \r\n\" style=\"fill:none;stroke:#cccccc;stroke-linecap:round;\"/>\r\n     </g>\r\n     <g id=\"text_13\">\r\n      <!-- 0.3 -->\r\n      <g style=\"fill:#262626;\" transform=\"translate(22.174375 148.236308)scale(0.11 -0.11)\">\r\n       <defs>\r\n        <path d=\"M 269 1209 \r\nL 831 1284 \r\nQ 928 806 1161 595 \r\nQ 1394 384 1728 384 \r\nQ 2125 384 2398 659 \r\nQ 2672 934 2672 1341 \r\nQ 2672 1728 2419 1979 \r\nQ 2166 2231 1775 2231 \r\nQ 1616 2231 1378 2169 \r\nL 1441 2663 \r\nQ 1497 2656 1531 2656 \r\nQ 1891 2656 2178 2843 \r\nQ 2466 3031 2466 3422 \r\nQ 2466 3731 2256 3934 \r\nQ 2047 4138 1716 4138 \r\nQ 1388 4138 1169 3931 \r\nQ 950 3725 888 3313 \r\nL 325 3413 \r\nQ 428 3978 793 4289 \r\nQ 1159 4600 1703 4600 \r\nQ 2078 4600 2393 4439 \r\nQ 2709 4278 2876 4000 \r\nQ 3044 3722 3044 3409 \r\nQ 3044 3113 2884 2869 \r\nQ 2725 2625 2413 2481 \r\nQ 2819 2388 3044 2092 \r\nQ 3269 1797 3269 1353 \r\nQ 3269 753 2831 336 \r\nQ 2394 -81 1725 -81 \r\nQ 1122 -81 723 278 \r\nQ 325 638 269 1209 \r\nz\r\n\" id=\"ArialMT-33\" transform=\"scale(0.015625)\"/>\r\n       </defs>\r\n       <use xlink:href=\"#ArialMT-30\"/>\r\n       <use x=\"55.615234\" xlink:href=\"#ArialMT-2e\"/>\r\n       <use x=\"83.398438\" xlink:href=\"#ArialMT-33\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"ytick_5\">\r\n     <g id=\"line2d_13\">\r\n      <path clip-path=\"url(#p9b01c13afe)\" d=\"M 46.964375 115.31014 \r\nL 381.764375 115.31014 \r\n\" style=\"fill:none;stroke:#cccccc;stroke-linecap:round;\"/>\r\n     </g>\r\n     <g id=\"text_14\">\r\n      <!-- 0.4 -->\r\n      <g style=\"fill:#262626;\" transform=\"translate(22.174375 119.246937)scale(0.11 -0.11)\">\r\n       <defs>\r\n        <path d=\"M 2069 0 \r\nL 2069 1097 \r\nL 81 1097 \r\nL 81 1613 \r\nL 2172 4581 \r\nL 2631 4581 \r\nL 2631 1613 \r\nL 3250 1613 \r\nL 3250 1097 \r\nL 2631 1097 \r\nL 2631 0 \r\nL 2069 0 \r\nz\r\nM 2069 1613 \r\nL 2069 3678 \r\nL 634 1613 \r\nL 2069 1613 \r\nz\r\n\" id=\"ArialMT-34\" transform=\"scale(0.015625)\"/>\r\n       </defs>\r\n       <use xlink:href=\"#ArialMT-30\"/>\r\n       <use x=\"55.615234\" xlink:href=\"#ArialMT-2e\"/>\r\n       <use x=\"83.398438\" xlink:href=\"#ArialMT-34\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"ytick_6\">\r\n     <g id=\"line2d_14\">\r\n      <path clip-path=\"url(#p9b01c13afe)\" d=\"M 46.964375 86.32077 \r\nL 381.764375 86.32077 \r\n\" style=\"fill:none;stroke:#cccccc;stroke-linecap:round;\"/>\r\n     </g>\r\n     <g id=\"text_15\">\r\n      <!-- 0.5 -->\r\n      <g style=\"fill:#262626;\" transform=\"translate(22.174375 90.257567)scale(0.11 -0.11)\">\r\n       <use xlink:href=\"#ArialMT-30\"/>\r\n       <use x=\"55.615234\" xlink:href=\"#ArialMT-2e\"/>\r\n       <use x=\"83.398438\" xlink:href=\"#ArialMT-35\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"ytick_7\">\r\n     <g id=\"line2d_15\">\r\n      <path clip-path=\"url(#p9b01c13afe)\" d=\"M 46.964375 57.3314 \r\nL 381.764375 57.3314 \r\n\" style=\"fill:none;stroke:#cccccc;stroke-linecap:round;\"/>\r\n     </g>\r\n     <g id=\"text_16\">\r\n      <!-- 0.6 -->\r\n      <g style=\"fill:#262626;\" transform=\"translate(22.174375 61.268196)scale(0.11 -0.11)\">\r\n       <defs>\r\n        <path d=\"M 3184 3459 \r\nL 2625 3416 \r\nQ 2550 3747 2413 3897 \r\nQ 2184 4138 1850 4138 \r\nQ 1581 4138 1378 3988 \r\nQ 1113 3794 959 3422 \r\nQ 806 3050 800 2363 \r\nQ 1003 2672 1297 2822 \r\nQ 1591 2972 1913 2972 \r\nQ 2475 2972 2870 2558 \r\nQ 3266 2144 3266 1488 \r\nQ 3266 1056 3080 686 \r\nQ 2894 316 2569 119 \r\nQ 2244 -78 1831 -78 \r\nQ 1128 -78 684 439 \r\nQ 241 956 241 2144 \r\nQ 241 3472 731 4075 \r\nQ 1159 4600 1884 4600 \r\nQ 2425 4600 2770 4297 \r\nQ 3116 3994 3184 3459 \r\nz\r\nM 888 1484 \r\nQ 888 1194 1011 928 \r\nQ 1134 663 1356 523 \r\nQ 1578 384 1822 384 \r\nQ 2178 384 2434 671 \r\nQ 2691 959 2691 1453 \r\nQ 2691 1928 2437 2201 \r\nQ 2184 2475 1800 2475 \r\nQ 1419 2475 1153 2201 \r\nQ 888 1928 888 1484 \r\nz\r\n\" id=\"ArialMT-36\" transform=\"scale(0.015625)\"/>\r\n       </defs>\r\n       <use xlink:href=\"#ArialMT-30\"/>\r\n       <use x=\"55.615234\" xlink:href=\"#ArialMT-2e\"/>\r\n       <use x=\"83.398438\" xlink:href=\"#ArialMT-36\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"ytick_8\">\r\n     <g id=\"line2d_16\">\r\n      <path clip-path=\"url(#p9b01c13afe)\" d=\"M 46.964375 28.342029 \r\nL 381.764375 28.342029 \r\n\" style=\"fill:none;stroke:#cccccc;stroke-linecap:round;\"/>\r\n     </g>\r\n     <g id=\"text_17\">\r\n      <!-- 0.7 -->\r\n      <g style=\"fill:#262626;\" transform=\"translate(22.174375 32.278826)scale(0.11 -0.11)\">\r\n       <use xlink:href=\"#ArialMT-30\"/>\r\n       <use x=\"55.615234\" xlink:href=\"#ArialMT-2e\"/>\r\n       <use x=\"83.398438\" xlink:href=\"#ArialMT-37\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"text_18\">\r\n     <!-- loss -->\r\n     <g style=\"fill:#262626;\" transform=\"translate(15.789375 141.179063)rotate(-90)scale(0.12 -0.12)\">\r\n      <defs>\r\n       <path d=\"M 409 0 \r\nL 409 4581 \r\nL 972 4581 \r\nL 972 0 \r\nL 409 0 \r\nz\r\n\" id=\"ArialMT-6c\" transform=\"scale(0.015625)\"/>\r\n       <path d=\"M 197 991 \r\nL 753 1078 \r\nQ 800 744 1014 566 \r\nQ 1228 388 1613 388 \r\nQ 2000 388 2187 545 \r\nQ 2375 703 2375 916 \r\nQ 2375 1106 2209 1216 \r\nQ 2094 1291 1634 1406 \r\nQ 1016 1563 777 1677 \r\nQ 538 1791 414 1992 \r\nQ 291 2194 291 2438 \r\nQ 291 2659 392 2848 \r\nQ 494 3038 669 3163 \r\nQ 800 3259 1026 3326 \r\nQ 1253 3394 1513 3394 \r\nQ 1903 3394 2198 3281 \r\nQ 2494 3169 2634 2976 \r\nQ 2775 2784 2828 2463 \r\nL 2278 2388 \r\nQ 2241 2644 2061 2787 \r\nQ 1881 2931 1553 2931 \r\nQ 1166 2931 1000 2803 \r\nQ 834 2675 834 2503 \r\nQ 834 2394 903 2306 \r\nQ 972 2216 1119 2156 \r\nQ 1203 2125 1616 2013 \r\nQ 2213 1853 2448 1751 \r\nQ 2684 1650 2818 1456 \r\nQ 2953 1263 2953 975 \r\nQ 2953 694 2789 445 \r\nQ 2625 197 2315 61 \r\nQ 2006 -75 1616 -75 \r\nQ 969 -75 630 194 \r\nQ 291 463 197 991 \r\nz\r\n\" id=\"ArialMT-73\" transform=\"scale(0.015625)\"/>\r\n      </defs>\r\n      <use xlink:href=\"#ArialMT-6c\"/>\r\n      <use x=\"22.216797\" xlink:href=\"#ArialMT-6f\"/>\r\n      <use x=\"77.832031\" xlink:href=\"#ArialMT-73\"/>\r\n      <use x=\"127.832031\" xlink:href=\"#ArialMT-73\"/>\r\n     </g>\r\n    </g>\r\n   </g>\r\n   <g id=\"line2d_17\">\r\n    <path clip-path=\"url(#p9b01c13afe)\" d=\"M 62.182557 31.673011 \r\nL 78.201696 42.340313 \r\nL 94.220834 80.795858 \r\nL 110.239973 133.161189 \r\nL 126.259112 157.573632 \r\nL 142.278251 172.360855 \r\nL 158.297389 184.078776 \r\nL 174.316528 193.346426 \r\nL 190.335667 201.929615 \r\nL 206.354806 208.882578 \r\nL 222.373944 214.524055 \r\nL 238.393083 218.800381 \r\nL 254.412222 221.941079 \r\nL 270.431361 224.70397 \r\nL 286.450499 226.283708 \r\nL 302.469638 227.210949 \r\nL 318.488777 228.067888 \r\nL 334.507916 228.74947 \r\nL 350.527054 229.082701 \r\nL 366.546193 229.345739 \r\n\" style=\"fill:none;stroke:#4c72b0;stroke-linecap:round;stroke-width:1.5;\"/>\r\n   </g>\r\n   <g id=\"line2d_18\">\r\n    <path clip-path=\"url(#p9b01c13afe)\" d=\"M 62.182557 33.871696 \r\nL 78.201696 50.717108 \r\nL 94.220834 101.904779 \r\nL 110.239973 138.714862 \r\nL 126.259112 147.621147 \r\nL 142.278251 151.239052 \r\nL 158.297389 152.657641 \r\nL 174.316528 153.059473 \r\nL 190.335667 151.202204 \r\nL 206.354806 148.504285 \r\nL 222.373944 143.345723 \r\nL 238.393083 139.240498 \r\nL 254.412222 134.424328 \r\nL 270.431361 129.49625 \r\nL 286.450499 124.631128 \r\nL 302.469638 119.959549 \r\nL 318.488777 114.013746 \r\nL 334.507916 111.369548 \r\nL 350.527054 107.876095 \r\nL 366.546193 105.134382 \r\n\" style=\"fill:none;stroke:#dd8452;stroke-linecap:round;stroke-width:1.5;\"/>\r\n   </g>\r\n   <g id=\"patch_3\">\r\n    <path d=\"M 46.964375 239.229375 \r\nL 46.964375 21.789375 \r\n\" style=\"fill:none;stroke:#cccccc;stroke-linecap:square;stroke-linejoin:miter;stroke-width:1.25;\"/>\r\n   </g>\r\n   <g id=\"patch_4\">\r\n    <path d=\"M 381.764375 239.229375 \r\nL 381.764375 21.789375 \r\n\" style=\"fill:none;stroke:#cccccc;stroke-linecap:square;stroke-linejoin:miter;stroke-width:1.25;\"/>\r\n   </g>\r\n   <g id=\"patch_5\">\r\n    <path d=\"M 46.964375 239.229375 \r\nL 381.764375 239.229375 \r\n\" style=\"fill:none;stroke:#cccccc;stroke-linecap:square;stroke-linejoin:miter;stroke-width:1.25;\"/>\r\n   </g>\r\n   <g id=\"patch_6\">\r\n    <path d=\"M 46.964375 21.789375 \r\nL 381.764375 21.789375 \r\n\" style=\"fill:none;stroke:#cccccc;stroke-linecap:square;stroke-linejoin:miter;stroke-width:1.25;\"/>\r\n   </g>\r\n   <g id=\"text_19\">\r\n    <!-- model loss -->\r\n    <g style=\"fill:#262626;\" transform=\"translate(185.687187 15.789375)scale(0.12 -0.12)\">\r\n     <defs>\r\n      <path d=\"M 422 0 \r\nL 422 3319 \r\nL 925 3319 \r\nL 925 2853 \r\nQ 1081 3097 1340 3245 \r\nQ 1600 3394 1931 3394 \r\nQ 2300 3394 2536 3241 \r\nQ 2772 3088 2869 2813 \r\nQ 3263 3394 3894 3394 \r\nQ 4388 3394 4653 3120 \r\nQ 4919 2847 4919 2278 \r\nL 4919 0 \r\nL 4359 0 \r\nL 4359 2091 \r\nQ 4359 2428 4304 2576 \r\nQ 4250 2725 4106 2815 \r\nQ 3963 2906 3769 2906 \r\nQ 3419 2906 3187 2673 \r\nQ 2956 2441 2956 1928 \r\nL 2956 0 \r\nL 2394 0 \r\nL 2394 2156 \r\nQ 2394 2531 2256 2718 \r\nQ 2119 2906 1806 2906 \r\nQ 1569 2906 1367 2781 \r\nQ 1166 2656 1075 2415 \r\nQ 984 2175 984 1722 \r\nL 984 0 \r\nL 422 0 \r\nz\r\n\" id=\"ArialMT-6d\" transform=\"scale(0.015625)\"/>\r\n      <path d=\"M 2575 0 \r\nL 2575 419 \r\nQ 2259 -75 1647 -75 \r\nQ 1250 -75 917 144 \r\nQ 584 363 401 755 \r\nQ 219 1147 219 1656 \r\nQ 219 2153 384 2558 \r\nQ 550 2963 881 3178 \r\nQ 1213 3394 1622 3394 \r\nQ 1922 3394 2156 3267 \r\nQ 2391 3141 2538 2938 \r\nL 2538 4581 \r\nL 3097 4581 \r\nL 3097 0 \r\nL 2575 0 \r\nz\r\nM 797 1656 \r\nQ 797 1019 1065 703 \r\nQ 1334 388 1700 388 \r\nQ 2069 388 2326 689 \r\nQ 2584 991 2584 1609 \r\nQ 2584 2291 2321 2609 \r\nQ 2059 2928 1675 2928 \r\nQ 1300 2928 1048 2622 \r\nQ 797 2316 797 1656 \r\nz\r\n\" id=\"ArialMT-64\" transform=\"scale(0.015625)\"/>\r\n      <path id=\"ArialMT-20\" transform=\"scale(0.015625)\"/>\r\n     </defs>\r\n     <use xlink:href=\"#ArialMT-6d\"/>\r\n     <use x=\"83.300781\" xlink:href=\"#ArialMT-6f\"/>\r\n     <use x=\"138.916016\" xlink:href=\"#ArialMT-64\"/>\r\n     <use x=\"194.53125\" xlink:href=\"#ArialMT-65\"/>\r\n     <use x=\"250.146484\" xlink:href=\"#ArialMT-6c\"/>\r\n     <use x=\"272.363281\" xlink:href=\"#ArialMT-20\"/>\r\n     <use x=\"300.146484\" xlink:href=\"#ArialMT-6c\"/>\r\n     <use x=\"322.363281\" xlink:href=\"#ArialMT-6f\"/>\r\n     <use x=\"377.978516\" xlink:href=\"#ArialMT-73\"/>\r\n     <use x=\"427.978516\" xlink:href=\"#ArialMT-73\"/>\r\n    </g>\r\n   </g>\r\n   <g id=\"legend_1\">\r\n    <g id=\"patch_7\">\r\n     <path d=\"M 54.664375 61.709063 \r\nL 136.337656 61.709063 \r\nQ 138.537656 61.709063 138.537656 59.509063 \r\nL 138.537656 29.489375 \r\nQ 138.537656 27.289375 136.337656 27.289375 \r\nL 54.664375 27.289375 \r\nQ 52.464375 27.289375 52.464375 29.489375 \r\nL 52.464375 59.509063 \r\nQ 52.464375 61.709063 54.664375 61.709063 \r\nz\r\n\" style=\"fill:#ffffff;opacity:0.8;stroke:#cccccc;stroke-linejoin:miter;\"/>\r\n    </g>\r\n    <g id=\"line2d_19\">\r\n     <path d=\"M 56.864375 35.712969 \r\nL 78.864375 35.712969 \r\n\" style=\"fill:none;stroke:#4c72b0;stroke-linecap:round;stroke-width:1.5;\"/>\r\n    </g>\r\n    <g id=\"line2d_20\"/>\r\n    <g id=\"text_20\">\r\n     <!-- train -->\r\n     <g style=\"fill:#262626;\" transform=\"translate(87.664375 39.562969)scale(0.11 -0.11)\">\r\n      <defs>\r\n       <path d=\"M 1650 503 \r\nL 1731 6 \r\nQ 1494 -44 1306 -44 \r\nQ 1000 -44 831 53 \r\nQ 663 150 594 308 \r\nQ 525 466 525 972 \r\nL 525 2881 \r\nL 113 2881 \r\nL 113 3319 \r\nL 525 3319 \r\nL 525 4141 \r\nL 1084 4478 \r\nL 1084 3319 \r\nL 1650 3319 \r\nL 1650 2881 \r\nL 1084 2881 \r\nL 1084 941 \r\nQ 1084 700 1114 631 \r\nQ 1144 563 1211 522 \r\nQ 1278 481 1403 481 \r\nQ 1497 481 1650 503 \r\nz\r\n\" id=\"ArialMT-74\" transform=\"scale(0.015625)\"/>\r\n       <path d=\"M 416 0 \r\nL 416 3319 \r\nL 922 3319 \r\nL 922 2816 \r\nQ 1116 3169 1280 3281 \r\nQ 1444 3394 1641 3394 \r\nQ 1925 3394 2219 3213 \r\nL 2025 2691 \r\nQ 1819 2813 1613 2813 \r\nQ 1428 2813 1281 2702 \r\nQ 1134 2591 1072 2394 \r\nQ 978 2094 978 1738 \r\nL 978 0 \r\nL 416 0 \r\nz\r\n\" id=\"ArialMT-72\" transform=\"scale(0.015625)\"/>\r\n       <path d=\"M 2588 409 \r\nQ 2275 144 1986 34 \r\nQ 1697 -75 1366 -75 \r\nQ 819 -75 525 192 \r\nQ 231 459 231 875 \r\nQ 231 1119 342 1320 \r\nQ 453 1522 633 1644 \r\nQ 813 1766 1038 1828 \r\nQ 1203 1872 1538 1913 \r\nQ 2219 1994 2541 2106 \r\nQ 2544 2222 2544 2253 \r\nQ 2544 2597 2384 2738 \r\nQ 2169 2928 1744 2928 \r\nQ 1347 2928 1158 2789 \r\nQ 969 2650 878 2297 \r\nL 328 2372 \r\nQ 403 2725 575 2942 \r\nQ 747 3159 1072 3276 \r\nQ 1397 3394 1825 3394 \r\nQ 2250 3394 2515 3294 \r\nQ 2781 3194 2906 3042 \r\nQ 3031 2891 3081 2659 \r\nQ 3109 2516 3109 2141 \r\nL 3109 1391 \r\nQ 3109 606 3145 398 \r\nQ 3181 191 3288 0 \r\nL 2700 0 \r\nQ 2613 175 2588 409 \r\nz\r\nM 2541 1666 \r\nQ 2234 1541 1622 1453 \r\nQ 1275 1403 1131 1340 \r\nQ 988 1278 909 1158 \r\nQ 831 1038 831 891 \r\nQ 831 666 1001 516 \r\nQ 1172 366 1500 366 \r\nQ 1825 366 2078 508 \r\nQ 2331 650 2450 897 \r\nQ 2541 1088 2541 1459 \r\nL 2541 1666 \r\nz\r\n\" id=\"ArialMT-61\" transform=\"scale(0.015625)\"/>\r\n       <path d=\"M 425 3934 \r\nL 425 4581 \r\nL 988 4581 \r\nL 988 3934 \r\nL 425 3934 \r\nz\r\nM 425 0 \r\nL 425 3319 \r\nL 988 3319 \r\nL 988 0 \r\nL 425 0 \r\nz\r\n\" id=\"ArialMT-69\" transform=\"scale(0.015625)\"/>\r\n       <path d=\"M 422 0 \r\nL 422 3319 \r\nL 928 3319 \r\nL 928 2847 \r\nQ 1294 3394 1984 3394 \r\nQ 2284 3394 2536 3286 \r\nQ 2788 3178 2913 3003 \r\nQ 3038 2828 3088 2588 \r\nQ 3119 2431 3119 2041 \r\nL 3119 0 \r\nL 2556 0 \r\nL 2556 2019 \r\nQ 2556 2363 2490 2533 \r\nQ 2425 2703 2258 2804 \r\nQ 2091 2906 1866 2906 \r\nQ 1506 2906 1245 2678 \r\nQ 984 2450 984 1813 \r\nL 984 0 \r\nL 422 0 \r\nz\r\n\" id=\"ArialMT-6e\" transform=\"scale(0.015625)\"/>\r\n      </defs>\r\n      <use xlink:href=\"#ArialMT-74\"/>\r\n      <use x=\"27.783203\" xlink:href=\"#ArialMT-72\"/>\r\n      <use x=\"61.083984\" xlink:href=\"#ArialMT-61\"/>\r\n      <use x=\"116.699219\" xlink:href=\"#ArialMT-69\"/>\r\n      <use x=\"138.916016\" xlink:href=\"#ArialMT-6e\"/>\r\n     </g>\r\n    </g>\r\n    <g id=\"line2d_21\">\r\n     <path d=\"M 56.864375 51.272813 \r\nL 78.864375 51.272813 \r\n\" style=\"fill:none;stroke:#dd8452;stroke-linecap:round;stroke-width:1.5;\"/>\r\n    </g>\r\n    <g id=\"line2d_22\"/>\r\n    <g id=\"text_21\">\r\n     <!-- validation -->\r\n     <g style=\"fill:#262626;\" transform=\"translate(87.664375 55.122813)scale(0.11 -0.11)\">\r\n      <defs>\r\n       <path d=\"M 1344 0 \r\nL 81 3319 \r\nL 675 3319 \r\nL 1388 1331 \r\nQ 1503 1009 1600 663 \r\nQ 1675 925 1809 1294 \r\nL 2547 3319 \r\nL 3125 3319 \r\nL 1869 0 \r\nL 1344 0 \r\nz\r\n\" id=\"ArialMT-76\" transform=\"scale(0.015625)\"/>\r\n      </defs>\r\n      <use xlink:href=\"#ArialMT-76\"/>\r\n      <use x=\"50\" xlink:href=\"#ArialMT-61\"/>\r\n      <use x=\"105.615234\" xlink:href=\"#ArialMT-6c\"/>\r\n      <use x=\"127.832031\" xlink:href=\"#ArialMT-69\"/>\r\n      <use x=\"150.048828\" xlink:href=\"#ArialMT-64\"/>\r\n      <use x=\"205.664062\" xlink:href=\"#ArialMT-61\"/>\r\n      <use x=\"261.279297\" xlink:href=\"#ArialMT-74\"/>\r\n      <use x=\"289.0625\" xlink:href=\"#ArialMT-69\"/>\r\n      <use x=\"311.279297\" xlink:href=\"#ArialMT-6f\"/>\r\n      <use x=\"366.894531\" xlink:href=\"#ArialMT-6e\"/>\r\n     </g>\r\n    </g>\r\n   </g>\r\n  </g>\r\n </g>\r\n <defs>\r\n  <clipPath id=\"p9b01c13afe\">\r\n   <rect height=\"217.44\" width=\"334.8\" x=\"46.964375\" y=\"21.789375\"/>\r\n  </clipPath>\r\n </defs>\r\n</svg>\r\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'validation'], loc='upper left')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "image/svg+xml": "<?xml version=\"1.0\" encoding=\"utf-8\" standalone=\"no\"?>\r\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\r\n  \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\r\n<svg height=\"320.349219pt\" version=\"1.1\" viewBox=\"0 0 708.79 320.349219\" width=\"708.79pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\r\n <metadata>\r\n  <rdf:RDF xmlns:cc=\"http://creativecommons.org/ns#\" xmlns:dc=\"http://purl.org/dc/elements/1.1/\" xmlns:rdf=\"http://www.w3.org/1999/02/22-rdf-syntax-ns#\">\r\n   <cc:Work>\r\n    <dc:type rdf:resource=\"http://purl.org/dc/dcmitype/StillImage\"/>\r\n    <dc:date>2021-06-15T19:59:54.635203</dc:date>\r\n    <dc:format>image/svg+xml</dc:format>\r\n    <dc:creator>\r\n     <cc:Agent>\r\n      <dc:title>Matplotlib v3.4.2, https://matplotlib.org/</dc:title>\r\n     </cc:Agent>\r\n    </dc:creator>\r\n   </cc:Work>\r\n  </rdf:RDF>\r\n </metadata>\r\n <defs>\r\n  <style type=\"text/css\">*{stroke-linecap:butt;stroke-linejoin:round;}</style>\r\n </defs>\r\n <g id=\"figure_1\">\r\n  <g id=\"patch_1\">\r\n   <path d=\"M 0 320.349219 \r\nL 708.79 320.349219 \r\nL 708.79 0 \r\nL 0 0 \r\nz\r\n\" style=\"fill:#ffffff;\"/>\r\n  </g>\r\n  <g id=\"axes_1\">\r\n   <g id=\"patch_2\">\r\n    <path d=\"M 31.99 293.589375 \r\nL 336.353636 293.589375 \r\nL 336.353636 21.789375 \r\nL 31.99 21.789375 \r\nz\r\n\" style=\"fill:#ffffff;\"/>\r\n   </g>\r\n   <g id=\"matplotlib.axis_1\">\r\n    <g id=\"xtick_1\">\r\n     <g id=\"line2d_1\">\r\n      <path clip-path=\"url(#pcadb55d9e4)\" d=\"M 67.668991 293.589375 \r\nL 67.668991 21.789375 \r\n\" style=\"fill:none;stroke:#cccccc;stroke-linecap:round;\"/>\r\n     </g>\r\n     <g id=\"text_1\">\r\n      <!-- 2.5 -->\r\n      <g style=\"fill:#262626;\" transform=\"translate(60.023991 310.962969)scale(0.11 -0.11)\">\r\n       <defs>\r\n        <path d=\"M 3222 541 \r\nL 3222 0 \r\nL 194 0 \r\nQ 188 203 259 391 \r\nQ 375 700 629 1000 \r\nQ 884 1300 1366 1694 \r\nQ 2113 2306 2375 2664 \r\nQ 2638 3022 2638 3341 \r\nQ 2638 3675 2398 3904 \r\nQ 2159 4134 1775 4134 \r\nQ 1369 4134 1125 3890 \r\nQ 881 3647 878 3216 \r\nL 300 3275 \r\nQ 359 3922 746 4261 \r\nQ 1134 4600 1788 4600 \r\nQ 2447 4600 2831 4234 \r\nQ 3216 3869 3216 3328 \r\nQ 3216 3053 3103 2787 \r\nQ 2991 2522 2730 2228 \r\nQ 2469 1934 1863 1422 \r\nQ 1356 997 1212 845 \r\nQ 1069 694 975 541 \r\nL 3222 541 \r\nz\r\n\" id=\"ArialMT-32\" transform=\"scale(0.015625)\"/>\r\n        <path d=\"M 581 0 \r\nL 581 641 \r\nL 1222 641 \r\nL 1222 0 \r\nL 581 0 \r\nz\r\n\" id=\"ArialMT-2e\" transform=\"scale(0.015625)\"/>\r\n        <path d=\"M 266 1200 \r\nL 856 1250 \r\nQ 922 819 1161 601 \r\nQ 1400 384 1738 384 \r\nQ 2144 384 2425 690 \r\nQ 2706 997 2706 1503 \r\nQ 2706 1984 2436 2262 \r\nQ 2166 2541 1728 2541 \r\nQ 1456 2541 1237 2417 \r\nQ 1019 2294 894 2097 \r\nL 366 2166 \r\nL 809 4519 \r\nL 3088 4519 \r\nL 3088 3981 \r\nL 1259 3981 \r\nL 1013 2750 \r\nQ 1425 3038 1878 3038 \r\nQ 2478 3038 2890 2622 \r\nQ 3303 2206 3303 1553 \r\nQ 3303 931 2941 478 \r\nQ 2500 -78 1738 -78 \r\nQ 1113 -78 717 272 \r\nQ 322 622 266 1200 \r\nz\r\n\" id=\"ArialMT-35\" transform=\"scale(0.015625)\"/>\r\n       </defs>\r\n       <use xlink:href=\"#ArialMT-32\"/>\r\n       <use x=\"55.615234\" xlink:href=\"#ArialMT-2e\"/>\r\n       <use x=\"83.398438\" xlink:href=\"#ArialMT-35\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_2\">\r\n     <g id=\"line2d_2\">\r\n      <path clip-path=\"url(#pcadb55d9e4)\" d=\"M 104.076124 293.589375 \r\nL 104.076124 21.789375 \r\n\" style=\"fill:none;stroke:#cccccc;stroke-linecap:round;\"/>\r\n     </g>\r\n     <g id=\"text_2\">\r\n      <!-- 5.0 -->\r\n      <g style=\"fill:#262626;\" transform=\"translate(96.431124 310.962969)scale(0.11 -0.11)\">\r\n       <defs>\r\n        <path d=\"M 266 2259 \r\nQ 266 3072 433 3567 \r\nQ 600 4063 929 4331 \r\nQ 1259 4600 1759 4600 \r\nQ 2128 4600 2406 4451 \r\nQ 2684 4303 2865 4023 \r\nQ 3047 3744 3150 3342 \r\nQ 3253 2941 3253 2259 \r\nQ 3253 1453 3087 958 \r\nQ 2922 463 2592 192 \r\nQ 2263 -78 1759 -78 \r\nQ 1097 -78 719 397 \r\nQ 266 969 266 2259 \r\nz\r\nM 844 2259 \r\nQ 844 1131 1108 757 \r\nQ 1372 384 1759 384 \r\nQ 2147 384 2411 759 \r\nQ 2675 1134 2675 2259 \r\nQ 2675 3391 2411 3762 \r\nQ 2147 4134 1753 4134 \r\nQ 1366 4134 1134 3806 \r\nQ 844 3388 844 2259 \r\nz\r\n\" id=\"ArialMT-30\" transform=\"scale(0.015625)\"/>\r\n       </defs>\r\n       <use xlink:href=\"#ArialMT-35\"/>\r\n       <use x=\"55.615234\" xlink:href=\"#ArialMT-2e\"/>\r\n       <use x=\"83.398438\" xlink:href=\"#ArialMT-30\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_3\">\r\n     <g id=\"line2d_3\">\r\n      <path clip-path=\"url(#pcadb55d9e4)\" d=\"M 140.483258 293.589375 \r\nL 140.483258 21.789375 \r\n\" style=\"fill:none;stroke:#cccccc;stroke-linecap:round;\"/>\r\n     </g>\r\n     <g id=\"text_3\">\r\n      <!-- 7.5 -->\r\n      <g style=\"fill:#262626;\" transform=\"translate(132.838258 310.962969)scale(0.11 -0.11)\">\r\n       <defs>\r\n        <path d=\"M 303 3981 \r\nL 303 4522 \r\nL 3269 4522 \r\nL 3269 4084 \r\nQ 2831 3619 2401 2847 \r\nQ 1972 2075 1738 1259 \r\nQ 1569 684 1522 0 \r\nL 944 0 \r\nQ 953 541 1156 1306 \r\nQ 1359 2072 1739 2783 \r\nQ 2119 3494 2547 3981 \r\nL 303 3981 \r\nz\r\n\" id=\"ArialMT-37\" transform=\"scale(0.015625)\"/>\r\n       </defs>\r\n       <use xlink:href=\"#ArialMT-37\"/>\r\n       <use x=\"55.615234\" xlink:href=\"#ArialMT-2e\"/>\r\n       <use x=\"83.398438\" xlink:href=\"#ArialMT-35\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_4\">\r\n     <g id=\"line2d_4\">\r\n      <path clip-path=\"url(#pcadb55d9e4)\" d=\"M 176.890391 293.589375 \r\nL 176.890391 21.789375 \r\n\" style=\"fill:none;stroke:#cccccc;stroke-linecap:round;\"/>\r\n     </g>\r\n     <g id=\"text_4\">\r\n      <!-- 10.0 -->\r\n      <g style=\"fill:#262626;\" transform=\"translate(166.186876 310.962969)scale(0.11 -0.11)\">\r\n       <defs>\r\n        <path d=\"M 2384 0 \r\nL 1822 0 \r\nL 1822 3584 \r\nQ 1619 3391 1289 3197 \r\nQ 959 3003 697 2906 \r\nL 697 3450 \r\nQ 1169 3672 1522 3987 \r\nQ 1875 4303 2022 4600 \r\nL 2384 4600 \r\nL 2384 0 \r\nz\r\n\" id=\"ArialMT-31\" transform=\"scale(0.015625)\"/>\r\n       </defs>\r\n       <use xlink:href=\"#ArialMT-31\"/>\r\n       <use x=\"55.615234\" xlink:href=\"#ArialMT-30\"/>\r\n       <use x=\"111.230469\" xlink:href=\"#ArialMT-2e\"/>\r\n       <use x=\"139.013672\" xlink:href=\"#ArialMT-30\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_5\">\r\n     <g id=\"line2d_5\">\r\n      <path clip-path=\"url(#pcadb55d9e4)\" d=\"M 213.297525 293.589375 \r\nL 213.297525 21.789375 \r\n\" style=\"fill:none;stroke:#cccccc;stroke-linecap:round;\"/>\r\n     </g>\r\n     <g id=\"text_5\">\r\n      <!-- 12.5 -->\r\n      <g style=\"fill:#262626;\" transform=\"translate(202.594009 310.962969)scale(0.11 -0.11)\">\r\n       <use xlink:href=\"#ArialMT-31\"/>\r\n       <use x=\"55.615234\" xlink:href=\"#ArialMT-32\"/>\r\n       <use x=\"111.230469\" xlink:href=\"#ArialMT-2e\"/>\r\n       <use x=\"139.013672\" xlink:href=\"#ArialMT-35\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_6\">\r\n     <g id=\"line2d_6\">\r\n      <path clip-path=\"url(#pcadb55d9e4)\" d=\"M 249.704659 293.589375 \r\nL 249.704659 21.789375 \r\n\" style=\"fill:none;stroke:#cccccc;stroke-linecap:round;\"/>\r\n     </g>\r\n     <g id=\"text_6\">\r\n      <!-- 15.0 -->\r\n      <g style=\"fill:#262626;\" transform=\"translate(239.001143 310.962969)scale(0.11 -0.11)\">\r\n       <use xlink:href=\"#ArialMT-31\"/>\r\n       <use x=\"55.615234\" xlink:href=\"#ArialMT-35\"/>\r\n       <use x=\"111.230469\" xlink:href=\"#ArialMT-2e\"/>\r\n       <use x=\"139.013672\" xlink:href=\"#ArialMT-30\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_7\">\r\n     <g id=\"line2d_7\">\r\n      <path clip-path=\"url(#pcadb55d9e4)\" d=\"M 286.111792 293.589375 \r\nL 286.111792 21.789375 \r\n\" style=\"fill:none;stroke:#cccccc;stroke-linecap:round;\"/>\r\n     </g>\r\n     <g id=\"text_7\">\r\n      <!-- 17.5 -->\r\n      <g style=\"fill:#262626;\" transform=\"translate(275.408276 310.962969)scale(0.11 -0.11)\">\r\n       <use xlink:href=\"#ArialMT-31\"/>\r\n       <use x=\"55.615234\" xlink:href=\"#ArialMT-37\"/>\r\n       <use x=\"111.230469\" xlink:href=\"#ArialMT-2e\"/>\r\n       <use x=\"139.013672\" xlink:href=\"#ArialMT-35\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_8\">\r\n     <g id=\"line2d_8\">\r\n      <path clip-path=\"url(#pcadb55d9e4)\" d=\"M 322.518926 293.589375 \r\nL 322.518926 21.789375 \r\n\" style=\"fill:none;stroke:#cccccc;stroke-linecap:round;\"/>\r\n     </g>\r\n     <g id=\"text_8\">\r\n      <!-- 20.0 -->\r\n      <g style=\"fill:#262626;\" transform=\"translate(311.81541 310.962969)scale(0.11 -0.11)\">\r\n       <use xlink:href=\"#ArialMT-32\"/>\r\n       <use x=\"55.615234\" xlink:href=\"#ArialMT-30\"/>\r\n       <use x=\"111.230469\" xlink:href=\"#ArialMT-2e\"/>\r\n       <use x=\"139.013672\" xlink:href=\"#ArialMT-30\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n   </g>\r\n   <g id=\"matplotlib.axis_2\">\r\n    <g id=\"ytick_1\">\r\n     <g id=\"line2d_9\">\r\n      <path clip-path=\"url(#pcadb55d9e4)\" d=\"M 31.99 258.406518 \r\nL 336.353636 258.406518 \r\n\" style=\"fill:none;stroke:#cccccc;stroke-linecap:round;\"/>\r\n     </g>\r\n     <g id=\"text_9\">\r\n      <!-- 0.6 -->\r\n      <g style=\"fill:#262626;\" transform=\"translate(7.2 262.343315)scale(0.11 -0.11)\">\r\n       <defs>\r\n        <path d=\"M 3184 3459 \r\nL 2625 3416 \r\nQ 2550 3747 2413 3897 \r\nQ 2184 4138 1850 4138 \r\nQ 1581 4138 1378 3988 \r\nQ 1113 3794 959 3422 \r\nQ 806 3050 800 2363 \r\nQ 1003 2672 1297 2822 \r\nQ 1591 2972 1913 2972 \r\nQ 2475 2972 2870 2558 \r\nQ 3266 2144 3266 1488 \r\nQ 3266 1056 3080 686 \r\nQ 2894 316 2569 119 \r\nQ 2244 -78 1831 -78 \r\nQ 1128 -78 684 439 \r\nQ 241 956 241 2144 \r\nQ 241 3472 731 4075 \r\nQ 1159 4600 1884 4600 \r\nQ 2425 4600 2770 4297 \r\nQ 3116 3994 3184 3459 \r\nz\r\nM 888 1484 \r\nQ 888 1194 1011 928 \r\nQ 1134 663 1356 523 \r\nQ 1578 384 1822 384 \r\nQ 2178 384 2434 671 \r\nQ 2691 959 2691 1453 \r\nQ 2691 1928 2437 2201 \r\nQ 2184 2475 1800 2475 \r\nQ 1419 2475 1153 2201 \r\nQ 888 1928 888 1484 \r\nz\r\n\" id=\"ArialMT-36\" transform=\"scale(0.015625)\"/>\r\n       </defs>\r\n       <use xlink:href=\"#ArialMT-30\"/>\r\n       <use x=\"55.615234\" xlink:href=\"#ArialMT-2e\"/>\r\n       <use x=\"83.398438\" xlink:href=\"#ArialMT-36\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"ytick_2\">\r\n     <g id=\"line2d_10\">\r\n      <path clip-path=\"url(#pcadb55d9e4)\" d=\"M 31.99 202.171112 \r\nL 336.353636 202.171112 \r\n\" style=\"fill:none;stroke:#cccccc;stroke-linecap:round;\"/>\r\n     </g>\r\n     <g id=\"text_10\">\r\n      <!-- 0.7 -->\r\n      <g style=\"fill:#262626;\" transform=\"translate(7.2 206.107909)scale(0.11 -0.11)\">\r\n       <use xlink:href=\"#ArialMT-30\"/>\r\n       <use x=\"55.615234\" xlink:href=\"#ArialMT-2e\"/>\r\n       <use x=\"83.398438\" xlink:href=\"#ArialMT-37\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"ytick_3\">\r\n     <g id=\"line2d_11\">\r\n      <path clip-path=\"url(#pcadb55d9e4)\" d=\"M 31.99 145.935706 \r\nL 336.353636 145.935706 \r\n\" style=\"fill:none;stroke:#cccccc;stroke-linecap:round;\"/>\r\n     </g>\r\n     <g id=\"text_11\">\r\n      <!-- 0.8 -->\r\n      <g style=\"fill:#262626;\" transform=\"translate(7.2 149.872503)scale(0.11 -0.11)\">\r\n       <defs>\r\n        <path d=\"M 1131 2484 \r\nQ 781 2613 612 2850 \r\nQ 444 3088 444 3419 \r\nQ 444 3919 803 4259 \r\nQ 1163 4600 1759 4600 \r\nQ 2359 4600 2725 4251 \r\nQ 3091 3903 3091 3403 \r\nQ 3091 3084 2923 2848 \r\nQ 2756 2613 2416 2484 \r\nQ 2838 2347 3058 2040 \r\nQ 3278 1734 3278 1309 \r\nQ 3278 722 2862 322 \r\nQ 2447 -78 1769 -78 \r\nQ 1091 -78 675 323 \r\nQ 259 725 259 1325 \r\nQ 259 1772 486 2073 \r\nQ 713 2375 1131 2484 \r\nz\r\nM 1019 3438 \r\nQ 1019 3113 1228 2906 \r\nQ 1438 2700 1772 2700 \r\nQ 2097 2700 2305 2904 \r\nQ 2513 3109 2513 3406 \r\nQ 2513 3716 2298 3927 \r\nQ 2084 4138 1766 4138 \r\nQ 1444 4138 1231 3931 \r\nQ 1019 3725 1019 3438 \r\nz\r\nM 838 1322 \r\nQ 838 1081 952 856 \r\nQ 1066 631 1291 507 \r\nQ 1516 384 1775 384 \r\nQ 2178 384 2440 643 \r\nQ 2703 903 2703 1303 \r\nQ 2703 1709 2433 1975 \r\nQ 2163 2241 1756 2241 \r\nQ 1359 2241 1098 1978 \r\nQ 838 1716 838 1322 \r\nz\r\n\" id=\"ArialMT-38\" transform=\"scale(0.015625)\"/>\r\n       </defs>\r\n       <use xlink:href=\"#ArialMT-30\"/>\r\n       <use x=\"55.615234\" xlink:href=\"#ArialMT-2e\"/>\r\n       <use x=\"83.398438\" xlink:href=\"#ArialMT-38\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"ytick_4\">\r\n     <g id=\"line2d_12\">\r\n      <path clip-path=\"url(#pcadb55d9e4)\" d=\"M 31.99 89.7003 \r\nL 336.353636 89.7003 \r\n\" style=\"fill:none;stroke:#cccccc;stroke-linecap:round;\"/>\r\n     </g>\r\n     <g id=\"text_12\">\r\n      <!-- 0.9 -->\r\n      <g style=\"fill:#262626;\" transform=\"translate(7.2 93.637097)scale(0.11 -0.11)\">\r\n       <defs>\r\n        <path d=\"M 350 1059 \r\nL 891 1109 \r\nQ 959 728 1153 556 \r\nQ 1347 384 1650 384 \r\nQ 1909 384 2104 503 \r\nQ 2300 622 2425 820 \r\nQ 2550 1019 2634 1356 \r\nQ 2719 1694 2719 2044 \r\nQ 2719 2081 2716 2156 \r\nQ 2547 1888 2255 1720 \r\nQ 1963 1553 1622 1553 \r\nQ 1053 1553 659 1965 \r\nQ 266 2378 266 3053 \r\nQ 266 3750 677 4175 \r\nQ 1088 4600 1706 4600 \r\nQ 2153 4600 2523 4359 \r\nQ 2894 4119 3086 3673 \r\nQ 3278 3228 3278 2384 \r\nQ 3278 1506 3087 986 \r\nQ 2897 466 2520 194 \r\nQ 2144 -78 1638 -78 \r\nQ 1100 -78 759 220 \r\nQ 419 519 350 1059 \r\nz\r\nM 2653 3081 \r\nQ 2653 3566 2395 3850 \r\nQ 2138 4134 1775 4134 \r\nQ 1400 4134 1122 3828 \r\nQ 844 3522 844 3034 \r\nQ 844 2597 1108 2323 \r\nQ 1372 2050 1759 2050 \r\nQ 2150 2050 2401 2323 \r\nQ 2653 2597 2653 3081 \r\nz\r\n\" id=\"ArialMT-39\" transform=\"scale(0.015625)\"/>\r\n       </defs>\r\n       <use xlink:href=\"#ArialMT-30\"/>\r\n       <use x=\"55.615234\" xlink:href=\"#ArialMT-2e\"/>\r\n       <use x=\"83.398438\" xlink:href=\"#ArialMT-39\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"ytick_5\">\r\n     <g id=\"line2d_13\">\r\n      <path clip-path=\"url(#pcadb55d9e4)\" d=\"M 31.99 33.464894 \r\nL 336.353636 33.464894 \r\n\" style=\"fill:none;stroke:#cccccc;stroke-linecap:round;\"/>\r\n     </g>\r\n     <g id=\"text_13\">\r\n      <!-- 1.0 -->\r\n      <g style=\"fill:#262626;\" transform=\"translate(7.2 37.401691)scale(0.11 -0.11)\">\r\n       <use xlink:href=\"#ArialMT-31\"/>\r\n       <use x=\"55.615234\" xlink:href=\"#ArialMT-2e\"/>\r\n       <use x=\"83.398438\" xlink:href=\"#ArialMT-30\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n   </g>\r\n   <g id=\"line2d_14\">\r\n    <path clip-path=\"url(#pcadb55d9e4)\" d=\"M 45.824711 281.23483 \r\nL 60.387564 166.903758 \r\nL 74.950418 121.676687 \r\nL 89.513271 105.853514 \r\nL 104.076124 90.109312 \r\nL 118.638978 76.24428 \r\nL 133.201831 66.500901 \r\nL 147.764685 58.068179 \r\nL 162.327538 51.593632 \r\nL 176.890391 45.940232 \r\nL 191.453245 41.960766 \r\nL 206.016098 39.197232 \r\nL 220.578952 37.475969 \r\nL 235.141805 35.975763 \r\nL 249.704659 35.359886 \r\nL 264.267512 34.980888 \r\nL 278.830365 34.522919 \r\nL 293.393219 34.270253 \r\nL 307.956072 34.14392 \r\nL 322.518926 34.191316 \r\n\" style=\"fill:none;stroke:#4c72b0;stroke-linecap:round;stroke-width:1.5;\"/>\r\n   </g>\r\n   <g id=\"line2d_15\">\r\n    <path clip-path=\"url(#pcadb55d9e4)\" d=\"M 45.824711 137.939059 \r\nL 60.387564 119.242376 \r\nL 74.950418 112.925904 \r\nL 89.513271 107.93591 \r\nL 104.076124 101.240474 \r\nL 118.638978 96.376779 \r\nL 133.201831 94.797669 \r\nL 147.764685 93.723891 \r\nL 162.327538 93.78704 \r\nL 176.890391 95.492483 \r\nL 191.453245 96.945259 \r\nL 206.016098 97.892739 \r\nL 220.578952 98.713885 \r\nL 235.141805 99.598181 \r\nL 249.704659 100.040329 \r\nL 264.267512 100.54566 \r\nL 278.830365 102.12477 \r\nL 293.393219 102.440585 \r\nL 307.956072 103.135398 \r\nL 322.518926 104.082878 \r\n\" style=\"fill:none;stroke:#c44e52;stroke-linecap:round;stroke-width:1.5;\"/>\r\n   </g>\r\n   <g id=\"patch_3\">\r\n    <path d=\"M 31.99 293.589375 \r\nL 31.99 21.789375 \r\n\" style=\"fill:none;stroke:#cccccc;stroke-linecap:square;stroke-linejoin:miter;stroke-width:1.25;\"/>\r\n   </g>\r\n   <g id=\"patch_4\">\r\n    <path d=\"M 336.353636 293.589375 \r\nL 336.353636 21.789375 \r\n\" style=\"fill:none;stroke:#cccccc;stroke-linecap:square;stroke-linejoin:miter;stroke-width:1.25;\"/>\r\n   </g>\r\n   <g id=\"patch_5\">\r\n    <path d=\"M 31.99 293.589375 \r\nL 336.353636 293.589375 \r\n\" style=\"fill:none;stroke:#cccccc;stroke-linecap:square;stroke-linejoin:miter;stroke-width:1.25;\"/>\r\n   </g>\r\n   <g id=\"patch_6\">\r\n    <path d=\"M 31.99 21.789375 \r\nL 336.353636 21.789375 \r\n\" style=\"fill:none;stroke:#cccccc;stroke-linecap:square;stroke-linejoin:miter;stroke-width:1.25;\"/>\r\n   </g>\r\n   <g id=\"text_14\">\r\n    <!-- Training and validation accuracy -->\r\n    <g style=\"fill:#262626;\" transform=\"translate(98.354943 15.789375)scale(0.12 -0.12)\">\r\n     <defs>\r\n      <path d=\"M 1659 0 \r\nL 1659 4041 \r\nL 150 4041 \r\nL 150 4581 \r\nL 3781 4581 \r\nL 3781 4041 \r\nL 2266 4041 \r\nL 2266 0 \r\nL 1659 0 \r\nz\r\n\" id=\"ArialMT-54\" transform=\"scale(0.015625)\"/>\r\n      <path d=\"M 416 0 \r\nL 416 3319 \r\nL 922 3319 \r\nL 922 2816 \r\nQ 1116 3169 1280 3281 \r\nQ 1444 3394 1641 3394 \r\nQ 1925 3394 2219 3213 \r\nL 2025 2691 \r\nQ 1819 2813 1613 2813 \r\nQ 1428 2813 1281 2702 \r\nQ 1134 2591 1072 2394 \r\nQ 978 2094 978 1738 \r\nL 978 0 \r\nL 416 0 \r\nz\r\n\" id=\"ArialMT-72\" transform=\"scale(0.015625)\"/>\r\n      <path d=\"M 2588 409 \r\nQ 2275 144 1986 34 \r\nQ 1697 -75 1366 -75 \r\nQ 819 -75 525 192 \r\nQ 231 459 231 875 \r\nQ 231 1119 342 1320 \r\nQ 453 1522 633 1644 \r\nQ 813 1766 1038 1828 \r\nQ 1203 1872 1538 1913 \r\nQ 2219 1994 2541 2106 \r\nQ 2544 2222 2544 2253 \r\nQ 2544 2597 2384 2738 \r\nQ 2169 2928 1744 2928 \r\nQ 1347 2928 1158 2789 \r\nQ 969 2650 878 2297 \r\nL 328 2372 \r\nQ 403 2725 575 2942 \r\nQ 747 3159 1072 3276 \r\nQ 1397 3394 1825 3394 \r\nQ 2250 3394 2515 3294 \r\nQ 2781 3194 2906 3042 \r\nQ 3031 2891 3081 2659 \r\nQ 3109 2516 3109 2141 \r\nL 3109 1391 \r\nQ 3109 606 3145 398 \r\nQ 3181 191 3288 0 \r\nL 2700 0 \r\nQ 2613 175 2588 409 \r\nz\r\nM 2541 1666 \r\nQ 2234 1541 1622 1453 \r\nQ 1275 1403 1131 1340 \r\nQ 988 1278 909 1158 \r\nQ 831 1038 831 891 \r\nQ 831 666 1001 516 \r\nQ 1172 366 1500 366 \r\nQ 1825 366 2078 508 \r\nQ 2331 650 2450 897 \r\nQ 2541 1088 2541 1459 \r\nL 2541 1666 \r\nz\r\n\" id=\"ArialMT-61\" transform=\"scale(0.015625)\"/>\r\n      <path d=\"M 425 3934 \r\nL 425 4581 \r\nL 988 4581 \r\nL 988 3934 \r\nL 425 3934 \r\nz\r\nM 425 0 \r\nL 425 3319 \r\nL 988 3319 \r\nL 988 0 \r\nL 425 0 \r\nz\r\n\" id=\"ArialMT-69\" transform=\"scale(0.015625)\"/>\r\n      <path d=\"M 422 0 \r\nL 422 3319 \r\nL 928 3319 \r\nL 928 2847 \r\nQ 1294 3394 1984 3394 \r\nQ 2284 3394 2536 3286 \r\nQ 2788 3178 2913 3003 \r\nQ 3038 2828 3088 2588 \r\nQ 3119 2431 3119 2041 \r\nL 3119 0 \r\nL 2556 0 \r\nL 2556 2019 \r\nQ 2556 2363 2490 2533 \r\nQ 2425 2703 2258 2804 \r\nQ 2091 2906 1866 2906 \r\nQ 1506 2906 1245 2678 \r\nQ 984 2450 984 1813 \r\nL 984 0 \r\nL 422 0 \r\nz\r\n\" id=\"ArialMT-6e\" transform=\"scale(0.015625)\"/>\r\n      <path d=\"M 319 -275 \r\nL 866 -356 \r\nQ 900 -609 1056 -725 \r\nQ 1266 -881 1628 -881 \r\nQ 2019 -881 2231 -725 \r\nQ 2444 -569 2519 -288 \r\nQ 2563 -116 2559 434 \r\nQ 2191 0 1641 0 \r\nQ 956 0 581 494 \r\nQ 206 988 206 1678 \r\nQ 206 2153 378 2554 \r\nQ 550 2956 876 3175 \r\nQ 1203 3394 1644 3394 \r\nQ 2231 3394 2613 2919 \r\nL 2613 3319 \r\nL 3131 3319 \r\nL 3131 450 \r\nQ 3131 -325 2973 -648 \r\nQ 2816 -972 2473 -1159 \r\nQ 2131 -1347 1631 -1347 \r\nQ 1038 -1347 672 -1080 \r\nQ 306 -813 319 -275 \r\nz\r\nM 784 1719 \r\nQ 784 1066 1043 766 \r\nQ 1303 466 1694 466 \r\nQ 2081 466 2343 764 \r\nQ 2606 1063 2606 1700 \r\nQ 2606 2309 2336 2618 \r\nQ 2066 2928 1684 2928 \r\nQ 1309 2928 1046 2623 \r\nQ 784 2319 784 1719 \r\nz\r\n\" id=\"ArialMT-67\" transform=\"scale(0.015625)\"/>\r\n      <path id=\"ArialMT-20\" transform=\"scale(0.015625)\"/>\r\n      <path d=\"M 2575 0 \r\nL 2575 419 \r\nQ 2259 -75 1647 -75 \r\nQ 1250 -75 917 144 \r\nQ 584 363 401 755 \r\nQ 219 1147 219 1656 \r\nQ 219 2153 384 2558 \r\nQ 550 2963 881 3178 \r\nQ 1213 3394 1622 3394 \r\nQ 1922 3394 2156 3267 \r\nQ 2391 3141 2538 2938 \r\nL 2538 4581 \r\nL 3097 4581 \r\nL 3097 0 \r\nL 2575 0 \r\nz\r\nM 797 1656 \r\nQ 797 1019 1065 703 \r\nQ 1334 388 1700 388 \r\nQ 2069 388 2326 689 \r\nQ 2584 991 2584 1609 \r\nQ 2584 2291 2321 2609 \r\nQ 2059 2928 1675 2928 \r\nQ 1300 2928 1048 2622 \r\nQ 797 2316 797 1656 \r\nz\r\n\" id=\"ArialMT-64\" transform=\"scale(0.015625)\"/>\r\n      <path d=\"M 1344 0 \r\nL 81 3319 \r\nL 675 3319 \r\nL 1388 1331 \r\nQ 1503 1009 1600 663 \r\nQ 1675 925 1809 1294 \r\nL 2547 3319 \r\nL 3125 3319 \r\nL 1869 0 \r\nL 1344 0 \r\nz\r\n\" id=\"ArialMT-76\" transform=\"scale(0.015625)\"/>\r\n      <path d=\"M 409 0 \r\nL 409 4581 \r\nL 972 4581 \r\nL 972 0 \r\nL 409 0 \r\nz\r\n\" id=\"ArialMT-6c\" transform=\"scale(0.015625)\"/>\r\n      <path d=\"M 1650 503 \r\nL 1731 6 \r\nQ 1494 -44 1306 -44 \r\nQ 1000 -44 831 53 \r\nQ 663 150 594 308 \r\nQ 525 466 525 972 \r\nL 525 2881 \r\nL 113 2881 \r\nL 113 3319 \r\nL 525 3319 \r\nL 525 4141 \r\nL 1084 4478 \r\nL 1084 3319 \r\nL 1650 3319 \r\nL 1650 2881 \r\nL 1084 2881 \r\nL 1084 941 \r\nQ 1084 700 1114 631 \r\nQ 1144 563 1211 522 \r\nQ 1278 481 1403 481 \r\nQ 1497 481 1650 503 \r\nz\r\n\" id=\"ArialMT-74\" transform=\"scale(0.015625)\"/>\r\n      <path d=\"M 213 1659 \r\nQ 213 2581 725 3025 \r\nQ 1153 3394 1769 3394 \r\nQ 2453 3394 2887 2945 \r\nQ 3322 2497 3322 1706 \r\nQ 3322 1066 3130 698 \r\nQ 2938 331 2570 128 \r\nQ 2203 -75 1769 -75 \r\nQ 1072 -75 642 372 \r\nQ 213 819 213 1659 \r\nz\r\nM 791 1659 \r\nQ 791 1022 1069 705 \r\nQ 1347 388 1769 388 \r\nQ 2188 388 2466 706 \r\nQ 2744 1025 2744 1678 \r\nQ 2744 2294 2464 2611 \r\nQ 2184 2928 1769 2928 \r\nQ 1347 2928 1069 2612 \r\nQ 791 2297 791 1659 \r\nz\r\n\" id=\"ArialMT-6f\" transform=\"scale(0.015625)\"/>\r\n      <path d=\"M 2588 1216 \r\nL 3141 1144 \r\nQ 3050 572 2676 248 \r\nQ 2303 -75 1759 -75 \r\nQ 1078 -75 664 370 \r\nQ 250 816 250 1647 \r\nQ 250 2184 428 2587 \r\nQ 606 2991 970 3192 \r\nQ 1334 3394 1763 3394 \r\nQ 2303 3394 2647 3120 \r\nQ 2991 2847 3088 2344 \r\nL 2541 2259 \r\nQ 2463 2594 2264 2762 \r\nQ 2066 2931 1784 2931 \r\nQ 1359 2931 1093 2626 \r\nQ 828 2322 828 1663 \r\nQ 828 994 1084 691 \r\nQ 1341 388 1753 388 \r\nQ 2084 388 2306 591 \r\nQ 2528 794 2588 1216 \r\nz\r\n\" id=\"ArialMT-63\" transform=\"scale(0.015625)\"/>\r\n      <path d=\"M 2597 0 \r\nL 2597 488 \r\nQ 2209 -75 1544 -75 \r\nQ 1250 -75 995 37 \r\nQ 741 150 617 320 \r\nQ 494 491 444 738 \r\nQ 409 903 409 1263 \r\nL 409 3319 \r\nL 972 3319 \r\nL 972 1478 \r\nQ 972 1038 1006 884 \r\nQ 1059 663 1231 536 \r\nQ 1403 409 1656 409 \r\nQ 1909 409 2131 539 \r\nQ 2353 669 2445 892 \r\nQ 2538 1116 2538 1541 \r\nL 2538 3319 \r\nL 3100 3319 \r\nL 3100 0 \r\nL 2597 0 \r\nz\r\n\" id=\"ArialMT-75\" transform=\"scale(0.015625)\"/>\r\n      <path d=\"M 397 -1278 \r\nL 334 -750 \r\nQ 519 -800 656 -800 \r\nQ 844 -800 956 -737 \r\nQ 1069 -675 1141 -563 \r\nQ 1194 -478 1313 -144 \r\nQ 1328 -97 1363 -6 \r\nL 103 3319 \r\nL 709 3319 \r\nL 1400 1397 \r\nQ 1534 1031 1641 628 \r\nQ 1738 1016 1872 1384 \r\nL 2581 3319 \r\nL 3144 3319 \r\nL 1881 -56 \r\nQ 1678 -603 1566 -809 \r\nQ 1416 -1088 1222 -1217 \r\nQ 1028 -1347 759 -1347 \r\nQ 597 -1347 397 -1278 \r\nz\r\n\" id=\"ArialMT-79\" transform=\"scale(0.015625)\"/>\r\n     </defs>\r\n     <use xlink:href=\"#ArialMT-54\"/>\r\n     <use x=\"57.333984\" xlink:href=\"#ArialMT-72\"/>\r\n     <use x=\"90.634766\" xlink:href=\"#ArialMT-61\"/>\r\n     <use x=\"146.25\" xlink:href=\"#ArialMT-69\"/>\r\n     <use x=\"168.466797\" xlink:href=\"#ArialMT-6e\"/>\r\n     <use x=\"224.082031\" xlink:href=\"#ArialMT-69\"/>\r\n     <use x=\"246.298828\" xlink:href=\"#ArialMT-6e\"/>\r\n     <use x=\"301.914062\" xlink:href=\"#ArialMT-67\"/>\r\n     <use x=\"357.529297\" xlink:href=\"#ArialMT-20\"/>\r\n     <use x=\"385.3125\" xlink:href=\"#ArialMT-61\"/>\r\n     <use x=\"440.927734\" xlink:href=\"#ArialMT-6e\"/>\r\n     <use x=\"496.542969\" xlink:href=\"#ArialMT-64\"/>\r\n     <use x=\"552.158203\" xlink:href=\"#ArialMT-20\"/>\r\n     <use x=\"579.941406\" xlink:href=\"#ArialMT-76\"/>\r\n     <use x=\"629.941406\" xlink:href=\"#ArialMT-61\"/>\r\n     <use x=\"685.556641\" xlink:href=\"#ArialMT-6c\"/>\r\n     <use x=\"707.773438\" xlink:href=\"#ArialMT-69\"/>\r\n     <use x=\"729.990234\" xlink:href=\"#ArialMT-64\"/>\r\n     <use x=\"785.605469\" xlink:href=\"#ArialMT-61\"/>\r\n     <use x=\"841.220703\" xlink:href=\"#ArialMT-74\"/>\r\n     <use x=\"869.003906\" xlink:href=\"#ArialMT-69\"/>\r\n     <use x=\"891.220703\" xlink:href=\"#ArialMT-6f\"/>\r\n     <use x=\"946.835938\" xlink:href=\"#ArialMT-6e\"/>\r\n     <use x=\"1002.451172\" xlink:href=\"#ArialMT-20\"/>\r\n     <use x=\"1030.234375\" xlink:href=\"#ArialMT-61\"/>\r\n     <use x=\"1085.849609\" xlink:href=\"#ArialMT-63\"/>\r\n     <use x=\"1135.849609\" xlink:href=\"#ArialMT-63\"/>\r\n     <use x=\"1185.849609\" xlink:href=\"#ArialMT-75\"/>\r\n     <use x=\"1241.464844\" xlink:href=\"#ArialMT-72\"/>\r\n     <use x=\"1274.765625\" xlink:href=\"#ArialMT-61\"/>\r\n     <use x=\"1330.380859\" xlink:href=\"#ArialMT-63\"/>\r\n     <use x=\"1380.380859\" xlink:href=\"#ArialMT-79\"/>\r\n    </g>\r\n   </g>\r\n   <g id=\"legend_1\">\r\n    <g id=\"patch_7\">\r\n     <path d=\"M 225.781293 288.089375 \r\nL 328.653636 288.089375 \r\nQ 330.853636 288.089375 330.853636 285.889375 \r\nL 330.853636 255.740781 \r\nQ 330.853636 253.540781 328.653636 253.540781 \r\nL 225.781293 253.540781 \r\nQ 223.581293 253.540781 223.581293 255.740781 \r\nL 223.581293 285.889375 \r\nQ 223.581293 288.089375 225.781293 288.089375 \r\nz\r\n\" style=\"fill:#ffffff;opacity:0.8;stroke:#cccccc;stroke-linejoin:miter;\"/>\r\n    </g>\r\n    <g id=\"line2d_16\">\r\n     <path d=\"M 227.981293 261.964375 \r\nL 249.981293 261.964375 \r\n\" style=\"fill:none;stroke:#4c72b0;stroke-linecap:round;stroke-width:1.5;\"/>\r\n    </g>\r\n    <g id=\"line2d_17\"/>\r\n    <g id=\"text_15\">\r\n     <!-- Training acc -->\r\n     <g style=\"fill:#262626;\" transform=\"translate(258.781293 265.814375)scale(0.11 -0.11)\">\r\n      <use xlink:href=\"#ArialMT-54\"/>\r\n      <use x=\"57.333984\" xlink:href=\"#ArialMT-72\"/>\r\n      <use x=\"90.634766\" xlink:href=\"#ArialMT-61\"/>\r\n      <use x=\"146.25\" xlink:href=\"#ArialMT-69\"/>\r\n      <use x=\"168.466797\" xlink:href=\"#ArialMT-6e\"/>\r\n      <use x=\"224.082031\" xlink:href=\"#ArialMT-69\"/>\r\n      <use x=\"246.298828\" xlink:href=\"#ArialMT-6e\"/>\r\n      <use x=\"301.914062\" xlink:href=\"#ArialMT-67\"/>\r\n      <use x=\"357.529297\" xlink:href=\"#ArialMT-20\"/>\r\n      <use x=\"385.3125\" xlink:href=\"#ArialMT-61\"/>\r\n      <use x=\"440.927734\" xlink:href=\"#ArialMT-63\"/>\r\n      <use x=\"490.927734\" xlink:href=\"#ArialMT-63\"/>\r\n     </g>\r\n    </g>\r\n    <g id=\"line2d_18\">\r\n     <path d=\"M 227.981293 277.653125 \r\nL 249.981293 277.653125 \r\n\" style=\"fill:none;stroke:#c44e52;stroke-linecap:round;stroke-width:1.5;\"/>\r\n    </g>\r\n    <g id=\"line2d_19\"/>\r\n    <g id=\"text_16\">\r\n     <!-- Validation acc -->\r\n     <g style=\"fill:#262626;\" transform=\"translate(258.781293 281.503125)scale(0.11 -0.11)\">\r\n      <defs>\r\n       <path d=\"M 1803 0 \r\nL 28 4581 \r\nL 684 4581 \r\nL 1875 1253 \r\nQ 2019 853 2116 503 \r\nQ 2222 878 2363 1253 \r\nL 3600 4581 \r\nL 4219 4581 \r\nL 2425 0 \r\nL 1803 0 \r\nz\r\n\" id=\"ArialMT-56\" transform=\"scale(0.015625)\"/>\r\n      </defs>\r\n      <use xlink:href=\"#ArialMT-56\"/>\r\n      <use x=\"59.324219\" xlink:href=\"#ArialMT-61\"/>\r\n      <use x=\"114.939453\" xlink:href=\"#ArialMT-6c\"/>\r\n      <use x=\"137.15625\" xlink:href=\"#ArialMT-69\"/>\r\n      <use x=\"159.373047\" xlink:href=\"#ArialMT-64\"/>\r\n      <use x=\"214.988281\" xlink:href=\"#ArialMT-61\"/>\r\n      <use x=\"270.603516\" xlink:href=\"#ArialMT-74\"/>\r\n      <use x=\"298.386719\" xlink:href=\"#ArialMT-69\"/>\r\n      <use x=\"320.603516\" xlink:href=\"#ArialMT-6f\"/>\r\n      <use x=\"376.21875\" xlink:href=\"#ArialMT-6e\"/>\r\n      <use x=\"431.833984\" xlink:href=\"#ArialMT-20\"/>\r\n      <use x=\"459.617188\" xlink:href=\"#ArialMT-61\"/>\r\n      <use x=\"515.232422\" xlink:href=\"#ArialMT-63\"/>\r\n      <use x=\"565.232422\" xlink:href=\"#ArialMT-63\"/>\r\n     </g>\r\n    </g>\r\n   </g>\r\n  </g>\r\n  <g id=\"axes_2\">\r\n   <g id=\"patch_8\">\r\n    <path d=\"M 397.226364 293.589375 \r\nL 701.59 293.589375 \r\nL 701.59 21.789375 \r\nL 397.226364 21.789375 \r\nz\r\n\" style=\"fill:#ffffff;\"/>\r\n   </g>\r\n   <g id=\"matplotlib.axis_3\">\r\n    <g id=\"xtick_9\">\r\n     <g id=\"line2d_20\">\r\n      <path clip-path=\"url(#p9fb57203a4)\" d=\"M 432.905355 293.589375 \r\nL 432.905355 21.789375 \r\n\" style=\"fill:none;stroke:#cccccc;stroke-linecap:round;\"/>\r\n     </g>\r\n     <g id=\"text_17\">\r\n      <!-- 2.5 -->\r\n      <g style=\"fill:#262626;\" transform=\"translate(425.260355 310.962969)scale(0.11 -0.11)\">\r\n       <use xlink:href=\"#ArialMT-32\"/>\r\n       <use x=\"55.615234\" xlink:href=\"#ArialMT-2e\"/>\r\n       <use x=\"83.398438\" xlink:href=\"#ArialMT-35\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_10\">\r\n     <g id=\"line2d_21\">\r\n      <path clip-path=\"url(#p9fb57203a4)\" d=\"M 469.312488 293.589375 \r\nL 469.312488 21.789375 \r\n\" style=\"fill:none;stroke:#cccccc;stroke-linecap:round;\"/>\r\n     </g>\r\n     <g id=\"text_18\">\r\n      <!-- 5.0 -->\r\n      <g style=\"fill:#262626;\" transform=\"translate(461.667488 310.962969)scale(0.11 -0.11)\">\r\n       <use xlink:href=\"#ArialMT-35\"/>\r\n       <use x=\"55.615234\" xlink:href=\"#ArialMT-2e\"/>\r\n       <use x=\"83.398438\" xlink:href=\"#ArialMT-30\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_11\">\r\n     <g id=\"line2d_22\">\r\n      <path clip-path=\"url(#p9fb57203a4)\" d=\"M 505.719622 293.589375 \r\nL 505.719622 21.789375 \r\n\" style=\"fill:none;stroke:#cccccc;stroke-linecap:round;\"/>\r\n     </g>\r\n     <g id=\"text_19\">\r\n      <!-- 7.5 -->\r\n      <g style=\"fill:#262626;\" transform=\"translate(498.074622 310.962969)scale(0.11 -0.11)\">\r\n       <use xlink:href=\"#ArialMT-37\"/>\r\n       <use x=\"55.615234\" xlink:href=\"#ArialMT-2e\"/>\r\n       <use x=\"83.398438\" xlink:href=\"#ArialMT-35\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_12\">\r\n     <g id=\"line2d_23\">\r\n      <path clip-path=\"url(#p9fb57203a4)\" d=\"M 542.126755 293.589375 \r\nL 542.126755 21.789375 \r\n\" style=\"fill:none;stroke:#cccccc;stroke-linecap:round;\"/>\r\n     </g>\r\n     <g id=\"text_20\">\r\n      <!-- 10.0 -->\r\n      <g style=\"fill:#262626;\" transform=\"translate(531.423239 310.962969)scale(0.11 -0.11)\">\r\n       <use xlink:href=\"#ArialMT-31\"/>\r\n       <use x=\"55.615234\" xlink:href=\"#ArialMT-30\"/>\r\n       <use x=\"111.230469\" xlink:href=\"#ArialMT-2e\"/>\r\n       <use x=\"139.013672\" xlink:href=\"#ArialMT-30\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_13\">\r\n     <g id=\"line2d_24\">\r\n      <path clip-path=\"url(#p9fb57203a4)\" d=\"M 578.533889 293.589375 \r\nL 578.533889 21.789375 \r\n\" style=\"fill:none;stroke:#cccccc;stroke-linecap:round;\"/>\r\n     </g>\r\n     <g id=\"text_21\">\r\n      <!-- 12.5 -->\r\n      <g style=\"fill:#262626;\" transform=\"translate(567.830373 310.962969)scale(0.11 -0.11)\">\r\n       <use xlink:href=\"#ArialMT-31\"/>\r\n       <use x=\"55.615234\" xlink:href=\"#ArialMT-32\"/>\r\n       <use x=\"111.230469\" xlink:href=\"#ArialMT-2e\"/>\r\n       <use x=\"139.013672\" xlink:href=\"#ArialMT-35\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_14\">\r\n     <g id=\"line2d_25\">\r\n      <path clip-path=\"url(#p9fb57203a4)\" d=\"M 614.941022 293.589375 \r\nL 614.941022 21.789375 \r\n\" style=\"fill:none;stroke:#cccccc;stroke-linecap:round;\"/>\r\n     </g>\r\n     <g id=\"text_22\">\r\n      <!-- 15.0 -->\r\n      <g style=\"fill:#262626;\" transform=\"translate(604.237507 310.962969)scale(0.11 -0.11)\">\r\n       <use xlink:href=\"#ArialMT-31\"/>\r\n       <use x=\"55.615234\" xlink:href=\"#ArialMT-35\"/>\r\n       <use x=\"111.230469\" xlink:href=\"#ArialMT-2e\"/>\r\n       <use x=\"139.013672\" xlink:href=\"#ArialMT-30\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_15\">\r\n     <g id=\"line2d_26\">\r\n      <path clip-path=\"url(#p9fb57203a4)\" d=\"M 651.348156 293.589375 \r\nL 651.348156 21.789375 \r\n\" style=\"fill:none;stroke:#cccccc;stroke-linecap:round;\"/>\r\n     </g>\r\n     <g id=\"text_23\">\r\n      <!-- 17.5 -->\r\n      <g style=\"fill:#262626;\" transform=\"translate(640.64464 310.962969)scale(0.11 -0.11)\">\r\n       <use xlink:href=\"#ArialMT-31\"/>\r\n       <use x=\"55.615234\" xlink:href=\"#ArialMT-37\"/>\r\n       <use x=\"111.230469\" xlink:href=\"#ArialMT-2e\"/>\r\n       <use x=\"139.013672\" xlink:href=\"#ArialMT-35\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_16\">\r\n     <g id=\"line2d_27\">\r\n      <path clip-path=\"url(#p9fb57203a4)\" d=\"M 687.755289 293.589375 \r\nL 687.755289 21.789375 \r\n\" style=\"fill:none;stroke:#cccccc;stroke-linecap:round;\"/>\r\n     </g>\r\n     <g id=\"text_24\">\r\n      <!-- 20.0 -->\r\n      <g style=\"fill:#262626;\" transform=\"translate(677.051774 310.962969)scale(0.11 -0.11)\">\r\n       <use xlink:href=\"#ArialMT-32\"/>\r\n       <use x=\"55.615234\" xlink:href=\"#ArialMT-30\"/>\r\n       <use x=\"111.230469\" xlink:href=\"#ArialMT-2e\"/>\r\n       <use x=\"139.013672\" xlink:href=\"#ArialMT-30\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n   </g>\r\n   <g id=\"matplotlib.axis_4\">\r\n    <g id=\"ytick_6\">\r\n     <g id=\"line2d_28\">\r\n      <path clip-path=\"url(#p9fb57203a4)\" d=\"M 397.226364 283.637183 \r\nL 701.59 283.637183 \r\n\" style=\"fill:none;stroke:#cccccc;stroke-linecap:round;\"/>\r\n     </g>\r\n     <g id=\"text_25\">\r\n      <!-- 0.0 -->\r\n      <g style=\"fill:#262626;\" transform=\"translate(372.436364 287.57398)scale(0.11 -0.11)\">\r\n       <use xlink:href=\"#ArialMT-30\"/>\r\n       <use x=\"55.615234\" xlink:href=\"#ArialMT-2e\"/>\r\n       <use x=\"83.398438\" xlink:href=\"#ArialMT-30\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"ytick_7\">\r\n     <g id=\"line2d_29\">\r\n      <path clip-path=\"url(#p9fb57203a4)\" d=\"M 397.226364 247.400471 \r\nL 701.59 247.400471 \r\n\" style=\"fill:none;stroke:#cccccc;stroke-linecap:round;\"/>\r\n     </g>\r\n     <g id=\"text_26\">\r\n      <!-- 0.1 -->\r\n      <g style=\"fill:#262626;\" transform=\"translate(372.436364 251.337267)scale(0.11 -0.11)\">\r\n       <use xlink:href=\"#ArialMT-30\"/>\r\n       <use x=\"55.615234\" xlink:href=\"#ArialMT-2e\"/>\r\n       <use x=\"83.398438\" xlink:href=\"#ArialMT-31\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"ytick_8\">\r\n     <g id=\"line2d_30\">\r\n      <path clip-path=\"url(#p9fb57203a4)\" d=\"M 397.226364 211.163758 \r\nL 701.59 211.163758 \r\n\" style=\"fill:none;stroke:#cccccc;stroke-linecap:round;\"/>\r\n     </g>\r\n     <g id=\"text_27\">\r\n      <!-- 0.2 -->\r\n      <g style=\"fill:#262626;\" transform=\"translate(372.436364 215.100554)scale(0.11 -0.11)\">\r\n       <use xlink:href=\"#ArialMT-30\"/>\r\n       <use x=\"55.615234\" xlink:href=\"#ArialMT-2e\"/>\r\n       <use x=\"83.398438\" xlink:href=\"#ArialMT-32\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"ytick_9\">\r\n     <g id=\"line2d_31\">\r\n      <path clip-path=\"url(#p9fb57203a4)\" d=\"M 397.226364 174.927045 \r\nL 701.59 174.927045 \r\n\" style=\"fill:none;stroke:#cccccc;stroke-linecap:round;\"/>\r\n     </g>\r\n     <g id=\"text_28\">\r\n      <!-- 0.3 -->\r\n      <g style=\"fill:#262626;\" transform=\"translate(372.436364 178.863841)scale(0.11 -0.11)\">\r\n       <defs>\r\n        <path d=\"M 269 1209 \r\nL 831 1284 \r\nQ 928 806 1161 595 \r\nQ 1394 384 1728 384 \r\nQ 2125 384 2398 659 \r\nQ 2672 934 2672 1341 \r\nQ 2672 1728 2419 1979 \r\nQ 2166 2231 1775 2231 \r\nQ 1616 2231 1378 2169 \r\nL 1441 2663 \r\nQ 1497 2656 1531 2656 \r\nQ 1891 2656 2178 2843 \r\nQ 2466 3031 2466 3422 \r\nQ 2466 3731 2256 3934 \r\nQ 2047 4138 1716 4138 \r\nQ 1388 4138 1169 3931 \r\nQ 950 3725 888 3313 \r\nL 325 3413 \r\nQ 428 3978 793 4289 \r\nQ 1159 4600 1703 4600 \r\nQ 2078 4600 2393 4439 \r\nQ 2709 4278 2876 4000 \r\nQ 3044 3722 3044 3409 \r\nQ 3044 3113 2884 2869 \r\nQ 2725 2625 2413 2481 \r\nQ 2819 2388 3044 2092 \r\nQ 3269 1797 3269 1353 \r\nQ 3269 753 2831 336 \r\nQ 2394 -81 1725 -81 \r\nQ 1122 -81 723 278 \r\nQ 325 638 269 1209 \r\nz\r\n\" id=\"ArialMT-33\" transform=\"scale(0.015625)\"/>\r\n       </defs>\r\n       <use xlink:href=\"#ArialMT-30\"/>\r\n       <use x=\"55.615234\" xlink:href=\"#ArialMT-2e\"/>\r\n       <use x=\"83.398438\" xlink:href=\"#ArialMT-33\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"ytick_10\">\r\n     <g id=\"line2d_32\">\r\n      <path clip-path=\"url(#p9fb57203a4)\" d=\"M 397.226364 138.690332 \r\nL 701.59 138.690332 \r\n\" style=\"fill:none;stroke:#cccccc;stroke-linecap:round;\"/>\r\n     </g>\r\n     <g id=\"text_29\">\r\n      <!-- 0.4 -->\r\n      <g style=\"fill:#262626;\" transform=\"translate(372.436364 142.627129)scale(0.11 -0.11)\">\r\n       <defs>\r\n        <path d=\"M 2069 0 \r\nL 2069 1097 \r\nL 81 1097 \r\nL 81 1613 \r\nL 2172 4581 \r\nL 2631 4581 \r\nL 2631 1613 \r\nL 3250 1613 \r\nL 3250 1097 \r\nL 2631 1097 \r\nL 2631 0 \r\nL 2069 0 \r\nz\r\nM 2069 1613 \r\nL 2069 3678 \r\nL 634 1613 \r\nL 2069 1613 \r\nz\r\n\" id=\"ArialMT-34\" transform=\"scale(0.015625)\"/>\r\n       </defs>\r\n       <use xlink:href=\"#ArialMT-30\"/>\r\n       <use x=\"55.615234\" xlink:href=\"#ArialMT-2e\"/>\r\n       <use x=\"83.398438\" xlink:href=\"#ArialMT-34\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"ytick_11\">\r\n     <g id=\"line2d_33\">\r\n      <path clip-path=\"url(#p9fb57203a4)\" d=\"M 397.226364 102.453619 \r\nL 701.59 102.453619 \r\n\" style=\"fill:none;stroke:#cccccc;stroke-linecap:round;\"/>\r\n     </g>\r\n     <g id=\"text_30\">\r\n      <!-- 0.5 -->\r\n      <g style=\"fill:#262626;\" transform=\"translate(372.436364 106.390416)scale(0.11 -0.11)\">\r\n       <use xlink:href=\"#ArialMT-30\"/>\r\n       <use x=\"55.615234\" xlink:href=\"#ArialMT-2e\"/>\r\n       <use x=\"83.398438\" xlink:href=\"#ArialMT-35\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"ytick_12\">\r\n     <g id=\"line2d_34\">\r\n      <path clip-path=\"url(#p9fb57203a4)\" d=\"M 397.226364 66.216906 \r\nL 701.59 66.216906 \r\n\" style=\"fill:none;stroke:#cccccc;stroke-linecap:round;\"/>\r\n     </g>\r\n     <g id=\"text_31\">\r\n      <!-- 0.6 -->\r\n      <g style=\"fill:#262626;\" transform=\"translate(372.436364 70.153703)scale(0.11 -0.11)\">\r\n       <use xlink:href=\"#ArialMT-30\"/>\r\n       <use x=\"55.615234\" xlink:href=\"#ArialMT-2e\"/>\r\n       <use x=\"83.398438\" xlink:href=\"#ArialMT-36\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"ytick_13\">\r\n     <g id=\"line2d_35\">\r\n      <path clip-path=\"url(#p9fb57203a4)\" d=\"M 397.226364 29.980193 \r\nL 701.59 29.980193 \r\n\" style=\"fill:none;stroke:#cccccc;stroke-linecap:round;\"/>\r\n     </g>\r\n     <g id=\"text_32\">\r\n      <!-- 0.7 -->\r\n      <g style=\"fill:#262626;\" transform=\"translate(372.436364 33.91699)scale(0.11 -0.11)\">\r\n       <use xlink:href=\"#ArialMT-30\"/>\r\n       <use x=\"55.615234\" xlink:href=\"#ArialMT-2e\"/>\r\n       <use x=\"83.398438\" xlink:href=\"#ArialMT-37\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n   </g>\r\n   <g id=\"line2d_36\">\r\n    <path clip-path=\"url(#p9fb57203a4)\" d=\"M 411.061074 34.14392 \r\nL 425.623928 47.478047 \r\nL 440.186781 95.547479 \r\nL 454.749635 161.004142 \r\nL 469.312488 191.519697 \r\nL 483.875341 210.003725 \r\nL 498.438195 224.651126 \r\nL 513.001048 236.235688 \r\nL 527.563902 246.964674 \r\nL 542.126755 255.655879 \r\nL 556.689609 262.707725 \r\nL 571.252462 268.053133 \r\nL 585.815315 271.979005 \r\nL 600.378169 275.432619 \r\nL 614.941022 277.407291 \r\nL 629.503876 278.566343 \r\nL 644.066729 279.637516 \r\nL 658.629582 280.489494 \r\nL 673.192436 280.906033 \r\nL 687.755289 281.23483 \r\n\" style=\"fill:none;stroke:#4c72b0;stroke-linecap:round;stroke-width:1.5;\"/>\r\n   </g>\r\n   <g id=\"line2d_37\">\r\n    <path clip-path=\"url(#p9fb57203a4)\" d=\"M 411.061074 36.892277 \r\nL 425.623928 57.949041 \r\nL 440.186781 121.93363 \r\nL 454.749635 167.946233 \r\nL 469.312488 179.079089 \r\nL 483.875341 183.601471 \r\nL 498.438195 185.374708 \r\nL 513.001048 185.876998 \r\nL 527.563902 183.555412 \r\nL 542.126755 180.183013 \r\nL 556.689609 173.73481 \r\nL 571.252462 168.603279 \r\nL 585.815315 162.583066 \r\nL 600.378169 156.422969 \r\nL 614.941022 150.341567 \r\nL 629.503876 144.502093 \r\nL 644.066729 137.069839 \r\nL 658.629582 133.764591 \r\nL 673.192436 129.397774 \r\nL 687.755289 125.970634 \r\n\" style=\"fill:none;stroke:#c44e52;stroke-linecap:round;stroke-width:1.5;\"/>\r\n   </g>\r\n   <g id=\"patch_9\">\r\n    <path d=\"M 397.226364 293.589375 \r\nL 397.226364 21.789375 \r\n\" style=\"fill:none;stroke:#cccccc;stroke-linecap:square;stroke-linejoin:miter;stroke-width:1.25;\"/>\r\n   </g>\r\n   <g id=\"patch_10\">\r\n    <path d=\"M 701.59 293.589375 \r\nL 701.59 21.789375 \r\n\" style=\"fill:none;stroke:#cccccc;stroke-linecap:square;stroke-linejoin:miter;stroke-width:1.25;\"/>\r\n   </g>\r\n   <g id=\"patch_11\">\r\n    <path d=\"M 397.226364 293.589375 \r\nL 701.59 293.589375 \r\n\" style=\"fill:none;stroke:#cccccc;stroke-linecap:square;stroke-linejoin:miter;stroke-width:1.25;\"/>\r\n   </g>\r\n   <g id=\"patch_12\">\r\n    <path d=\"M 397.226364 21.789375 \r\nL 701.59 21.789375 \r\n\" style=\"fill:none;stroke:#cccccc;stroke-linecap:square;stroke-linejoin:miter;stroke-width:1.25;\"/>\r\n   </g>\r\n   <g id=\"text_33\">\r\n    <!-- Training and validation loss -->\r\n    <g style=\"fill:#262626;\" transform=\"translate(476.929119 15.789375)scale(0.12 -0.12)\">\r\n     <defs>\r\n      <path d=\"M 197 991 \r\nL 753 1078 \r\nQ 800 744 1014 566 \r\nQ 1228 388 1613 388 \r\nQ 2000 388 2187 545 \r\nQ 2375 703 2375 916 \r\nQ 2375 1106 2209 1216 \r\nQ 2094 1291 1634 1406 \r\nQ 1016 1563 777 1677 \r\nQ 538 1791 414 1992 \r\nQ 291 2194 291 2438 \r\nQ 291 2659 392 2848 \r\nQ 494 3038 669 3163 \r\nQ 800 3259 1026 3326 \r\nQ 1253 3394 1513 3394 \r\nQ 1903 3394 2198 3281 \r\nQ 2494 3169 2634 2976 \r\nQ 2775 2784 2828 2463 \r\nL 2278 2388 \r\nQ 2241 2644 2061 2787 \r\nQ 1881 2931 1553 2931 \r\nQ 1166 2931 1000 2803 \r\nQ 834 2675 834 2503 \r\nQ 834 2394 903 2306 \r\nQ 972 2216 1119 2156 \r\nQ 1203 2125 1616 2013 \r\nQ 2213 1853 2448 1751 \r\nQ 2684 1650 2818 1456 \r\nQ 2953 1263 2953 975 \r\nQ 2953 694 2789 445 \r\nQ 2625 197 2315 61 \r\nQ 2006 -75 1616 -75 \r\nQ 969 -75 630 194 \r\nQ 291 463 197 991 \r\nz\r\n\" id=\"ArialMT-73\" transform=\"scale(0.015625)\"/>\r\n     </defs>\r\n     <use xlink:href=\"#ArialMT-54\"/>\r\n     <use x=\"57.333984\" xlink:href=\"#ArialMT-72\"/>\r\n     <use x=\"90.634766\" xlink:href=\"#ArialMT-61\"/>\r\n     <use x=\"146.25\" xlink:href=\"#ArialMT-69\"/>\r\n     <use x=\"168.466797\" xlink:href=\"#ArialMT-6e\"/>\r\n     <use x=\"224.082031\" xlink:href=\"#ArialMT-69\"/>\r\n     <use x=\"246.298828\" xlink:href=\"#ArialMT-6e\"/>\r\n     <use x=\"301.914062\" xlink:href=\"#ArialMT-67\"/>\r\n     <use x=\"357.529297\" xlink:href=\"#ArialMT-20\"/>\r\n     <use x=\"385.3125\" xlink:href=\"#ArialMT-61\"/>\r\n     <use x=\"440.927734\" xlink:href=\"#ArialMT-6e\"/>\r\n     <use x=\"496.542969\" xlink:href=\"#ArialMT-64\"/>\r\n     <use x=\"552.158203\" xlink:href=\"#ArialMT-20\"/>\r\n     <use x=\"579.941406\" xlink:href=\"#ArialMT-76\"/>\r\n     <use x=\"629.941406\" xlink:href=\"#ArialMT-61\"/>\r\n     <use x=\"685.556641\" xlink:href=\"#ArialMT-6c\"/>\r\n     <use x=\"707.773438\" xlink:href=\"#ArialMT-69\"/>\r\n     <use x=\"729.990234\" xlink:href=\"#ArialMT-64\"/>\r\n     <use x=\"785.605469\" xlink:href=\"#ArialMT-61\"/>\r\n     <use x=\"841.220703\" xlink:href=\"#ArialMT-74\"/>\r\n     <use x=\"869.003906\" xlink:href=\"#ArialMT-69\"/>\r\n     <use x=\"891.220703\" xlink:href=\"#ArialMT-6f\"/>\r\n     <use x=\"946.835938\" xlink:href=\"#ArialMT-6e\"/>\r\n     <use x=\"1002.451172\" xlink:href=\"#ArialMT-20\"/>\r\n     <use x=\"1030.234375\" xlink:href=\"#ArialMT-6c\"/>\r\n     <use x=\"1052.451172\" xlink:href=\"#ArialMT-6f\"/>\r\n     <use x=\"1108.066406\" xlink:href=\"#ArialMT-73\"/>\r\n     <use x=\"1158.066406\" xlink:href=\"#ArialMT-73\"/>\r\n    </g>\r\n   </g>\r\n   <g id=\"legend_2\">\r\n    <g id=\"patch_13\">\r\n     <path d=\"M 588.573594 61.837969 \r\nL 693.89 61.837969 \r\nQ 696.09 61.837969 696.09 59.637969 \r\nL 696.09 29.489375 \r\nQ 696.09 27.289375 693.89 27.289375 \r\nL 588.573594 27.289375 \r\nQ 586.373594 27.289375 586.373594 29.489375 \r\nL 586.373594 59.637969 \r\nQ 586.373594 61.837969 588.573594 61.837969 \r\nz\r\n\" style=\"fill:#ffffff;opacity:0.8;stroke:#cccccc;stroke-linejoin:miter;\"/>\r\n    </g>\r\n    <g id=\"line2d_38\">\r\n     <path d=\"M 590.773594 35.712969 \r\nL 612.773594 35.712969 \r\n\" style=\"fill:none;stroke:#4c72b0;stroke-linecap:round;stroke-width:1.5;\"/>\r\n    </g>\r\n    <g id=\"line2d_39\"/>\r\n    <g id=\"text_34\">\r\n     <!-- Training loss -->\r\n     <g style=\"fill:#262626;\" transform=\"translate(621.573594 39.562969)scale(0.11 -0.11)\">\r\n      <use xlink:href=\"#ArialMT-54\"/>\r\n      <use x=\"57.333984\" xlink:href=\"#ArialMT-72\"/>\r\n      <use x=\"90.634766\" xlink:href=\"#ArialMT-61\"/>\r\n      <use x=\"146.25\" xlink:href=\"#ArialMT-69\"/>\r\n      <use x=\"168.466797\" xlink:href=\"#ArialMT-6e\"/>\r\n      <use x=\"224.082031\" xlink:href=\"#ArialMT-69\"/>\r\n      <use x=\"246.298828\" xlink:href=\"#ArialMT-6e\"/>\r\n      <use x=\"301.914062\" xlink:href=\"#ArialMT-67\"/>\r\n      <use x=\"357.529297\" xlink:href=\"#ArialMT-20\"/>\r\n      <use x=\"385.3125\" xlink:href=\"#ArialMT-6c\"/>\r\n      <use x=\"407.529297\" xlink:href=\"#ArialMT-6f\"/>\r\n      <use x=\"463.144531\" xlink:href=\"#ArialMT-73\"/>\r\n      <use x=\"513.144531\" xlink:href=\"#ArialMT-73\"/>\r\n     </g>\r\n    </g>\r\n    <g id=\"line2d_40\">\r\n     <path d=\"M 590.773594 51.401719 \r\nL 612.773594 51.401719 \r\n\" style=\"fill:none;stroke:#c44e52;stroke-linecap:round;stroke-width:1.5;\"/>\r\n    </g>\r\n    <g id=\"line2d_41\"/>\r\n    <g id=\"text_35\">\r\n     <!-- Validation loss -->\r\n     <g style=\"fill:#262626;\" transform=\"translate(621.573594 55.251719)scale(0.11 -0.11)\">\r\n      <use xlink:href=\"#ArialMT-56\"/>\r\n      <use x=\"59.324219\" xlink:href=\"#ArialMT-61\"/>\r\n      <use x=\"114.939453\" xlink:href=\"#ArialMT-6c\"/>\r\n      <use x=\"137.15625\" xlink:href=\"#ArialMT-69\"/>\r\n      <use x=\"159.373047\" xlink:href=\"#ArialMT-64\"/>\r\n      <use x=\"214.988281\" xlink:href=\"#ArialMT-61\"/>\r\n      <use x=\"270.603516\" xlink:href=\"#ArialMT-74\"/>\r\n      <use x=\"298.386719\" xlink:href=\"#ArialMT-69\"/>\r\n      <use x=\"320.603516\" xlink:href=\"#ArialMT-6f\"/>\r\n      <use x=\"376.21875\" xlink:href=\"#ArialMT-6e\"/>\r\n      <use x=\"431.833984\" xlink:href=\"#ArialMT-20\"/>\r\n      <use x=\"459.617188\" xlink:href=\"#ArialMT-6c\"/>\r\n      <use x=\"481.833984\" xlink:href=\"#ArialMT-6f\"/>\r\n      <use x=\"537.449219\" xlink:href=\"#ArialMT-73\"/>\r\n      <use x=\"587.449219\" xlink:href=\"#ArialMT-73\"/>\r\n     </g>\r\n    </g>\r\n   </g>\r\n  </g>\r\n </g>\r\n <defs>\r\n  <clipPath id=\"pcadb55d9e4\">\r\n   <rect height=\"271.8\" width=\"304.363636\" x=\"31.99\" y=\"21.789375\"/>\r\n  </clipPath>\r\n  <clipPath id=\"p9fb57203a4\">\r\n   <rect height=\"271.8\" width=\"304.363636\" x=\"397.226364\" y=\"21.789375\"/>\r\n  </clipPath>\r\n </defs>\r\n</svg>\r\n",
            "text/plain": [
              "<Figure size 864x360 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "plot_history(history)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {},
      "outputs": [],
      "source": [
        "model = load_model(\"./modelo_mlp.hdf5\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1113/1113 [==============================] - 5s 4ms/step - loss: 0.1065 - accuracy: 0.9754\n",
            "\n",
            "accuracy: 97.54%\n"
          ]
        }
      ],
      "source": [
        "scores = model.evaluate(X_treino, y_treino)\n",
        "print(\"\\n%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "279/279 [==============================] - 1s 4ms/step - loss: 0.2698 - accuracy: 0.8928\n",
            "\n",
            "accuracy: 89.28%\n"
          ]
        }
      ],
      "source": [
        "scores = model.evaluate(X_teste, y_teste)\n",
        "print(\"\\n%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "68SiMjcWqD_m"
      },
      "source": [
        "#### **Validação do professor**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T24EasckqG2I"
      },
      "source": [
        "Consolidar apenas os scripts do seu **modelo campeão**, desde o carregamento do dataframe, separação das amostras, tratamentos utilizados (funções, limpezas, etc.), criação dos objetos de vetorização dos textos e modelo treinado e outras implementações utilizadas no processo de desenvolvimento do modelo."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VFA-CYfawkEJ"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "TemplateTrabalhoFinal-NLP.ipynb",
      "provenance": []
    },
    "interpreter": {
      "hash": "c24c9dacf042e5cf8b743bae11b2cef3a95983df3bc5153773d9ffef1d5207d2"
    },
    "kernelspec": {
      "display_name": "Python 3.8.10 64-bit ('tf-gpu': conda)",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": ""
    },
    "metadata": {
      "interpreter": {
        "hash": "63fd5069d213b44bf678585dea6b12cceca9941eaf7f819626cde1f2670de90d"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}